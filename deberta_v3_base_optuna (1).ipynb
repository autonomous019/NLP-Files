{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "505e1dbe-f484-4304-8001-f10b5e0321c8",
        "outputId": "277b4d60-49cd-4924-a2a5-5a276beb05de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.0.2-py3-none-any.whl (348 kB)\n",
            "\u001b[K     |████████████████████████████████| 348 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy<1.9.0,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.3)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 9.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (6.0)\n",
            "Collecting alembic>=1.5.0\n",
            "  Downloading alembic-1.8.1-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 47.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from alembic>=1.5.0->optuna) (4.12.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.3-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic>=1.5.0->optuna) (5.9.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.3.0->optuna) (1.1.3)\n",
            "Collecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.4.1)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.10.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 44.8 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.2-py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 53.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (4.1.1)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (22.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->alembic>=1.5.0->optuna) (3.8.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=2acbea5997813e13b200744faae6d48d935a6e9254da94d3bcd17cee5194bcbf\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.2.3 alembic-1.8.1 autopage-0.5.1 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.2 colorlog-6.7.0 optuna-3.0.2 pbr-5.10.0 pyperclip-1.8.2 stevedore-3.5.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.22.1-py3-none-any.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.9.0\n",
            "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 55.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 54.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.22.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 4.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna\n",
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install sentencepiece\n",
        "\n",
        "#\n",
        "#\n",
        "\n"
      ],
      "id": "505e1dbe-f484-4304-8001-f10b5e0321c8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ef39394-5986-44bb-a6d6-84957a492ae5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "b3206746a345465c9e6cd6cebe17e36a",
            "2245537afaa4475f8c666d87e0d40fe3",
            "ba65a8f16cc744949c301fa6fbe97a6f",
            "d2d464de09dc4d849496e75a367ce676",
            "4d6846d243ce44b296f6fb9ada4b5118",
            "6804fd0bf95e455cbe353620c25cb283",
            "a307c09a5cfb458b9c4b0c98ee018c9e",
            "7ef4e0eaa48e4b829f17268185ac98f0",
            "1badb5737ac942ada61d4f612da7166c",
            "08766aa343eb44889cb28348c6c558f8",
            "3e05981666154fd18381cd70fe2cb3f5"
          ]
        },
        "outputId": "b5de9446-7316-4078-8807-dbcbc8ab22fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moving 0 files to the new cache system\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3206746a345465c9e6cd6cebe17e36a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "################ NOTES ####################\n",
        "#\n",
        "#  - see ensemble https://www.kaggle.com/code/gilfernandes/commonlit-pytorch-ensemble-large/notebook \n",
        "#  - following is based on https://github.com/gilfernandes/commonlit\n",
        "#  - original notebook at https://github.com/gilfernandes/commonlit/blob/main/72_pytorch_transformers_deberta_optuna.ipynb\n",
        "#  - see article at https://signal.onepointltd.com/post/102h4el/modern-natural-language-processing-on-kaggle\n",
        "#  - guide to HF scheduler and differential learning rate https://www.kaggle.com/code/rhtsingh/guide-to-huggingface-schedulers-differential-lrs/notebook\n",
        "#  - learning rate schedulers https://www.kaggle.com/code/snnclsr/learning-rate-schedulers\n",
        "#  - optuna toy example https://github.com/optuna/optuna-examples/blob/main/pytorch/pytorch_simple.pyc\n",
        "#  - K-Folding, https://cran.r-project.org/web/packages/cvms/vignettes/picking_the_number_of_folds_for_cross-validation.html\n",
        "#  - deberta-v2 documentation: https://huggingface.co/transformers/v4.7.0/model_doc/deberta_v2.html\n",
        "#  - torch optimization documentation, to adjust activation and learning scheduler https://alband.github.io/doc_view/optim.html\n",
        "#  - HF, optimization docs, https://huggingface.co/docs/transformers/main_classes/optimizer_schedules\n",
        "#\n",
        "#\n",
        "###########################################\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "import gc, warnings, random, time, os\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam, lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AdamW\n",
        "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
        "from transformers import get_cosine_with_hard_restarts_schedule_with_warmup, get_cosine_schedule_with_warmup, get_linear_schedule_with_warmup\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "import gc\n",
        "gc.enable()\n",
        "\n",
        "import optuna"
      ],
      "id": "8ef39394-5986-44bb-a6d6-84957a492ae5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f58c54d1-55c1-4701-9fde-692cf4450c84"
      },
      "source": [
        "### Folders and Dataframes"
      ],
      "id": "f58c54d1-55c1-4701-9fde-692cf4450c84"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07938c53-d840-4889-b9ab-3170c608137e"
      },
      "outputs": [],
      "source": [
        "class Config(): \n",
        "    NUM_FOLDS = 6\n",
        "    NUM_EPOCHS = 3\n",
        "    BATCH_SIZE = 8 #was 16\n",
        "    MAX_LEN = 512 # was 248\n",
        "    EVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)]\n",
        "    MODEL_PATH = \"/content/gdrive/My Drive/feedback-prize-english-language-learning/deberta-v3-base\"\n",
        "    model = \"microsoft/deberta-v3-base\"\n",
        "    TOKENIZER_PATH = '/home/commonlit/models/deberta-large-lm/best_lm'\n",
        "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    SEED = 3\n",
        "    NUM_WORKERS = 2\n",
        "    MODEL_FOLDER = \"\"\n",
        "    model_name = 'deberta-v3-base'\n",
        "    svm_kernels = ['rbf']\n",
        "    svm_c = 5\n",
        "    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
        "\n",
        "cfg = Config()"
      ],
      "id": "07938c53-d840-4889-b9ab-3170c608137e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "08c75e83-4760-4511-bf31-a144abfc01fc",
        "outputId": "0d37897a-dd58-427e-f050-6dd297709bc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nDATA_PATH = Path('/home/commonlit/data/')\\nassert DATA_PATH.exists()\\nMODELS_PATH = Path('/home/commonlit/models/')\\nif not MODELS_PATH.exists():\\n    os.mkdir(MODELS_PATH)\\nassert MODELS_PATH.exists()\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# ====================================================\n",
        "# Directory settings\n",
        "# ====================================================\n",
        "import os\n",
        "# Import from GoogleDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "os.chdir(\"//content/gdrive/MyDrive/feedback-prize-english-language-learning\")\n",
        "\n",
        "save_dir = \"/content/gdrive/My Drive/feedback-prize-english-language-learning/submission\"\n",
        "logs_dir = \"/content/gdrive/My Drive/feedback-prize-english-language-learning/logs\"\n",
        "data_dir = \"/content/gdrive/My Drive/feedback-prize-english-language-learning\"\n",
        "model_dir = \"/content/gdrive/My Drive/feedback-prize-english-language-learning/deberta-v3-base\"\n",
        "\n",
        "import os.path\n",
        "from os import path\n",
        "\n",
        "model_folder = cfg.model.replace('/', '-')\n",
        "if path.exists(data_dir + \"/\" + \"trained_\" + model_folder) == False:\n",
        "  os.mkdir(data_dir + \"/\" + \"trained_\" + model_folder)\n",
        "save_model_dir = data_dir + \"/\" + \"trained_\" + model_folder\n",
        "\n",
        "#OUTPUT_DIR = './'\n",
        "#if not os.path.exists(OUTPUT_DIR):\n",
        "#    os.makedirs(OUTPUT_DIR)\n",
        "\n",
        "DATA_PATH = data_dir\n",
        "cfg.MODELS_PATH = model_dir\n",
        "\n",
        "'''\n",
        "DATA_PATH = Path('/home/commonlit/data/')\n",
        "assert DATA_PATH.exists()\n",
        "MODELS_PATH = Path('/home/commonlit/models/')\n",
        "if not MODELS_PATH.exists():\n",
        "    os.mkdir(MODELS_PATH)\n",
        "assert MODELS_PATH.exists()\n",
        "'''"
      ],
      "id": "08c75e83-4760-4511-bf31-a144abfc01fc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f12796f2-c49a-4d32-9f38-0ecdec520539"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(DATA_PATH + '/train.csv')\n",
        "test_df = pd.read_csv(DATA_PATH + '/test.csv')\n",
        "sample_df = pd.read_csv(DATA_PATH + '/sample_submission.csv')"
      ],
      "id": "f12796f2-c49a-4d32-9f38-0ecdec520539"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "836ed820-371a-48da-8412-db0701c05c8a"
      },
      "outputs": [],
      "source": [
        "def remove_unnecessary(df):\n",
        "    df.drop(df[df['syntax'] == 0].index, inplace=True)\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    \n",
        "remove_unnecessary(train_df)"
      ],
      "id": "836ed820-371a-48da-8412-db0701c05c8a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "179a075d-6fa8-4cf4-b703-db4f09c9649e",
        "outputId": "3679ac02-c778-48ab-a029-7d6a64831603"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           text_id                                          full_text  \\\n",
              "0     0016926B079C  I think that students would benefit from learn...   \n",
              "1     0022683E9EA5  When a problem is a change you have to let it ...   \n",
              "2     00299B378633  Dear, Principal\\n\\nIf u change the school poli...   \n",
              "3     003885A45F42  The best time in life is when you become yours...   \n",
              "4     0049B1DF5CCC  Small act of kindness can impact in other peop...   \n",
              "...            ...                                                ...   \n",
              "3906  FFD29828A873  I believe using cellphones in class for educat...   \n",
              "3907  FFD9A83B0849  Working alone, students do not have to argue w...   \n",
              "3908  FFDC4011AC9C  \"A problem is a chance for you to do your best...   \n",
              "3909  FFE16D704B16  Many people disagree with Albert Schweitzer's ...   \n",
              "3910  FFED00D6E0BD  Do you think that failure is the main thing fo...   \n",
              "\n",
              "      cohesion  syntax  vocabulary  phraseology  grammar  conventions  \n",
              "0          3.5     3.5         3.0          3.0      4.0          3.0  \n",
              "1          2.5     2.5         3.0          2.0      2.0          2.5  \n",
              "2          3.0     3.5         3.0          3.0      3.0          2.5  \n",
              "3          4.5     4.5         4.5          4.5      4.0          5.0  \n",
              "4          2.5     3.0         3.0          3.0      2.5          2.5  \n",
              "...        ...     ...         ...          ...      ...          ...  \n",
              "3906       2.5     3.0         3.0          3.5      2.5          2.5  \n",
              "3907       4.0     4.0         4.0          4.0      3.5          3.0  \n",
              "3908       2.5     3.0         3.0          3.0      3.5          3.0  \n",
              "3909       4.0     4.5         4.5          4.0      4.5          4.5  \n",
              "3910       3.5     2.5         3.5          3.0      3.0          3.5  \n",
              "\n",
              "[3911 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b1ff8925-d945-4a89-b7dc-108a96dda326\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_id</th>\n",
              "      <th>full_text</th>\n",
              "      <th>cohesion</th>\n",
              "      <th>syntax</th>\n",
              "      <th>vocabulary</th>\n",
              "      <th>phraseology</th>\n",
              "      <th>grammar</th>\n",
              "      <th>conventions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0016926B079C</td>\n",
              "      <td>I think that students would benefit from learn...</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0022683E9EA5</td>\n",
              "      <td>When a problem is a change you have to let it ...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00299B378633</td>\n",
              "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>003885A45F42</td>\n",
              "      <td>The best time in life is when you become yours...</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0049B1DF5CCC</td>\n",
              "      <td>Small act of kindness can impact in other peop...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3906</th>\n",
              "      <td>FFD29828A873</td>\n",
              "      <td>I believe using cellphones in class for educat...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3907</th>\n",
              "      <td>FFD9A83B0849</td>\n",
              "      <td>Working alone, students do not have to argue w...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3908</th>\n",
              "      <td>FFDC4011AC9C</td>\n",
              "      <td>\"A problem is a chance for you to do your best...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3909</th>\n",
              "      <td>FFE16D704B16</td>\n",
              "      <td>Many people disagree with Albert Schweitzer's ...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3910</th>\n",
              "      <td>FFED00D6E0BD</td>\n",
              "      <td>Do you think that failure is the main thing fo...</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3911 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b1ff8925-d945-4a89-b7dc-108a96dda326')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b1ff8925-d945-4a89-b7dc-108a96dda326 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b1ff8925-d945-4a89-b7dc-108a96dda326');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "train_df"
      ],
      "id": "179a075d-6fa8-4cf4-b703-db4f09c9649e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e79e005-5651-4414-9725-4567d3a9b300"
      },
      "source": [
        "### Config and Seeding"
      ],
      "id": "2e79e005-5651-4414-9725-4567d3a9b300"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02b17b48-922f-4a27-8bb4-e641491d137e"
      },
      "outputs": [],
      "source": [
        "#if not cfg.MODEL_FOLDER.exists():\n",
        "#    os.mkdir(cfg.MODEL_FOLDER)"
      ],
      "id": "02b17b48-922f-4a27-8bb4-e641491d137e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dd067b3-c1a6-4c4a-900e-9499ca93b551"
      },
      "outputs": [],
      "source": [
        "def set_random_seed(random_seed):\n",
        "    random.seed(random_seed)\n",
        "    np.random.seed(random_seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n",
        "\n",
        "    torch.manual_seed(random_seed)\n",
        "    torch.cuda.manual_seed(random_seed)\n",
        "    torch.cuda.manual_seed_all(random_seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True"
      ],
      "id": "2dd067b3-c1a6-4c4a-900e-9499ca93b551"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05ab8b20-6c63-4d51-b6fe-39ff141ad03e"
      },
      "source": [
        "### Dataset"
      ],
      "id": "05ab8b20-6c63-4d51-b6fe-39ff141ad03e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "978289c5-dc58-4be5-93d8-64566dad766e"
      },
      "outputs": [],
      "source": [
        "def add_bins(train_df, num_bins):\n",
        "    train_df.loc[:, 'bins'] = pd.cut(train_df['syntax'], bins=num_bins, labels=False)\n",
        "    return num_bins"
      ],
      "id": "978289c5-dc58-4be5-93d8-64566dad766e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "131b79d6-1ec5-492b-930f-e4c75288bcde",
        "outputId": "54cd09cc-c845-4629-ad5f-891fa1a91b43"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "add_bins(train_df, cfg.NUM_FOLDS)"
      ],
      "id": "131b79d6-1ec5-492b-930f-e4c75288bcde"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "c7ee1b97-cef2-46cc-88d7-3f7ae737c3e1",
        "outputId": "a27a9c5c-adf1-47ab-9bd2-1919f964d862"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     cohesion           syntax           vocabulary           phraseology  \\\n",
              "        count      mean  count      mean      count      mean       count   \n",
              "bins                                                                        \n",
              "0          40  1.612500     40  1.362500         40  1.962500          40   \n",
              "1         410  2.439024    410  2.000000        410  2.693902         410   \n",
              "2        2089  2.966730   2089  2.799186       2089  3.088320        2089   \n",
              "3         867  3.448097    867  3.500000        867  3.491926         867   \n",
              "4         388  3.813144    388  4.000000        388  3.795103         388   \n",
              "5         117  4.264957    117  4.572650        117  4.448718         117   \n",
              "\n",
              "               grammar           conventions            \n",
              "          mean   count      mean       count      mean  \n",
              "bins                                                    \n",
              "0     1.737500      40  1.687500          40  1.612500  \n",
              "1     2.450000     410  2.326829         410  2.389024  \n",
              "2     2.931067    2089  2.838200        2089  2.910244  \n",
              "3     3.452134     867  3.401384         867  3.427336  \n",
              "4     3.829897     388  3.742268         388  3.725515  \n",
              "5     4.393162     117  4.358974         117  4.354701  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-680f8154-e814-47fe-a606-05a9e59a112e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">cohesion</th>\n",
              "      <th colspan=\"2\" halign=\"left\">syntax</th>\n",
              "      <th colspan=\"2\" halign=\"left\">vocabulary</th>\n",
              "      <th colspan=\"2\" halign=\"left\">phraseology</th>\n",
              "      <th colspan=\"2\" halign=\"left\">grammar</th>\n",
              "      <th colspan=\"2\" halign=\"left\">conventions</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bins</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>40</td>\n",
              "      <td>1.612500</td>\n",
              "      <td>40</td>\n",
              "      <td>1.362500</td>\n",
              "      <td>40</td>\n",
              "      <td>1.962500</td>\n",
              "      <td>40</td>\n",
              "      <td>1.737500</td>\n",
              "      <td>40</td>\n",
              "      <td>1.687500</td>\n",
              "      <td>40</td>\n",
              "      <td>1.612500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>410</td>\n",
              "      <td>2.439024</td>\n",
              "      <td>410</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>410</td>\n",
              "      <td>2.693902</td>\n",
              "      <td>410</td>\n",
              "      <td>2.450000</td>\n",
              "      <td>410</td>\n",
              "      <td>2.326829</td>\n",
              "      <td>410</td>\n",
              "      <td>2.389024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2089</td>\n",
              "      <td>2.966730</td>\n",
              "      <td>2089</td>\n",
              "      <td>2.799186</td>\n",
              "      <td>2089</td>\n",
              "      <td>3.088320</td>\n",
              "      <td>2089</td>\n",
              "      <td>2.931067</td>\n",
              "      <td>2089</td>\n",
              "      <td>2.838200</td>\n",
              "      <td>2089</td>\n",
              "      <td>2.910244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>867</td>\n",
              "      <td>3.448097</td>\n",
              "      <td>867</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>867</td>\n",
              "      <td>3.491926</td>\n",
              "      <td>867</td>\n",
              "      <td>3.452134</td>\n",
              "      <td>867</td>\n",
              "      <td>3.401384</td>\n",
              "      <td>867</td>\n",
              "      <td>3.427336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>388</td>\n",
              "      <td>3.813144</td>\n",
              "      <td>388</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>388</td>\n",
              "      <td>3.795103</td>\n",
              "      <td>388</td>\n",
              "      <td>3.829897</td>\n",
              "      <td>388</td>\n",
              "      <td>3.742268</td>\n",
              "      <td>388</td>\n",
              "      <td>3.725515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>117</td>\n",
              "      <td>4.264957</td>\n",
              "      <td>117</td>\n",
              "      <td>4.572650</td>\n",
              "      <td>117</td>\n",
              "      <td>4.448718</td>\n",
              "      <td>117</td>\n",
              "      <td>4.393162</td>\n",
              "      <td>117</td>\n",
              "      <td>4.358974</td>\n",
              "      <td>117</td>\n",
              "      <td>4.354701</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-680f8154-e814-47fe-a606-05a9e59a112e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-680f8154-e814-47fe-a606-05a9e59a112e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-680f8154-e814-47fe-a606-05a9e59a112e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "train_df.groupby(['bins'])[cfg.target_cols].agg(['count', 'mean'])"
      ],
      "id": "c7ee1b97-cef2-46cc-88d7-3f7ae737c3e1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "xfAYc2rK-UDy",
        "outputId": "7830d4ae-04c7-4b97-901a-29afcd28b40f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "for fold in range(max(train_df[\"bins\"])+1):\n",
        "    #sns.distplot(df[df[\"skfold\"]==fold][\"syntax\"],\n",
        "    sns.distplot(train_df[train_df[\"bins\"]==fold][cfg.target_cols], \n",
        "                 hist=False,\n",
        "                 kde = True,\n",
        "                 label = f\"Label {fold}\"\n",
        "                )\n",
        "    \n",
        "plt.title(f\"Feature Distribution\")\n",
        "plt.legend(loc=\"best\") \n",
        "plt.show()"
      ],
      "id": "xfAYc2rK-UDy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41922d13-b7af-4675-ae2d-c384025c86e8",
        "outputId": "86b5715d-3103-405f-9f0c-206913de88f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)"
      ],
      "id": "41922d13-b7af-4675-ae2d-c384025c86e8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "929301e1-626d-4ba5-9f32-d361769f6c58",
        "outputId": "8d03b14c-01ea-488f-8f62-cad74726ee16"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nwith open('../data/tokenizer.vocab.txt', 'w') as f:\\n    for k, v in tokenizer.vocab.items():\\n        f.write(f'{k}: {v}\\n')\\n\""
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "with open('../data/tokenizer.vocab.txt', 'w') as f:\n",
        "    for k, v in tokenizer.vocab.items():\n",
        "        f.write(f'{k}: {v}\\n')\n",
        "'''"
      ],
      "id": "929301e1-626d-4ba5-9f32-d361769f6c58"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71b946f5-a6f0-4415-911c-e5a7f628f617"
      },
      "outputs": [],
      "source": [
        "pad_token = '______'"
      ],
      "id": "71b946f5-a6f0-4415-911c-e5a7f628f617"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42787f35-115b-4258-925f-6575f3063924"
      },
      "outputs": [],
      "source": [
        "class CommonLitDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, inference_only=False):\n",
        "        super().__init__()\n",
        "        self.df, self.inference_only = df, inference_only\n",
        "        self.text = df['full_text'].tolist()\n",
        "        self.bins = df['bins']\n",
        "\n",
        "        #is inference_only really necessary, check len of target, etc. \n",
        "\n",
        "        if not inference_only:\n",
        "            self.target = torch.tensor(df['syntax'].to_numpy(), dtype = torch.float32)\n",
        "            #self.target = torch.tensor(df[cfg.target_cols].to_numpy(), dtype = torch.float32)\n",
        "        \n",
        "\n",
        "        self.encoded = tokenizer.batch_encode_plus(\n",
        "            self.text,\n",
        "            padding = 'max_length',\n",
        "            max_length = cfg.MAX_LEN,\n",
        "            truncation = True,\n",
        "            return_attention_mask=True\n",
        "        )\n",
        "        self.tokenizer = tokenizer\n",
        "        \n",
        "    def __getitem__(self, index):        \n",
        "        input_ids = torch.tensor(self.encoded['input_ids'][index])\n",
        "        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n",
        "        \n",
        "        if self.inference_only:\n",
        "            return {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
        "        else:\n",
        "            target = self.target[index]\n",
        "            return {'input_ids': input_ids, 'attention_mask': attention_mask, 'target': target}\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.df)"
      ],
      "id": "42787f35-115b-4258-925f-6575f3063924"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bf2329ea-0c9a-407c-8c82-8f247ad9c852"
      },
      "outputs": [],
      "source": [
        "sample_ds = CommonLitDataset(train_df, tokenizer)"
      ],
      "id": "bf2329ea-0c9a-407c-8c82-8f247ad9c852"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd8ee04e-2d41-46bc-89e0-c0b9476090cb"
      },
      "source": [
        "### Model"
      ],
      "id": "bd8ee04e-2d41-46bc-89e0-c0b9476090cb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2ef269a-01da-4555-bdb7-265d93940648"
      },
      "outputs": [],
      "source": [
        "class AttentionHead(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_features, hidden_dim, num_targets):\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        \n",
        "        self.hidden_layer = nn.Linear(in_features, hidden_dim)\n",
        "        self.final_layer = nn.Linear(hidden_dim, num_targets)\n",
        "        self.out_features = hidden_dim\n",
        "        \n",
        "    def forward(self, features):\n",
        "        att = torch.tanh(self.hidden_layer(features))\n",
        "        score = self.final_layer(att)\n",
        "        attention_weights = torch.softmax(score, dim=1)\n",
        "        return attention_weights"
      ],
      "id": "d2ef269a-01da-4555-bdb7-265d93940648"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f69ec8b1-1d38-46f9-af3b-4a34e0c8dc5c"
      },
      "outputs": [],
      "source": [
        "config = AutoConfig.from_pretrained(cfg.MODEL_PATH)"
      ],
      "id": "f69ec8b1-1d38-46f9-af3b-4a34e0c8dc5c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b9b003d-a13f-43c9-830e-edecafdec275",
        "outputId": "0a0b56ea-aa93-4203-892c-678314d901d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128100, 128000)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "config.vocab_size, tokenizer.vocab_size"
      ],
      "id": "2b9b003d-a13f-43c9-830e-edecafdec275"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95f7c88c-5970-4b12-bb86-ee4a5de126b3"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "class CommonLitModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CommonLitModel, self).__init__()\n",
        "        config = AutoConfig.from_pretrained(cfg.MODEL_PATH)\n",
        "        config.update({\n",
        "            \"output_hidden_states\": True,\n",
        "            \"hidden_dropout_prob\": 0.0,\n",
        "            \"layer_norm_eps\": 1e-7\n",
        "        })\n",
        "        self.transformer_model = AutoModelForSequenceClassification.from_pretrained(cfg.MODEL_PATH, config=config)\n",
        "        self.attention = AttentionHead(config.hidden_size, 512, 1)\n",
        "        self.regressor = nn.Linear(config.hidden_size, 1)\n",
        "    \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        hidden_states = self.transformer_model(input_ids=input_ids, attention_mask=attention_mask)['hidden_states']\n",
        "        last_layer_hidden_states = hidden_states[-1]\n",
        "        weights = self.attention(last_layer_hidden_states)\n",
        "        context_vector = torch.sum(weights * last_layer_hidden_states, dim=1) \n",
        "        return self.regressor(context_vector), context_vector"
      ],
      "id": "95f7c88c-5970-4b12-bb86-ee4a5de126b3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aa41e86-dc36-43ae-a98f-e97cbc46fc53",
        "outputId": "db781d43-9f2c-4b6a-e11c-f8210c8b523f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at /content/gdrive/My Drive/feedback-prize-english-language-learning/deberta-v3-base were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.bias']\n",
            "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at /content/gdrive/My Drive/feedback-prize-english-language-learning/deberta-v3-base and are newly initialized: ['pooler.dense.weight', 'classifier.bias', 'classifier.weight', 'pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "sample_model = CommonLitModel()"
      ],
      "id": "1aa41e86-dc36-43ae-a98f-e97cbc46fc53"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01d5b219-2e0e-4485-99ef-3d2ffa0f149d"
      },
      "outputs": [],
      "source": [
        "\n",
        "'''\n",
        "parameters() return the parameters in topologically sorted order: To list\n",
        "model parameters in the sequence of their execution during forward pass, basically \n",
        "from input layer to the output layer. Or in the order of their execution in computation graph.\n",
        "\n",
        "Layer Wise Learning Rate, see create_optimizer() below, \n",
        "https://kozodoi.me/python/deep%20learning/pytorch/tutorial/2022/03/29/discriminative-lr.html\n",
        "\n",
        "use differential learning rates based on the layers in the model, for base layers=12, large layers=18\n",
        "based on a range set below base_lr and last_lr\n",
        "\n",
        "'''\n",
        "\n",
        "import re\n",
        "\n",
        "for i, (name, param) in enumerate(sample_model.named_parameters()):\n",
        "    if(name.find('layer') > -1):\n",
        "        layer_name = re.sub(r'.+(layer\\.\\d+).+', r'\\1', name)"
      ],
      "id": "01d5b219-2e0e-4485-99ef-3d2ffa0f149d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4929919-01cf-47e1-9e9c-3f040562b111",
        "outputId": "ecb88f1e-cc3c-4fc6-f366-5e81cd6fc031"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 transformer_model.deberta.embeddings.word_embeddings.weight torch.Size([128100, 768])\n",
            "1 transformer_model.deberta.embeddings.LayerNorm.weight torch.Size([768])\n",
            "2 transformer_model.deberta.embeddings.LayerNorm.bias torch.Size([768])\n",
            "3 transformer_model.deberta.encoder.layer.0.attention.self.query_proj.weight torch.Size([768, 768])\n",
            "4 transformer_model.deberta.encoder.layer.0.attention.self.query_proj.bias torch.Size([768])\n",
            "5 transformer_model.deberta.encoder.layer.0.attention.self.key_proj.weight torch.Size([768, 768])\n",
            "6 transformer_model.deberta.encoder.layer.0.attention.self.key_proj.bias torch.Size([768])\n",
            "7 transformer_model.deberta.encoder.layer.0.attention.self.value_proj.weight torch.Size([768, 768])\n",
            "8 transformer_model.deberta.encoder.layer.0.attention.self.value_proj.bias torch.Size([768])\n",
            "9 transformer_model.deberta.encoder.layer.0.attention.output.dense.weight torch.Size([768, 768])\n",
            "10 transformer_model.deberta.encoder.layer.0.attention.output.dense.bias torch.Size([768])\n",
            "11 transformer_model.deberta.encoder.layer.0.attention.output.LayerNorm.weight torch.Size([768])\n",
            "12 transformer_model.deberta.encoder.layer.0.attention.output.LayerNorm.bias torch.Size([768])\n",
            "13 transformer_model.deberta.encoder.layer.0.intermediate.dense.weight torch.Size([3072, 768])\n",
            "14 transformer_model.deberta.encoder.layer.0.intermediate.dense.bias torch.Size([3072])\n",
            "15 transformer_model.deberta.encoder.layer.0.output.dense.weight torch.Size([768, 3072])\n",
            "16 transformer_model.deberta.encoder.layer.0.output.dense.bias torch.Size([768])\n",
            "17 transformer_model.deberta.encoder.layer.0.output.LayerNorm.weight torch.Size([768])\n",
            "18 transformer_model.deberta.encoder.layer.0.output.LayerNorm.bias torch.Size([768])\n",
            "19 transformer_model.deberta.encoder.layer.1.attention.self.query_proj.weight torch.Size([768, 768])\n",
            "20 transformer_model.deberta.encoder.layer.1.attention.self.query_proj.bias torch.Size([768])\n",
            "21 transformer_model.deberta.encoder.layer.1.attention.self.key_proj.weight torch.Size([768, 768])\n",
            "22 transformer_model.deberta.encoder.layer.1.attention.self.key_proj.bias torch.Size([768])\n",
            "23 transformer_model.deberta.encoder.layer.1.attention.self.value_proj.weight torch.Size([768, 768])\n",
            "24 transformer_model.deberta.encoder.layer.1.attention.self.value_proj.bias torch.Size([768])\n",
            "25 transformer_model.deberta.encoder.layer.1.attention.output.dense.weight torch.Size([768, 768])\n",
            "26 transformer_model.deberta.encoder.layer.1.attention.output.dense.bias torch.Size([768])\n",
            "27 transformer_model.deberta.encoder.layer.1.attention.output.LayerNorm.weight torch.Size([768])\n",
            "28 transformer_model.deberta.encoder.layer.1.attention.output.LayerNorm.bias torch.Size([768])\n",
            "29 transformer_model.deberta.encoder.layer.1.intermediate.dense.weight torch.Size([3072, 768])\n",
            "30 transformer_model.deberta.encoder.layer.1.intermediate.dense.bias torch.Size([3072])\n",
            "31 transformer_model.deberta.encoder.layer.1.output.dense.weight torch.Size([768, 3072])\n",
            "32 transformer_model.deberta.encoder.layer.1.output.dense.bias torch.Size([768])\n",
            "33 transformer_model.deberta.encoder.layer.1.output.LayerNorm.weight torch.Size([768])\n",
            "34 transformer_model.deberta.encoder.layer.1.output.LayerNorm.bias torch.Size([768])\n",
            "35 transformer_model.deberta.encoder.layer.2.attention.self.query_proj.weight torch.Size([768, 768])\n",
            "36 transformer_model.deberta.encoder.layer.2.attention.self.query_proj.bias torch.Size([768])\n",
            "37 transformer_model.deberta.encoder.layer.2.attention.self.key_proj.weight torch.Size([768, 768])\n",
            "38 transformer_model.deberta.encoder.layer.2.attention.self.key_proj.bias torch.Size([768])\n",
            "39 transformer_model.deberta.encoder.layer.2.attention.self.value_proj.weight torch.Size([768, 768])\n",
            "40 transformer_model.deberta.encoder.layer.2.attention.self.value_proj.bias torch.Size([768])\n",
            "41 transformer_model.deberta.encoder.layer.2.attention.output.dense.weight torch.Size([768, 768])\n",
            "42 transformer_model.deberta.encoder.layer.2.attention.output.dense.bias torch.Size([768])\n",
            "43 transformer_model.deberta.encoder.layer.2.attention.output.LayerNorm.weight torch.Size([768])\n",
            "44 transformer_model.deberta.encoder.layer.2.attention.output.LayerNorm.bias torch.Size([768])\n",
            "45 transformer_model.deberta.encoder.layer.2.intermediate.dense.weight torch.Size([3072, 768])\n",
            "46 transformer_model.deberta.encoder.layer.2.intermediate.dense.bias torch.Size([3072])\n",
            "47 transformer_model.deberta.encoder.layer.2.output.dense.weight torch.Size([768, 3072])\n",
            "48 transformer_model.deberta.encoder.layer.2.output.dense.bias torch.Size([768])\n",
            "49 transformer_model.deberta.encoder.layer.2.output.LayerNorm.weight torch.Size([768])\n",
            "50 transformer_model.deberta.encoder.layer.2.output.LayerNorm.bias torch.Size([768])\n",
            "51 transformer_model.deberta.encoder.layer.3.attention.self.query_proj.weight torch.Size([768, 768])\n",
            "52 transformer_model.deberta.encoder.layer.3.attention.self.query_proj.bias torch.Size([768])\n",
            "53 transformer_model.deberta.encoder.layer.3.attention.self.key_proj.weight torch.Size([768, 768])\n",
            "54 transformer_model.deberta.encoder.layer.3.attention.self.key_proj.bias torch.Size([768])\n",
            "55 transformer_model.deberta.encoder.layer.3.attention.self.value_proj.weight torch.Size([768, 768])\n",
            "56 transformer_model.deberta.encoder.layer.3.attention.self.value_proj.bias torch.Size([768])\n",
            "57 transformer_model.deberta.encoder.layer.3.attention.output.dense.weight torch.Size([768, 768])\n",
            "58 transformer_model.deberta.encoder.layer.3.attention.output.dense.bias torch.Size([768])\n",
            "59 transformer_model.deberta.encoder.layer.3.attention.output.LayerNorm.weight torch.Size([768])\n",
            "60 transformer_model.deberta.encoder.layer.3.attention.output.LayerNorm.bias torch.Size([768])\n",
            "61 transformer_model.deberta.encoder.layer.3.intermediate.dense.weight torch.Size([3072, 768])\n",
            "62 transformer_model.deberta.encoder.layer.3.intermediate.dense.bias torch.Size([3072])\n",
            "63 transformer_model.deberta.encoder.layer.3.output.dense.weight torch.Size([768, 3072])\n",
            "64 transformer_model.deberta.encoder.layer.3.output.dense.bias torch.Size([768])\n",
            "65 transformer_model.deberta.encoder.layer.3.output.LayerNorm.weight torch.Size([768])\n",
            "66 transformer_model.deberta.encoder.layer.3.output.LayerNorm.bias torch.Size([768])\n",
            "67 transformer_model.deberta.encoder.layer.4.attention.self.query_proj.weight torch.Size([768, 768])\n",
            "68 transformer_model.deberta.encoder.layer.4.attention.self.query_proj.bias torch.Size([768])\n",
            "69 transformer_model.deberta.encoder.layer.4.attention.self.key_proj.weight torch.Size([768, 768])\n",
            "70 transformer_model.deberta.encoder.layer.4.attention.self.key_proj.bias torch.Size([768])\n",
            "71 transformer_model.deberta.encoder.layer.4.attention.self.value_proj.weight torch.Size([768, 768])\n",
            "72 transformer_model.deberta.encoder.layer.4.attention.self.value_proj.bias torch.Size([768])\n",
            "73 transformer_model.deberta.encoder.layer.4.attention.output.dense.weight torch.Size([768, 768])\n",
            "74 transformer_model.deberta.encoder.layer.4.attention.output.dense.bias torch.Size([768])\n",
            "75 transformer_model.deberta.encoder.layer.4.attention.output.LayerNorm.weight torch.Size([768])\n",
            "76 transformer_model.deberta.encoder.layer.4.attention.output.LayerNorm.bias torch.Size([768])\n",
            "77 transformer_model.deberta.encoder.layer.4.intermediate.dense.weight torch.Size([3072, 768])\n",
            "78 transformer_model.deberta.encoder.layer.4.intermediate.dense.bias torch.Size([3072])\n",
            "79 transformer_model.deberta.encoder.layer.4.output.dense.weight torch.Size([768, 3072])\n",
            "80 transformer_model.deberta.encoder.layer.4.output.dense.bias torch.Size([768])\n",
            "81 transformer_model.deberta.encoder.layer.4.output.LayerNorm.weight torch.Size([768])\n",
            "82 transformer_model.deberta.encoder.layer.4.output.LayerNorm.bias torch.Size([768])\n",
            "83 transformer_model.deberta.encoder.layer.5.attention.self.query_proj.weight torch.Size([768, 768])\n",
            "84 transformer_model.deberta.encoder.layer.5.attention.self.query_proj.bias torch.Size([768])\n",
            "85 transformer_model.deberta.encoder.layer.5.attention.self.key_proj.weight torch.Size([768, 768])\n",
            "86 transformer_model.deberta.encoder.layer.5.attention.self.key_proj.bias torch.Size([768])\n",
            "87 transformer_model.deberta.encoder.layer.5.attention.self.value_proj.weight torch.Size([768, 768])\n",
            "88 transformer_model.deberta.encoder.layer.5.attention.self.value_proj.bias torch.Size([768])\n",
            "89 transformer_model.deberta.encoder.layer.5.attention.output.dense.weight torch.Size([768, 768])\n",
            "90 transformer_model.deberta.encoder.layer.5.attention.output.dense.bias torch.Size([768])\n",
            "91 transformer_model.deberta.encoder.layer.5.attention.output.LayerNorm.weight torch.Size([768])\n",
            "92 transformer_model.deberta.encoder.layer.5.attention.output.LayerNorm.bias torch.Size([768])\n",
            "93 transformer_model.deberta.encoder.layer.5.intermediate.dense.weight torch.Size([3072, 768])\n",
            "94 transformer_model.deberta.encoder.layer.5.intermediate.dense.bias torch.Size([3072])\n",
            "95 transformer_model.deberta.encoder.layer.5.output.dense.weight torch.Size([768, 3072])\n",
            "96 transformer_model.deberta.encoder.layer.5.output.dense.bias torch.Size([768])\n",
            "97 transformer_model.deberta.encoder.layer.5.output.LayerNorm.weight torch.Size([768])\n",
            "98 transformer_model.deberta.encoder.layer.5.output.LayerNorm.bias torch.Size([768])\n",
            "99 transformer_model.deberta.encoder.layer.6.attention.self.query_proj.weight torch.Size([768, 768])\n",
            "100 transformer_model.deberta.encoder.layer.6.attention.self.query_proj.bias torch.Size([768])\n",
            "101 transformer_model.deberta.encoder.layer.6.attention.self.key_proj.weight torch.Size([768, 768])\n",
            "102 transformer_model.deberta.encoder.layer.6.attention.self.key_proj.bias torch.Size([768])\n",
            "103 transformer_model.deberta.encoder.layer.6.attention.self.value_proj.weight torch.Size([768, 768])\n",
            "104 transformer_model.deberta.encoder.layer.6.attention.self.value_proj.bias torch.Size([768])\n",
            "105 transformer_model.deberta.encoder.layer.6.attention.output.dense.weight torch.Size([768, 768])\n",
            "106 transformer_model.deberta.encoder.layer.6.attention.output.dense.bias torch.Size([768])\n",
            "107 transformer_model.deberta.encoder.layer.6.attention.output.LayerNorm.weight torch.Size([768])\n",
            "108 transformer_model.deberta.encoder.layer.6.attention.output.LayerNorm.bias torch.Size([768])\n",
            "109 transformer_model.deberta.encoder.layer.6.intermediate.dense.weight torch.Size([3072, 768])\n",
            "110 transformer_model.deberta.encoder.layer.6.intermediate.dense.bias torch.Size([3072])\n",
            "111 transformer_model.deberta.encoder.layer.6.output.dense.weight torch.Size([768, 3072])\n",
            "112 transformer_model.deberta.encoder.layer.6.output.dense.bias torch.Size([768])\n",
            "113 transformer_model.deberta.encoder.layer.6.output.LayerNorm.weight torch.Size([768])\n",
            "114 transformer_model.deberta.encoder.layer.6.output.LayerNorm.bias torch.Size([768])\n",
            "115 transformer_model.deberta.encoder.layer.7.attention.self.query_proj.weight torch.Size([768, 768])\n",
            "116 transformer_model.deberta.encoder.layer.7.attention.self.query_proj.bias torch.Size([768])\n",
            "117 transformer_model.deberta.encoder.layer.7.attention.self.key_proj.weight torch.Size([768, 768])\n",
            "118 transformer_model.deberta.encoder.layer.7.attention.self.key_proj.bias torch.Size([768])\n",
            "119 transformer_model.deberta.encoder.layer.7.attention.self.value_proj.weight torch.Size([768, 768])\n",
            "120 transformer_model.deberta.encoder.layer.7.attention.self.value_proj.bias torch.Size([768])\n",
            "121 transformer_model.deberta.encoder.layer.7.attention.output.dense.weight torch.Size([768, 768])\n",
            "122 transformer_model.deberta.encoder.layer.7.attention.output.dense.bias torch.Size([768])\n",
            "123 transformer_model.deberta.encoder.layer.7.attention.output.LayerNorm.weight torch.Size([768])\n",
            "124 transformer_model.deberta.encoder.layer.7.attention.output.LayerNorm.bias torch.Size([768])\n",
            "125 transformer_model.deberta.encoder.layer.7.intermediate.dense.weight torch.Size([3072, 768])\n",
            "126 transformer_model.deberta.encoder.layer.7.intermediate.dense.bias torch.Size([3072])\n",
            "127 transformer_model.deberta.encoder.layer.7.output.dense.weight torch.Size([768, 3072])\n",
            "128 transformer_model.deberta.encoder.layer.7.output.dense.bias torch.Size([768])\n",
            "129 transformer_model.deberta.encoder.layer.7.output.LayerNorm.weight torch.Size([768])\n",
            "130 transformer_model.deberta.encoder.layer.7.output.LayerNorm.bias torch.Size([768])\n",
            "131 transformer_model.deberta.encoder.layer.8.attention.self.query_proj.weight torch.Size([768, 768])\n",
            "132 transformer_model.deberta.encoder.layer.8.attention.self.query_proj.bias torch.Size([768])\n",
            "133 transformer_model.deberta.encoder.layer.8.attention.self.key_proj.weight torch.Size([768, 768])\n",
            "134 transformer_model.deberta.encoder.layer.8.attention.self.key_proj.bias torch.Size([768])\n",
            "135 transformer_model.deberta.encoder.layer.8.attention.self.value_proj.weight torch.Size([768, 768])\n",
            "136 transformer_model.deberta.encoder.layer.8.attention.self.value_proj.bias torch.Size([768])\n",
            "137 transformer_model.deberta.encoder.layer.8.attention.output.dense.weight torch.Size([768, 768])\n",
            "138 transformer_model.deberta.encoder.layer.8.attention.output.dense.bias torch.Size([768])\n",
            "139 transformer_model.deberta.encoder.layer.8.attention.output.LayerNorm.weight torch.Size([768])\n",
            "140 transformer_model.deberta.encoder.layer.8.attention.output.LayerNorm.bias torch.Size([768])\n",
            "141 transformer_model.deberta.encoder.layer.8.intermediate.dense.weight torch.Size([3072, 768])\n",
            "142 transformer_model.deberta.encoder.layer.8.intermediate.dense.bias torch.Size([3072])\n",
            "143 transformer_model.deberta.encoder.layer.8.output.dense.weight torch.Size([768, 3072])\n",
            "144 transformer_model.deberta.encoder.layer.8.output.dense.bias torch.Size([768])\n",
            "145 transformer_model.deberta.encoder.layer.8.output.LayerNorm.weight torch.Size([768])\n",
            "146 transformer_model.deberta.encoder.layer.8.output.LayerNorm.bias torch.Size([768])\n",
            "147 transformer_model.deberta.encoder.layer.9.attention.self.query_proj.weight torch.Size([768, 768])\n",
            "148 transformer_model.deberta.encoder.layer.9.attention.self.query_proj.bias torch.Size([768])\n",
            "149 transformer_model.deberta.encoder.layer.9.attention.self.key_proj.weight torch.Size([768, 768])\n",
            "150 transformer_model.deberta.encoder.layer.9.attention.self.key_proj.bias torch.Size([768])\n",
            "151 transformer_model.deberta.encoder.layer.9.attention.self.value_proj.weight torch.Size([768, 768])\n",
            "152 transformer_model.deberta.encoder.layer.9.attention.self.value_proj.bias torch.Size([768])\n",
            "153 transformer_model.deberta.encoder.layer.9.attention.output.dense.weight torch.Size([768, 768])\n",
            "154 transformer_model.deberta.encoder.layer.9.attention.output.dense.bias torch.Size([768])\n",
            "155 transformer_model.deberta.encoder.layer.9.attention.output.LayerNorm.weight torch.Size([768])\n",
            "156 transformer_model.deberta.encoder.layer.9.attention.output.LayerNorm.bias torch.Size([768])\n",
            "157 transformer_model.deberta.encoder.layer.9.intermediate.dense.weight torch.Size([3072, 768])\n",
            "158 transformer_model.deberta.encoder.layer.9.intermediate.dense.bias torch.Size([3072])\n",
            "159 transformer_model.deberta.encoder.layer.9.output.dense.weight torch.Size([768, 3072])\n",
            "160 transformer_model.deberta.encoder.layer.9.output.dense.bias torch.Size([768])\n",
            "161 transformer_model.deberta.encoder.layer.9.output.LayerNorm.weight torch.Size([768])\n",
            "162 transformer_model.deberta.encoder.layer.9.output.LayerNorm.bias torch.Size([768])\n",
            "163 transformer_model.deberta.encoder.layer.10.attention.self.query_proj.weight torch.Size([768, 768])\n",
            "164 transformer_model.deberta.encoder.layer.10.attention.self.query_proj.bias torch.Size([768])\n",
            "165 transformer_model.deberta.encoder.layer.10.attention.self.key_proj.weight torch.Size([768, 768])\n",
            "166 transformer_model.deberta.encoder.layer.10.attention.self.key_proj.bias torch.Size([768])\n",
            "167 transformer_model.deberta.encoder.layer.10.attention.self.value_proj.weight torch.Size([768, 768])\n",
            "168 transformer_model.deberta.encoder.layer.10.attention.self.value_proj.bias torch.Size([768])\n",
            "169 transformer_model.deberta.encoder.layer.10.attention.output.dense.weight torch.Size([768, 768])\n",
            "170 transformer_model.deberta.encoder.layer.10.attention.output.dense.bias torch.Size([768])\n",
            "171 transformer_model.deberta.encoder.layer.10.attention.output.LayerNorm.weight torch.Size([768])\n",
            "172 transformer_model.deberta.encoder.layer.10.attention.output.LayerNorm.bias torch.Size([768])\n",
            "173 transformer_model.deberta.encoder.layer.10.intermediate.dense.weight torch.Size([3072, 768])\n",
            "174 transformer_model.deberta.encoder.layer.10.intermediate.dense.bias torch.Size([3072])\n",
            "175 transformer_model.deberta.encoder.layer.10.output.dense.weight torch.Size([768, 3072])\n",
            "176 transformer_model.deberta.encoder.layer.10.output.dense.bias torch.Size([768])\n",
            "177 transformer_model.deberta.encoder.layer.10.output.LayerNorm.weight torch.Size([768])\n",
            "178 transformer_model.deberta.encoder.layer.10.output.LayerNorm.bias torch.Size([768])\n",
            "179 transformer_model.deberta.encoder.layer.11.attention.self.query_proj.weight torch.Size([768, 768])\n",
            "180 transformer_model.deberta.encoder.layer.11.attention.self.query_proj.bias torch.Size([768])\n",
            "181 transformer_model.deberta.encoder.layer.11.attention.self.key_proj.weight torch.Size([768, 768])\n",
            "182 transformer_model.deberta.encoder.layer.11.attention.self.key_proj.bias torch.Size([768])\n",
            "183 transformer_model.deberta.encoder.layer.11.attention.self.value_proj.weight torch.Size([768, 768])\n",
            "184 transformer_model.deberta.encoder.layer.11.attention.self.value_proj.bias torch.Size([768])\n",
            "185 transformer_model.deberta.encoder.layer.11.attention.output.dense.weight torch.Size([768, 768])\n",
            "186 transformer_model.deberta.encoder.layer.11.attention.output.dense.bias torch.Size([768])\n",
            "187 transformer_model.deberta.encoder.layer.11.attention.output.LayerNorm.weight torch.Size([768])\n",
            "188 transformer_model.deberta.encoder.layer.11.attention.output.LayerNorm.bias torch.Size([768])\n",
            "189 transformer_model.deberta.encoder.layer.11.intermediate.dense.weight torch.Size([3072, 768])\n",
            "190 transformer_model.deberta.encoder.layer.11.intermediate.dense.bias torch.Size([3072])\n",
            "191 transformer_model.deberta.encoder.layer.11.output.dense.weight torch.Size([768, 3072])\n",
            "192 transformer_model.deberta.encoder.layer.11.output.dense.bias torch.Size([768])\n",
            "193 transformer_model.deberta.encoder.layer.11.output.LayerNorm.weight torch.Size([768])\n",
            "194 transformer_model.deberta.encoder.layer.11.output.LayerNorm.bias torch.Size([768])\n",
            "195 transformer_model.deberta.encoder.rel_embeddings.weight torch.Size([512, 768])\n",
            "196 transformer_model.deberta.encoder.LayerNorm.weight torch.Size([768])\n",
            "197 transformer_model.deberta.encoder.LayerNorm.bias torch.Size([768])\n",
            "198 transformer_model.pooler.dense.weight torch.Size([768, 768])\n",
            "199 transformer_model.pooler.dense.bias torch.Size([768])\n",
            "200 transformer_model.classifier.weight torch.Size([2, 768])\n",
            "201 transformer_model.classifier.bias torch.Size([2])\n",
            "202 attention.hidden_layer.weight torch.Size([512, 768])\n",
            "203 attention.hidden_layer.bias torch.Size([512])\n",
            "204 attention.final_layer.weight torch.Size([1, 512])\n",
            "205 attention.final_layer.bias torch.Size([1])\n",
            "206 regressor.weight torch.Size([1, 768])\n",
            "207 regressor.bias torch.Size([1])\n"
          ]
        }
      ],
      "source": [
        "for i, (name, param) in enumerate(sample_model.named_parameters()):\n",
        "    print(i, name, param.size())"
      ],
      "id": "a4929919-01cf-47e1-9e9c-3f040562b111"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8c04f3dd-285e-4d70-8dd5-37fc2737ca5c"
      },
      "outputs": [],
      "source": [
        "# sample_input_ids = torch.randint(0, 1000, [2, 248])\n",
        "# sample_attention_mask = torch.randint(0, 1000, [2, 248])"
      ],
      "id": "8c04f3dd-285e-4d70-8dd5-37fc2737ca5c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ca35f5f4-51d1-4000-ad76-ed912daa8987"
      },
      "outputs": [],
      "source": [
        "sample_records = [sample_ds[i] for i in range(2)]"
      ],
      "id": "ca35f5f4-51d1-4000-ad76-ed912daa8987"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "709e45b4-ac40-4d67-8fd3-45c0f40d8a7a",
        "outputId": "d67ac154-e92b-4ffa-eddf-a6aedd3ff219"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask', 'target'])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "sample_records[0].keys()"
      ],
      "id": "709e45b4-ac40-4d67-8fd3-45c0f40d8a7a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3389bd94-785b-47b5-bc32-1e4e58dd9e2a"
      },
      "outputs": [],
      "source": [
        "sample_input_ids = torch.stack([r['input_ids'] for r in sample_records])\n",
        "sample_attention_mask = torch.stack([r['attention_mask'] for r in sample_records])\n",
        "sample_target = torch.stack([r['target'] for r in sample_records])"
      ],
      "id": "3389bd94-785b-47b5-bc32-1e4e58dd9e2a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04781a7b-218a-41cc-b81f-d2d248e2c7c1",
        "outputId": "5c5150b1-e808-42d0-9729-6fd31545cf0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 512]), torch.Size([2, 512]), torch.Size([2]))"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "sample_input_ids.shape, sample_attention_mask.shape, sample_target.shape"
      ],
      "id": "04781a7b-218a-41cc-b81f-d2d248e2c7c1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66a3b2b4-920e-4dff-bf9f-210d12b9c86b",
        "outputId": "65bca16e-bd8e-4996-894f-ff421c21a9f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[  1, 273, 428,  ...,   0,   0,   0],\n",
              "        [  1, 486, 266,  ..., 479, 374,   2]])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_input_ids"
      ],
      "id": "66a3b2b4-920e-4dff-bf9f-210d12b9c86b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25dd4b70-f9d7-4c3a-81d6-da03dd8cf914"
      },
      "outputs": [],
      "source": [
        "internal_out = sample_model.transformer_model(sample_input_ids, attention_mask=sample_attention_mask)"
      ],
      "id": "25dd4b70-f9d7-4c3a-81d6-da03dd8cf914"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a770a11a-485d-49b5-ae8a-9d5dccc90a05",
        "outputId": "b24d6367-6df6-4325-cf92-23adbd8ef20d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "odict_keys(['logits', 'hidden_states'])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "internal_out.keys()"
      ],
      "id": "a770a11a-485d-49b5-ae8a-9d5dccc90a05"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "841fcfeb-6e75-40e5-8f82-265ed8da72d1",
        "outputId": "4f7fd0f2-20a2-4b80-f6ff-5175c5f0ecc8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(13, torch.Size([2, 512, 768]))"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(internal_out.hidden_states), internal_out.hidden_states[-1].shape"
      ],
      "id": "841fcfeb-6e75-40e5-8f82-265ed8da72d1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31ded8f5-d2ec-465f-88ca-317bf1954026"
      },
      "outputs": [],
      "source": [
        "sample_res = sample_model(sample_input_ids, sample_attention_mask)"
      ],
      "id": "31ded8f5-d2ec-465f-88ca-317bf1954026"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea66f03e-eac6-478c-ab27-042d97ec1855",
        "outputId": "9c8e0bbf-11f3-4c6a-825f-26f392f8da82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([2, 1]), torch.Size([2, 768]))"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_res[0].shape, sample_res[1].shape"
      ],
      "id": "ea66f03e-eac6-478c-ab27-042d97ec1855"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb86b195-8d45-41e2-9042-7007e416d916",
        "outputId": "35b12370-7c02-43f0-f9af-8a24c5e58260"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[  1.7711, -13.9977,  -5.0611,  ...,  -2.6052,  -7.4638, -17.4571],\n",
              "        [ -4.6843,  16.3795, -35.6908,  ..., -57.1498,  -9.9274,   3.7000],\n",
              "        [ 21.4383, -34.1507,  -1.3559,  ...,   6.7833, -20.1302,  18.0184],\n",
              "        ...,\n",
              "        [ -8.8758, -17.4992,  34.6939,  ...,  -2.3758, -18.4880,  15.7974],\n",
              "        [ 23.5820,  36.7930,  10.4988,  ...,  -2.7897, -26.2732, -17.4451],\n",
              "        [-21.4052,  30.7723,   4.1797,  ...,  -2.3608, -11.8757,  22.8453]])"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.sum(torch.randn([8, 496, 768]), axis=1)"
      ],
      "id": "cb86b195-8d45-41e2-9042-7007e416d916"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f4bb67f-bc5f-4f90-8236-7f7eb949ec92"
      },
      "source": [
        "### Evaluation and Prediction"
      ],
      "id": "1f4bb67f-bc5f-4f90-8236-7f7eb949ec92"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31f7c55d-a9c2-4e76-a7ef-42acd56f7a87"
      },
      "outputs": [],
      "source": [
        "def eval_mse(model, data_loader):\n",
        "    model.eval()\n",
        "    mse_sum = 0\n",
        "    mse_loss = nn.MSELoss(reduction='sum')\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_num, record in enumerate(data_loader):\n",
        "            input_ids, attention_mask, target = record['input_ids'].to(cfg.DEVICE), record['attention_mask'].to(cfg.DEVICE), record['target'].to(cfg.DEVICE)\n",
        "            pred, _ = model(input_ids, attention_mask)\n",
        "            mse_sum += mse_loss(pred.flatten().cpu(), target.cpu())\n",
        "            \n",
        "    return mse_sum / len(data_loader.dataset)"
      ],
      "id": "31f7c55d-a9c2-4e76-a7ef-42acd56f7a87"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9b035767-df66-428f-a297-6db704dfc153"
      },
      "outputs": [],
      "source": [
        "def predict(model, data_loader):\n",
        "    model.eval()\n",
        "    result = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_num, record in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
        "            input_ids, attention_mask = record['input_ids'].to(cfg.DEVICE), record['attention_mask'].to(cfg.DEVICE)\n",
        "            pred, _ = model(input_ids, attention_mask)\n",
        "            result.extend(pred.flatten().to(\"cpu\").tolist())\n",
        "            \n",
        "    return np.array(result)"
      ],
      "id": "9b035767-df66-428f-a297-6db704dfc153"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b90cd468-30bf-4362-824b-480820edb2ed"
      },
      "outputs": [],
      "source": [
        "sample_dl = DataLoader(sample_ds, shuffle=False, batch_size=16, num_workers=1)"
      ],
      "id": "b90cd468-30bf-4362-824b-480820edb2ed"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fb0ec5d-7c5f-4a70-b792-7cb822fb35ce"
      },
      "source": [
        "### Optimizer and Sampler"
      ],
      "id": "3fb0ec5d-7c5f-4a70-b792-7cb822fb35ce"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04c43c63-bdf7-4493-9f76-7b96b4c3f42c"
      },
      "outputs": [],
      "source": [
        "def create_optimizer(model, base_lr=5e-5, last_lr=None):\n",
        "    \n",
        "    #layer wise learning. numerical arguments are from model.named_parameters, see above for list\n",
        "    named_parameters = list(model.named_parameters())\n",
        "    \n",
        "    attention_param_start = 194 #end of last layer, 0-11 layers, layer 11 end\n",
        "    regressor_param_start = 206 #named parameter regressor.weight\n",
        "    roberta_parameters = named_parameters[:198] #transformer_model.pooler.dense.weight\n",
        "    attention_parameters = named_parameters[202:regressor_param_start] #attention.hidden_layer_weight\n",
        "    regressor_parameters = named_parameters[regressor_param_start:]\n",
        "    \n",
        "    attention_group = [params for (name, params) in attention_parameters]\n",
        "    regressor_group = [params for (name, params) in regressor_parameters]\n",
        "    \n",
        "    parameters = []\n",
        "    if last_lr is not None:\n",
        "        parameters.append({\"params\": attention_group, \"lr\": last_lr})\n",
        "        parameters.append({\"params\": regressor_group, \"lr\": last_lr})\n",
        "    else:\n",
        "        parameters.append({\"params\": attention_group})\n",
        "        parameters.append({\"params\": regressor_group})\n",
        "        \n",
        "    # Change on different models\n",
        "    layer_low_threshold = 99\n",
        "    layer_middle_threshold = 130\n",
        "    \n",
        "    for layer_num, (name, params) in enumerate(roberta_parameters):\n",
        "        weight_decay = 0.0 if 'bias' in name else 0.01\n",
        "        \n",
        "        lr = base_lr / 2.5 # 2e-05\n",
        "        if layer_num >= layer_middle_threshold:\n",
        "            lr = base_lr / 0.5 # 1e-4\n",
        "        elif layer_num >= layer_low_threshold:        \n",
        "            lr = base_lr    \n",
        "            \n",
        "        parameters.append({\"params\": params,\n",
        "                           \"weight_decay\": weight_decay,\n",
        "                           \"lr\": lr})\n",
        "        \n",
        "    return AdamW(parameters)"
      ],
      "id": "04c43c63-bdf7-4493-9f76-7b96b4c3f42c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dd255e8-4568-4dfa-abd2-a429f9d545b5"
      },
      "outputs": [],
      "source": [
        "sample_optimizer = create_optimizer(sample_model)"
      ],
      "id": "7dd255e8-4568-4dfa-abd2-a429f9d545b5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4830178b-dff7-4635-a447-b9da1ca1ecf0"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Sampler,SequentialSampler,RandomSampler,SubsetRandomSampler\n",
        "from collections import Counter\n",
        "\n",
        "class WeightedSampler(Sampler):\n",
        "    \n",
        "    def __init__(self, dataset):\n",
        "        \n",
        "        self.indices = list(range(len(dataset)))\n",
        "        self.num_samples = len(dataset)\n",
        "        self.label_to_count = dict(Counter(dataset.bins))\n",
        "        weights = [1/self.label_to_count[i] for i in dataset.bins]\n",
        "        \n",
        "        self.weights = torch.tensor(weights,dtype=torch.double)\n",
        "        \n",
        "    def __iter__(self):\n",
        "        count = 0\n",
        "        index = [self.indices[i] for i in torch.multinomial(self.weights, self.num_samples, replacement=True)]\n",
        "        while count < self.num_samples:\n",
        "            yield index[count]\n",
        "            count += 1\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.num_samples"
      ],
      "id": "4830178b-dff7-4635-a447-b9da1ca1ecf0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7de8f75-5e7a-45d0-8029-ea6146ea2b48"
      },
      "source": [
        "### Training"
      ],
      "id": "b7de8f75-5e7a-45d0-8029-ea6146ea2b48"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89e6e9bd-9ae3-4871-a47d-37ed129634fc"
      },
      "outputs": [],
      "source": [
        "def choose_eval_period(val_rmse):\n",
        "    for rmse, period in cfg.EVAL_SCHEDULE:\n",
        "        if val_rmse >= rmse:\n",
        "            return period"
      ],
      "id": "89e6e9bd-9ae3-4871-a47d-37ed129634fc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2501f5b3-fffb-42c7-8fcb-9f026d32499d"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def serialize_best(best_val_rmse, best_epoch, val_rmse, epoch, model, model_path, lr):\n",
        "    if not best_val_rmse or val_rmse < best_val_rmse:\n",
        "        best_val_rmse = val_rmse\n",
        "        best_epoch = epoch\n",
        "        #if not model_path.parent.exists():\n",
        "        #    print(model_path.parent)\n",
        "        #    os.makedirs(model_path.parent)\n",
        "        \n",
        "#         torch.save(model.state_dict(), model_path)\n",
        "        torch.save(model.state_dict(), save_model_dir + \"/\" + f\"{cfg.model.replace('/', '-')}_fold{fold}_best.pt\")\n",
        "        print(f\"New best_val_rmse: {best_val_rmse:0.4}\")\n",
        "    else:       \n",
        "        print(f\"Still best_val_rmse: {best_val_rmse:0.4}\",\n",
        "              f\"(from epoch {best_epoch})\")\n",
        "    return best_epoch, best_val_rmse"
      ],
      "id": "2501f5b3-fffb-42c7-8fcb-9f026d32499d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01766a88-69dc-4c6d-8dca-2950bdc7e231"
      },
      "outputs": [],
      "source": [
        "class Trainer():\n",
        "    def __init__(self, lr, scaler, model, model_path, train_loader, val_loader, optimizer, scheduler=None, num_epochs=cfg.NUM_EPOCHS):\n",
        "        self.lr, self.scaler, self.model, self.model_path, self.train_loader, self.val_loader, self.optimizer, self.scheduler, self.num_epochs = (\n",
        "            lr, scaler, model, model_path, train_loader, val_loader, optimizer, scheduler, num_epochs\n",
        "        )\n",
        "            #    trainer = Trainer(lr, scaler, model, model_path, train_loader, val_loader, optimizer, scheduler = scheduler, num_epochs = epochs)\n",
        "    def train(self):\n",
        "        self.model.train()\n",
        "        \n",
        "        mse_loss = nn.MSELoss(reduction='mean')\n",
        "        \n",
        "        best_val_rmse = None\n",
        "        best_epoch = 0\n",
        "        step = 0\n",
        "        last_eval_step = 0\n",
        "        eval_period = cfg.EVAL_SCHEDULE[0][1]    \n",
        "\n",
        "        start = time.time()\n",
        "        val_rmse_list = []\n",
        "        \n",
        "        tbar = tqdm(range(self.num_epochs), total=self.num_epochs)\n",
        "        for epoch in tbar:\n",
        "            tbar.set_description(f'Epoch: {epoch}')\n",
        "            val_rmse = None\n",
        "            for batch_num, record in enumerate(self.train_loader):\n",
        "                input_ids, attention_mask, target = record['input_ids'].to(cfg.DEVICE), record['attention_mask'].to(cfg.DEVICE), record['target'].to(cfg.DEVICE)\n",
        "                \n",
        "                self.optimizer.zero_grad()\n",
        "                \n",
        "                # Casts operations to mixed precision\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    pred, _ = self.model(input_ids, attention_mask)\n",
        "                    mse = mse_loss(pred.flatten(), target)\n",
        "                    \n",
        "                self.scaler.scale(mse).backward()\n",
        "                self.scaler.step(self.optimizer)\n",
        "                self.scaler.update()\n",
        "                \n",
        "                if self.scheduler:\n",
        "                    self.scheduler.step()\n",
        "                    \n",
        "                if step >= last_eval_step + eval_period:\n",
        "                    elapsed_seconds = time.time() - start\n",
        "                    num_steps = step - last_eval_step\n",
        "                    print(f\"\\n{num_steps} steps took {elapsed_seconds:0.3} seconds\")\n",
        "                    last_eval_step = step\n",
        "                    \n",
        "                    val_rmse = np.sqrt(eval_mse(self.model, self.val_loader))\n",
        "                    print(f\"Epoch: {epoch} batch_num: {batch_num}\", f\"val_rmse: {val_rmse:0.4} \", end='')\n",
        "                    \n",
        "                    eval_period = choose_eval_period(val_rmse)\n",
        "                    best_epoch, best_val_rmse = serialize_best(best_val_rmse, best_epoch, val_rmse, epoch, self.model, self.model_path, self.lr)\n",
        "                    val_rmse_list.append(val_rmse)\n",
        "                    start = time.time()\n",
        "                # Finish early on condition\n",
        "                if epoch > 0 and best_val_rmse > 0.6 or (len(val_rmse_list) > 5 and np.array(val_rmse_list).mean() > 1.0):\n",
        "                    return best_val_rmse\n",
        "                \n",
        "                step += 1\n",
        "        return best_val_rmse"
      ],
      "id": "01766a88-69dc-4c6d-8dca-2950bdc7e231"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2692dcf2-a5b7-404f-bb07-3feecb6ec40e"
      },
      "outputs": [],
      "source": [
        "kfold = KFold(n_splits=cfg.NUM_FOLDS, random_state=cfg.SEED, shuffle=True)\n",
        "splits = list(kfold.split(train_df))"
      ],
      "id": "2692dcf2-a5b7-404f-bb07-3feecb6ec40e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6380179-d1bc-4102-b82f-73b7f8f1c5aa"
      },
      "source": [
        "### Optuna"
      ],
      "id": "d6380179-d1bc-4102-b82f-73b7f8f1c5aa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1f3b704f-b4e5-4b33-a33b-159ba8b5685b"
      },
      "outputs": [],
      "source": [
        "del sample_model\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "id": "1f3b704f-b4e5-4b33-a33b-159ba8b5685b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61471dbf-6953-4f76-a5ed-ca322f0bc541"
      },
      "outputs": [],
      "source": [
        "# Best results\n",
        "# Fold 0: { 'base_lr': 0.0001190683694379101, 'last_lr': 0.00017987585986205585, 'epochs': 4 } Best value: 0.49271923303604126\n",
        "# Fold 1: {'base_lr': 0.00012114635348406963, 'last_lr': 0.0005477206613438486, 'epochs': 4}. Best value:  0.45853328704833984\n",
        "# Fold 2: {'base_lr': 5.24730490640746e-05, 'last_lr': 0.00020041362261812433, 'epochs': 4}   Best value:  0.49088865518569946\n",
        "# Fold 3: {'base_lr': 6.108276630664184e-05, 'last_lr': 0.00011544056953737668, 'epochs': 4}. Best value:  0.4930591881275177\n",
        "# Fold 4: {'base_lr': 0.0001717178883932075, 'last_lr': 0.00042448836147656634, 'epochs': 4}  Best value:  0.48955243825912476\n",
        "# Fold 5: {'base_lr': 0.000135700916847811, 'last_lr': 0.0029640935672153, 'epochs': 4}.      Best value:  0.4688156247138977"
      ],
      "id": "61471dbf-6953-4f76-a5ed-ca322f0bc541"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1561a06c-a904-4056-8079-ba5cb737567c"
      },
      "outputs": [],
      "source": [
        "\n",
        "fold = 0\n",
        "\n",
        "def objective(trial):\n",
        "    epochs = 2  #4\n",
        "    #learning rate hyperparameter tuning, in this case for layer tuning in create_optimizer() above\n",
        "    base_lr = trial.suggest_float(\"base_lr\", 3e-5, 5e-4, log=True)\n",
        "    last_lr = trial.suggest_float(\"last_lr\", 8e-5, 5e-3, log=True)\n",
        "    lr = last_lr\n",
        "\n",
        "    #tuning lr scheduler hyperparameter\n",
        "    schedule_func = trial.suggest_categorical('schedule_func', [get_cosine_with_hard_restarts_schedule_with_warmup, get_cosine_schedule_with_warmup, get_linear_schedule_with_warmup])\n",
        "    \n",
        "    #tuning batch size hyperparameter\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [2, 4, 8])\n",
        "    \n",
        "    #tuning the optimizer hyperparameter\n",
        "    optimizer = trial.suggest_categorical(\"optimizer\", [\"adam\", \"adamw\"])\n",
        "\n",
        "    print(f'##### Using fold {fold}')\n",
        "    print(f'##### Using base_lr {base_lr} last_lr {last_lr} epochs {epochs}')\n",
        "    print(f'##### Using {schedule_func}')\n",
        "    \n",
        "    #model_path = cfg.MODEL_FOLDER + \"/\" + f\"{cfg.model_name.replace('/', '_')}_{fold + 1}/model_{fold + 1}.pth\"\n",
        "    model_path = \"/content/gdrive/My Drive/feedback-prize-english-language-learning/0917-deberta-v3-/microsoft-deberta-v3-base_fold2_best2.pth\"\n",
        "    print(\"Model path\")\n",
        "    print(model_path) #  /content/gdrive/My Drive/feedback-prize-english-language-learning/deberta-v3-base/deberta-v3-base_1/model_1.pth\n",
        "    \n",
        "    set_random_seed(cfg.SEED + fold)\n",
        "    \n",
        "    tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)\n",
        "    \n",
        "    train_indices, val_indices = splits[fold]\n",
        "    print(\"train_indices\")\n",
        "    print(len(train_indices))\n",
        "    print(type(train_indices))\n",
        "    train_dataset = CommonLitDataset(train_df.loc[train_indices], tokenizer) \n",
        "    print(\"train_dataset\")\n",
        "    print(len(train_dataset)) \n",
        "    print(type(train_dataset))  \n",
        "    val_dataset = CommonLitDataset(train_df.loc[val_indices], tokenizer)\n",
        "    print(\"val_dataset\")\n",
        "    print(len(val_dataset))\n",
        "    print(type(val_dataset))\n",
        "    \n",
        "    train_loader = DataLoader(train_dataset, batch_size=cfg.BATCH_SIZE, drop_last=False, shuffle=True, num_workers=cfg.NUM_WORKERS)    \n",
        "    val_loader = DataLoader(val_dataset, batch_size=cfg.BATCH_SIZE, drop_last=False, shuffle=False, num_workers=cfg.NUM_WORKERS)\n",
        "    \n",
        "    model = CommonLitModel().to(cfg.DEVICE)\n",
        "    #print(model.config)\n",
        "    \n",
        "    optimizer = create_optimizer(model, base_lr=base_lr, last_lr=last_lr)\n",
        "    \n",
        "    scheduler = schedule_func(optimizer, num_training_steps=cfg.NUM_EPOCHS * len(train_loader), num_warmup_steps=50) #num_warmup_steps=50\n",
        "    scaler = torch.cuda.amp.GradScaler() # fp16\n",
        "\n",
        "    \n",
        "    trainer = Trainer(lr, scaler, model, model_path, train_loader, val_loader, optimizer, scheduler = scheduler, num_epochs = epochs)\n",
        "    rmse_val = trainer.train()\n",
        "\n",
        "    # Handle pruning based on the intermediate value.\n",
        "    if trial.should_prune():\n",
        "      raise optuna.exceptions.TrialPruned()\n",
        "    \n",
        "    del trainer\n",
        "    del model\n",
        "    del tokenizer\n",
        "    del scaler\n",
        "    del optimizer\n",
        "    del train_loader\n",
        "    del val_loader\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    return rmse_val #return learning rate also"
      ],
      "id": "1561a06c-a904-4056-8079-ba5cb737567c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0cd54542f16b4b789593db716088db30",
            "6f99cafc22a84eefa4779cf58f7c4645",
            "1fa142239bde4480b2dd4e1e1f124f0f",
            "db4587a905df42fa8dca0a269ea25f9f",
            "9e52ecf6f0f04f69a2105e7c267d9583",
            "ce3599bd3a3745cc954d3f63c18f86b9",
            "9526d7e3421f4cb199f1de7f074f204e",
            "4ab7129032b64ef8bfc832f12a0ffea8",
            "3bf8f0f7c315454195e35e3448ebd7bd",
            "a23a2041e4b34db4bcc5c8aaea4e3bf6",
            "ef7d650c9e3c4afdbbcc11f71053d765",
            "ff88504b2ae8430d99fe12885723ecca",
            "e77fbcc105de449e914293ebdad64bb3",
            "37953eebe35c468d8b73157f8d9eb74e",
            "5a4e67dc9ed54b978b602964e0fcc37b",
            "d22aba869ff14c5ba39412874b935752",
            "ff38cc3b284d4127b4ca316075d70a61",
            "03609fd9407b4cad819897205be25795",
            "cc3ad48f882b4b3baa6e6ad675427d0d",
            "d6bd007881764222a2db1376740caaa1",
            "b34b340693064ecca93d7ead7cee8ceb",
            "d3dd42c03e3a42cb97a4cb004b428488",
            "55772880edde46a3a9d2992e54494d9c",
            "185db4e3c9084cae8e41ce5f2eb0f998",
            "556dd0c57a4d4a029249b5a83315f443",
            "b1cdec34663e4bd08ad1c6eb18371a8d",
            "bbbf4981209f4f7e8a008a150998e6b7",
            "aacc28cb283e4d3289a748a01229bd2b",
            "1fff40feb71b45db83ac74a8bce54791",
            "a3c8adbee3854af8a18ab1cf97961771",
            "dddbc1880ea54efeb49fbd50a2158e96",
            "e86a130bec0a470d8e5af821882a844d",
            "9e16f5966b66472788de79a3173523a3",
            "68ca7b2b2f144b85ac90501bc7aebaf5",
            "9abef67aacd84158aaebacf4d4b89df9",
            "3dd04e53ab6746dca3475b6309ede9b8",
            "129ea341968249f3a35f724becf88170",
            "60e4cc85bebd4a6ca2c3cc8dc38fa821",
            "ec4968332c2b46049aeefacfa7a23bb0",
            "781504b638fd4acb842a2b5dfe8aa78e",
            "ca8d7c27dd8042bbb3e425a929cf4a3c",
            "bf0eea23318448cea384c260e92b1e46",
            "1541432391394fbfaceed522a55765ee",
            "fda6ebbb48504b4d8d73e01e886d70b5",
            "09c05d2b5f0c409da17eef91f70f1fbd",
            "bd811ff4fb3c4cd593ab75229ba2f269",
            "ab0fc8272b7343ab8dfd6e3e5419977c",
            "e679cdd86c584f1b9281bf9f7f84a4c3",
            "23dae928bb1341f2aa5031366d688672",
            "2e47ec956d864448afbacc2ab375f51b",
            "3c88df238991414e8204a1916a0bc0e1",
            "6666ed7f91884d0e85653271f9acb21d",
            "a97301ffca414a78b00271fdeb4d075d",
            "00362774a3a4483db0058e3191a6fdaa",
            "7e5a3a5c30c24f829d020d80e94b037c",
            "79a0f371b4cc442fa91b285bd6863379",
            "7ddf538ebfeb42fbad51fb556aa6b62f",
            "67a3efc5d6ee481fa8f25b136189aaf7",
            "729e27f0c98d432f80bb17c19293d1e0",
            "eedd5ce0d4b647ce828ae3bf464e834d",
            "949b0c7987a24859ad0413c4c48c6fc1",
            "ecb3cdecfa194e88b32aefb9067b2391",
            "23cf86c20fe948d1adadb10869da011b",
            "da54eab21c334c2dbff5643b5931e12b",
            "c9074be9404a4b24bdf35c9dad6ebe69",
            "194c1be7078f42f385db452af1f4ad46",
            "049f4adc9edc4613bcff8006daebb070",
            "c3756d81f5ce4bf9b7b65255fbb16ccb",
            "62760582ede2419ea52aad9f0581ce32",
            "9e3c0e794b6b4a05a2b820e9a0fcb7ab",
            "d9ae0f8c8031415a9b41b484df58045d",
            "8411e93e873f47e396990618831abba9",
            "7ca07fc91670451d9bc4e78ee8751b77",
            "f41cffe82a1844b883b107f114a259c5",
            "10b2836914a4405d9bfa766baff8733d",
            "406f354626ca4ad89ebbb86af233583f",
            "f6f9cf838fbb4f469fe67f9cd0775f61",
            "0434489585be42b9adab9b7d0e2b86f2",
            "4530e3a2fcc64f9d85f8a823772c6c03",
            "9d00213a02354271b33fe6416f990f3c",
            "7fa41932901a4ba9ab438db021c13ab6",
            "2fea71869441416d91ec8e1ada11a682",
            "38a90602ba284c23b7270815ff1d9086",
            "14738aafc055462ab3f8420fb383870f",
            "dff8e3f4e3ec40b89c1ec35390af2bb7",
            "93bd77ff2869409593704a5fb7813019",
            "ffe99fe880254b9cb3d530a313ca2b0e",
            "0afeb7cb684f4bf0a715bc3f24df4c12",
            "acf1a21b13ed4ad0b418cbcde0a4b968",
            "513ca98be4eb4231a1adea0ee9c6e32a",
            "e451df8b02ac4e47a708672b61d77b1a",
            "a01232dfb9d8429298563a31fb2cfdb6",
            "5dffd65ae28d42e3ac52a7e1cac29d80",
            "5351f0094377416abff31dea69238172",
            "0f8c22cbc7f844d79e9a69f3a03865e2",
            "61c31ae9ad51412b8951146fd0f65903",
            "24947296fee143ecbbe05a4f88f96016",
            "1a269e972116429891a4b24c45b7150c",
            "12a85a5381104dd3b02dd939602c7466"
          ]
        },
        "id": "48210ee3-d9ea-4bab-b852-627f6f75ce0c",
        "outputId": "0e244664-4c87-4eba-ded2-196ae8a09306"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-09-23 03:25:30,055]\u001b[0m A new study created in memory with name: no-name-4d9a26be-ab94-42f1-bd4b-d8748943a233\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "##### Using fold 0\n",
            "##### Using base_lr 3.577643544798571e-05 last_lr 0.0015857753780737184 epochs 2\n",
            "##### Using <function get_cosine_with_hard_restarts_schedule_with_warmup at 0x7fb51fd03680>\n",
            "Model path\n",
            "/content/gdrive/My Drive/feedback-prize-english-language-learning/0917-deberta-v3-/microsoft-deberta-v3-base_fold2_best2.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_indices\n",
            "3259\n",
            "<class 'numpy.ndarray'>\n",
            "train_dataset\n",
            "3259\n",
            "<class '__main__.CommonLitDataset'>\n",
            "val_dataset\n",
            "652\n",
            "<class '__main__.CommonLitDataset'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /content/gdrive/My Drive/feedback-prize-english-language-learning/deberta-v3-base were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias']\n",
            "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at /content/gdrive/My Drive/feedback-prize-english-language-learning/deberta-v3-base and are newly initialized: ['classifier.bias', 'pooler.dense.weight', 'classifier.weight', 'pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0cd54542f16b4b789593db716088db30",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "16 steps took 12.3 seconds\n",
            "Epoch: 0 batch_num: 16 val_rmse: 1.019 New best_val_rmse: 1.019\n",
            "\n",
            "16 steps took 10.3 seconds\n",
            "Epoch: 0 batch_num: 32 val_rmse: 0.609 New best_val_rmse: 0.609\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 48 val_rmse: 0.5471 New best_val_rmse: 0.5471\n",
            "\n",
            "16 steps took 10.3 seconds\n",
            "Epoch: 0 batch_num: 64 val_rmse: 0.4866 New best_val_rmse: 0.4866\n",
            "\n",
            "4 steps took 2.55 seconds\n",
            "Epoch: 0 batch_num: 68 val_rmse: 0.5889 Still best_val_rmse: 0.4866 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 84 val_rmse: 0.5365 Still best_val_rmse: 0.4866 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 100 val_rmse: 0.4761 New best_val_rmse: 0.4761\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 0 batch_num: 102 val_rmse: 0.4838 Still best_val_rmse: 0.4761 (from epoch 0)\n",
            "\n",
            "4 steps took 2.55 seconds\n",
            "Epoch: 0 batch_num: 106 val_rmse: 0.522 Still best_val_rmse: 0.4761 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 122 val_rmse: 0.6181 Still best_val_rmse: 0.4761 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 138 val_rmse: 0.4726 New best_val_rmse: 0.4726\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 0 batch_num: 140 val_rmse: 0.566 Still best_val_rmse: 0.4726 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 156 val_rmse: 0.4503 New best_val_rmse: 0.4503\n",
            "\n",
            "1 steps took 0.643 seconds\n",
            "Epoch: 0 batch_num: 157 val_rmse: 0.4535 Still best_val_rmse: 0.4503 (from epoch 0)\n",
            "\n",
            "1 steps took 0.653 seconds\n",
            "Epoch: 0 batch_num: 158 val_rmse: 0.4527 Still best_val_rmse: 0.4503 (from epoch 0)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 0 batch_num: 159 val_rmse: 0.4687 Still best_val_rmse: 0.4503 (from epoch 0)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 0 batch_num: 160 val_rmse: 0.4609 Still best_val_rmse: 0.4503 (from epoch 0)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 0 batch_num: 161 val_rmse: 0.4571 Still best_val_rmse: 0.4503 (from epoch 0)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 0 batch_num: 162 val_rmse: 0.4482 New best_val_rmse: 0.4482\n",
            "\n",
            "1 steps took 0.641 seconds\n",
            "Epoch: 0 batch_num: 163 val_rmse: 0.4536 Still best_val_rmse: 0.4482 (from epoch 0)\n",
            "\n",
            "1 steps took 0.657 seconds\n",
            "Epoch: 0 batch_num: 164 val_rmse: 0.4479 New best_val_rmse: 0.4479\n",
            "\n",
            "1 steps took 0.656 seconds\n",
            "Epoch: 0 batch_num: 165 val_rmse: 0.4522 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 0 batch_num: 166 val_rmse: 0.4499 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "1 steps took 0.631 seconds\n",
            "Epoch: 0 batch_num: 167 val_rmse: 0.4597 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 0 batch_num: 168 val_rmse: 0.4704 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 0 batch_num: 170 val_rmse: 0.4502 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "1 steps took 0.632 seconds\n",
            "Epoch: 0 batch_num: 171 val_rmse: 0.4486 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 0 batch_num: 172 val_rmse: 0.4512 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 0 batch_num: 173 val_rmse: 0.4744 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 0 batch_num: 175 val_rmse: 0.53 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 191 val_rmse: 0.4614 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 0 batch_num: 192 val_rmse: 0.4727 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 0 batch_num: 194 val_rmse: 0.5048 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 210 val_rmse: 0.4585 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 0 batch_num: 211 val_rmse: 0.4546 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 0 batch_num: 212 val_rmse: 0.4541 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 0 batch_num: 213 val_rmse: 0.4625 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 0 batch_num: 214 val_rmse: 0.4655 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 0 batch_num: 215 val_rmse: 0.4549 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 0 batch_num: 216 val_rmse: 0.455 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 0 batch_num: 217 val_rmse: 0.4897 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "4 steps took 2.55 seconds\n",
            "Epoch: 0 batch_num: 221 val_rmse: 0.4872 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "4 steps took 2.55 seconds\n",
            "Epoch: 0 batch_num: 225 val_rmse: 0.7641 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 241 val_rmse: 0.6707 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 257 val_rmse: 0.5335 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 273 val_rmse: 0.5777 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 289 val_rmse: 0.4499 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 0 batch_num: 290 val_rmse: 0.4801 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "4 steps took 2.55 seconds\n",
            "Epoch: 0 batch_num: 294 val_rmse: 0.523 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 310 val_rmse: 0.4815 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "4 steps took 2.55 seconds\n",
            "Epoch: 0 batch_num: 314 val_rmse: 0.4733 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 0 batch_num: 316 val_rmse: 0.4563 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 0 batch_num: 317 val_rmse: 0.4479 New best_val_rmse: 0.4479\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 0 batch_num: 318 val_rmse: 0.5061 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 334 val_rmse: 0.4551 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 0 batch_num: 335 val_rmse: 0.5045 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 351 val_rmse: 0.5184 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 367 val_rmse: 0.4534 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 0 batch_num: 368 val_rmse: 0.4875 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "4 steps took 2.55 seconds\n",
            "Epoch: 0 batch_num: 372 val_rmse: 0.508 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 388 val_rmse: 0.4581 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 0 batch_num: 389 val_rmse: 0.465 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 0 batch_num: 390 val_rmse: 0.463 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 0 batch_num: 391 val_rmse: 0.4573 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "1 steps took 0.64 seconds\n",
            "Epoch: 0 batch_num: 392 val_rmse: 0.4565 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "1 steps took 0.641 seconds\n",
            "Epoch: 0 batch_num: 393 val_rmse: 0.4521 Still best_val_rmse: 0.4479 (from epoch 0)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 0 batch_num: 394 val_rmse: 0.4459 New best_val_rmse: 0.4459\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 0 batch_num: 395 val_rmse: 0.444 New best_val_rmse: 0.444\n",
            "\n",
            "1 steps took 0.649 seconds\n",
            "Epoch: 0 batch_num: 396 val_rmse: 0.4444 Still best_val_rmse: 0.444 (from epoch 0)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 0 batch_num: 397 val_rmse: 0.4566 Still best_val_rmse: 0.444 (from epoch 0)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 0 batch_num: 398 val_rmse: 0.4717 Still best_val_rmse: 0.444 (from epoch 0)\n",
            "\n",
            "2 steps took 1.28 seconds\n",
            "Epoch: 0 batch_num: 400 val_rmse: 0.4524 Still best_val_rmse: 0.444 (from epoch 0)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 0 batch_num: 401 val_rmse: 0.4423 New best_val_rmse: 0.4423\n",
            "\n",
            "1 steps took 0.642 seconds\n",
            "Epoch: 0 batch_num: 402 val_rmse: 0.4551 Still best_val_rmse: 0.4423 (from epoch 0)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 0 batch_num: 403 val_rmse: 0.4967 Still best_val_rmse: 0.4423 (from epoch 0)\n",
            "\n",
            "8 steps took 5.16 seconds\n",
            "Epoch: 1 batch_num: 3 val_rmse: 0.477 Still best_val_rmse: 0.4423 (from epoch 0)\n",
            "\n",
            "2 steps took 1.28 seconds\n",
            "Epoch: 1 batch_num: 5 val_rmse: 0.4449 Still best_val_rmse: 0.4423 (from epoch 0)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 6 val_rmse: 0.4391 New best_val_rmse: 0.4391\n",
            "\n",
            "1 steps took 0.654 seconds\n",
            "Epoch: 1 batch_num: 7 val_rmse: 0.4483 Still best_val_rmse: 0.4391 (from epoch 1)\n",
            "\n",
            "1 steps took 0.631 seconds\n",
            "Epoch: 1 batch_num: 8 val_rmse: 0.4623 Still best_val_rmse: 0.4391 (from epoch 1)\n",
            "\n",
            "1 steps took 0.642 seconds\n",
            "Epoch: 1 batch_num: 9 val_rmse: 0.4601 Still best_val_rmse: 0.4391 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 10 val_rmse: 0.4437 Still best_val_rmse: 0.4391 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 11 val_rmse: 0.4377 New best_val_rmse: 0.4377\n",
            "\n",
            "1 steps took 0.64 seconds\n",
            "Epoch: 1 batch_num: 12 val_rmse: 0.4385 Still best_val_rmse: 0.4377 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 13 val_rmse: 0.4376 New best_val_rmse: 0.4376\n",
            "\n",
            "1 steps took 0.656 seconds\n",
            "Epoch: 1 batch_num: 14 val_rmse: 0.4369 New best_val_rmse: 0.4369\n",
            "\n",
            "1 steps took 0.641 seconds\n",
            "Epoch: 1 batch_num: 15 val_rmse: 0.4383 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 16 val_rmse: 0.4466 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 17 val_rmse: 0.4629 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 18 val_rmse: 0.4592 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 19 val_rmse: 0.4412 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 20 val_rmse: 0.4389 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 21 val_rmse: 0.4411 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 22 val_rmse: 0.4427 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 23 val_rmse: 0.4563 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 24 val_rmse: 0.4788 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 26 val_rmse: 0.4815 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "4 steps took 2.54 seconds\n",
            "Epoch: 1 batch_num: 30 val_rmse: 0.4672 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 31 val_rmse: 0.4839 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "4 steps took 2.54 seconds\n",
            "Epoch: 1 batch_num: 35 val_rmse: 0.516 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 1 batch_num: 51 val_rmse: 0.4421 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 52 val_rmse: 0.4574 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 53 val_rmse: 0.4617 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 54 val_rmse: 0.4442 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 55 val_rmse: 0.4422 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 56 val_rmse: 0.4683 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 57 val_rmse: 0.4682 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 58 val_rmse: 0.4547 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 59 val_rmse: 0.4437 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 60 val_rmse: 0.4386 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 61 val_rmse: 0.4439 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 62 val_rmse: 0.4478 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 63 val_rmse: 0.4616 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 64 val_rmse: 0.4856 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "4 steps took 2.54 seconds\n",
            "Epoch: 1 batch_num: 68 val_rmse: 0.6024 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 1 batch_num: 84 val_rmse: 0.5284 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 1 batch_num: 100 val_rmse: 0.4511 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.641 seconds\n",
            "Epoch: 1 batch_num: 101 val_rmse: 0.4414 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 102 val_rmse: 0.4425 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 103 val_rmse: 0.4465 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.632 seconds\n",
            "Epoch: 1 batch_num: 104 val_rmse: 0.4453 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 105 val_rmse: 0.4421 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 106 val_rmse: 0.4406 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 107 val_rmse: 0.4398 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 108 val_rmse: 0.4399 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 109 val_rmse: 0.4416 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 110 val_rmse: 0.4438 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 111 val_rmse: 0.441 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 112 val_rmse: 0.437 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 113 val_rmse: 0.4369 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 114 val_rmse: 0.4377 Still best_val_rmse: 0.4369 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 115 val_rmse: 0.436 New best_val_rmse: 0.436\n",
            "\n",
            "1 steps took 0.645 seconds\n",
            "Epoch: 1 batch_num: 116 val_rmse: 0.44 Still best_val_rmse: 0.436 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 117 val_rmse: 0.45 Still best_val_rmse: 0.436 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 118 val_rmse: 0.4494 Still best_val_rmse: 0.436 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 119 val_rmse: 0.443 Still best_val_rmse: 0.436 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 120 val_rmse: 0.4436 Still best_val_rmse: 0.436 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 121 val_rmse: 0.4434 Still best_val_rmse: 0.436 (from epoch 1)\n",
            "\n",
            "1 steps took 0.645 seconds\n",
            "Epoch: 1 batch_num: 122 val_rmse: 0.4335 New best_val_rmse: 0.4335\n",
            "\n",
            "1 steps took 0.658 seconds\n",
            "Epoch: 1 batch_num: 123 val_rmse: 0.4364 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 124 val_rmse: 0.4349 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 125 val_rmse: 0.4361 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 126 val_rmse: 0.4562 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 127 val_rmse: 0.4723 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 129 val_rmse: 0.4422 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 130 val_rmse: 0.4366 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.641 seconds\n",
            "Epoch: 1 batch_num: 131 val_rmse: 0.4521 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 132 val_rmse: 0.4766 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 134 val_rmse: 0.5107 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 1 batch_num: 150 val_rmse: 0.4663 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 151 val_rmse: 0.4695 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 152 val_rmse: 0.4431 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 153 val_rmse: 0.4357 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 154 val_rmse: 0.44 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.641 seconds\n",
            "Epoch: 1 batch_num: 155 val_rmse: 0.4492 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.631 seconds\n",
            "Epoch: 1 batch_num: 156 val_rmse: 0.447 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 157 val_rmse: 0.4427 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 158 val_rmse: 0.4446 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 159 val_rmse: 0.441 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 160 val_rmse: 0.4401 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 161 val_rmse: 0.4409 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 162 val_rmse: 0.4422 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 163 val_rmse: 0.4424 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 164 val_rmse: 0.4475 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.631 seconds\n",
            "Epoch: 1 batch_num: 165 val_rmse: 0.4651 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.63 seconds\n",
            "Epoch: 1 batch_num: 166 val_rmse: 0.4817 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "4 steps took 2.55 seconds\n",
            "Epoch: 1 batch_num: 170 val_rmse: 0.4404 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 171 val_rmse: 0.4386 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 172 val_rmse: 0.4395 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.642 seconds\n",
            "Epoch: 1 batch_num: 173 val_rmse: 0.437 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 174 val_rmse: 0.4439 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.641 seconds\n",
            "Epoch: 1 batch_num: 175 val_rmse: 0.4644 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 176 val_rmse: 0.4861 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "4 steps took 2.54 seconds\n",
            "Epoch: 1 batch_num: 180 val_rmse: 0.4511 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.632 seconds\n",
            "Epoch: 1 batch_num: 181 val_rmse: 0.4854 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "4 steps took 2.55 seconds\n",
            "Epoch: 1 batch_num: 185 val_rmse: 0.4919 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "8 steps took 5.1 seconds\n",
            "Epoch: 1 batch_num: 193 val_rmse: 0.4504 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 194 val_rmse: 0.4624 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 195 val_rmse: 0.4921 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "8 steps took 5.11 seconds\n",
            "Epoch: 1 batch_num: 203 val_rmse: 0.4438 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 204 val_rmse: 0.441 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 205 val_rmse: 0.4404 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 206 val_rmse: 0.4433 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 207 val_rmse: 0.4404 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.632 seconds\n",
            "Epoch: 1 batch_num: 208 val_rmse: 0.44 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 209 val_rmse: 0.4397 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.643 seconds\n",
            "Epoch: 1 batch_num: 210 val_rmse: 0.4379 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 211 val_rmse: 0.4383 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 212 val_rmse: 0.4419 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.631 seconds\n",
            "Epoch: 1 batch_num: 213 val_rmse: 0.4432 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.632 seconds\n",
            "Epoch: 1 batch_num: 214 val_rmse: 0.4407 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.63 seconds\n",
            "Epoch: 1 batch_num: 215 val_rmse: 0.4413 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 216 val_rmse: 0.4415 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 217 val_rmse: 0.4399 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.631 seconds\n",
            "Epoch: 1 batch_num: 218 val_rmse: 0.4405 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 219 val_rmse: 0.4379 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 220 val_rmse: 0.4387 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 221 val_rmse: 0.4416 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 222 val_rmse: 0.4488 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 223 val_rmse: 0.4572 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 224 val_rmse: 0.4597 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 225 val_rmse: 0.4626 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 226 val_rmse: 0.4487 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 227 val_rmse: 0.4436 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 228 val_rmse: 0.4432 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 229 val_rmse: 0.449 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 230 val_rmse: 0.4597 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 231 val_rmse: 0.4729 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 233 val_rmse: 0.4651 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 234 val_rmse: 0.4649 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 235 val_rmse: 0.4627 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 236 val_rmse: 0.4584 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 237 val_rmse: 0.4445 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 238 val_rmse: 0.438 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 239 val_rmse: 0.4447 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.646 seconds\n",
            "Epoch: 1 batch_num: 240 val_rmse: 0.4498 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.64 seconds\n",
            "Epoch: 1 batch_num: 241 val_rmse: 0.4537 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.64 seconds\n",
            "Epoch: 1 batch_num: 242 val_rmse: 0.4473 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 243 val_rmse: 0.438 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 244 val_rmse: 0.4556 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 245 val_rmse: 0.4982 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "8 steps took 5.09 seconds\n",
            "Epoch: 1 batch_num: 253 val_rmse: 0.4871 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "4 steps took 2.54 seconds\n",
            "Epoch: 1 batch_num: 257 val_rmse: 0.4574 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 258 val_rmse: 0.468 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 259 val_rmse: 0.4747 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 261 val_rmse: 0.4613 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.631 seconds\n",
            "Epoch: 1 batch_num: 262 val_rmse: 0.459 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 263 val_rmse: 0.459 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 264 val_rmse: 0.4537 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 265 val_rmse: 0.4511 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 266 val_rmse: 0.4593 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 267 val_rmse: 0.4761 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 269 val_rmse: 0.5144 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 1 batch_num: 285 val_rmse: 0.4638 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.64 seconds\n",
            "Epoch: 1 batch_num: 286 val_rmse: 0.4711 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "2 steps took 1.28 seconds\n",
            "Epoch: 1 batch_num: 288 val_rmse: 0.4613 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 289 val_rmse: 0.4454 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 290 val_rmse: 0.4421 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 291 val_rmse: 0.4578 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 292 val_rmse: 0.4836 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "4 steps took 2.55 seconds\n",
            "Epoch: 1 batch_num: 296 val_rmse: 0.4944 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "8 steps took 5.1 seconds\n",
            "Epoch: 1 batch_num: 304 val_rmse: 0.4486 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 305 val_rmse: 0.4532 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 306 val_rmse: 0.4621 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 307 val_rmse: 0.4603 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 308 val_rmse: 0.4621 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 309 val_rmse: 0.4684 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.643 seconds\n",
            "Epoch: 1 batch_num: 310 val_rmse: 0.469 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 311 val_rmse: 0.4556 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 312 val_rmse: 0.4504 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 313 val_rmse: 0.4474 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.631 seconds\n",
            "Epoch: 1 batch_num: 314 val_rmse: 0.4474 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.64 seconds\n",
            "Epoch: 1 batch_num: 315 val_rmse: 0.4451 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 316 val_rmse: 0.4411 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 317 val_rmse: 0.4423 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 318 val_rmse: 0.4449 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 319 val_rmse: 0.4431 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 320 val_rmse: 0.4414 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 321 val_rmse: 0.4423 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 322 val_rmse: 0.4504 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.632 seconds\n",
            "Epoch: 1 batch_num: 323 val_rmse: 0.4615 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 324 val_rmse: 0.4494 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 325 val_rmse: 0.443 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 326 val_rmse: 0.4408 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 327 val_rmse: 0.4439 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 328 val_rmse: 0.4501 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 329 val_rmse: 0.4555 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 330 val_rmse: 0.4678 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 331 val_rmse: 0.4588 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.64 seconds\n",
            "Epoch: 1 batch_num: 332 val_rmse: 0.4527 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.632 seconds\n",
            "Epoch: 1 batch_num: 333 val_rmse: 0.4458 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 334 val_rmse: 0.4412 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 335 val_rmse: 0.4437 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 336 val_rmse: 0.4537 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.632 seconds\n",
            "Epoch: 1 batch_num: 337 val_rmse: 0.4683 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 338 val_rmse: 0.4731 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 340 val_rmse: 0.4539 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.642 seconds\n",
            "Epoch: 1 batch_num: 341 val_rmse: 0.4447 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 342 val_rmse: 0.4451 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 343 val_rmse: 0.4625 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 344 val_rmse: 0.4728 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 346 val_rmse: 0.4608 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 347 val_rmse: 0.4547 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 348 val_rmse: 0.4469 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 349 val_rmse: 0.4418 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 350 val_rmse: 0.441 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 351 val_rmse: 0.4449 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 352 val_rmse: 0.4507 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 353 val_rmse: 0.4552 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 354 val_rmse: 0.4583 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 355 val_rmse: 0.4483 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 356 val_rmse: 0.4395 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.63 seconds\n",
            "Epoch: 1 batch_num: 357 val_rmse: 0.4379 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 358 val_rmse: 0.4391 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 359 val_rmse: 0.4408 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 360 val_rmse: 0.4454 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.632 seconds\n",
            "Epoch: 1 batch_num: 361 val_rmse: 0.4552 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 362 val_rmse: 0.4572 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 363 val_rmse: 0.451 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 364 val_rmse: 0.442 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 365 val_rmse: 0.4382 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 366 val_rmse: 0.4432 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.632 seconds\n",
            "Epoch: 1 batch_num: 367 val_rmse: 0.452 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 368 val_rmse: 0.4572 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 369 val_rmse: 0.4542 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 370 val_rmse: 0.4494 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.64 seconds\n",
            "Epoch: 1 batch_num: 371 val_rmse: 0.4436 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 372 val_rmse: 0.441 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 373 val_rmse: 0.4397 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 374 val_rmse: 0.4405 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 375 val_rmse: 0.4415 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 376 val_rmse: 0.4425 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 377 val_rmse: 0.4444 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 378 val_rmse: 0.4471 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 379 val_rmse: 0.4503 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 380 val_rmse: 0.452 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 381 val_rmse: 0.4488 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 382 val_rmse: 0.45 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 383 val_rmse: 0.4499 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 384 val_rmse: 0.4509 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 385 val_rmse: 0.4517 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 386 val_rmse: 0.4576 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 387 val_rmse: 0.4675 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 388 val_rmse: 0.4644 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 389 val_rmse: 0.4545 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 390 val_rmse: 0.4461 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 391 val_rmse: 0.4405 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 392 val_rmse: 0.4395 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.642 seconds\n",
            "Epoch: 1 batch_num: 393 val_rmse: 0.4409 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 394 val_rmse: 0.4507 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 395 val_rmse: 0.4551 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 396 val_rmse: 0.4567 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 397 val_rmse: 0.4598 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 398 val_rmse: 0.4514 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 399 val_rmse: 0.4434 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 400 val_rmse: 0.4406 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 401 val_rmse: 0.4405 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 402 val_rmse: 0.444 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 403 val_rmse: 0.4521 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.64 seconds\n",
            "Epoch: 1 batch_num: 404 val_rmse: 0.4598 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 405 val_rmse: 0.4675 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 406 val_rmse: 0.4532 Still best_val_rmse: 0.4335 (from epoch 1)\n",
            "\n",
            "1 steps took 0.294 seconds\n",
            "Epoch: 1 batch_num: 407 val_rmse: 0.441 Still best_val_rmse: 0.4335 (from epoch 1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-09-23 05:23:45,709]\u001b[0m Trial 0 finished with value: 0.4334683418273926 and parameters: {'base_lr': 3.577643544798571e-05, 'last_lr': 0.0015857753780737184, 'schedule_func': <function get_cosine_with_hard_restarts_schedule_with_warmup at 0x7fb51fd03680>, 'batch_size': 2, 'optimizer': 'adam'}. Best is trial 0 with value: 0.4334683418273926.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "##### Using fold 0\n",
            "##### Using base_lr 0.0004919224821358357 last_lr 0.000976393727357976 epochs 2\n",
            "##### Using <function get_linear_schedule_with_warmup at 0x7fb51fd03560>\n",
            "Model path\n",
            "/content/gdrive/My Drive/feedback-prize-english-language-learning/0917-deberta-v3-/microsoft-deberta-v3-base_fold2_best2.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_indices\n",
            "3259\n",
            "<class 'numpy.ndarray'>\n",
            "train_dataset\n",
            "3259\n",
            "<class '__main__.CommonLitDataset'>\n",
            "val_dataset\n",
            "652\n",
            "<class '__main__.CommonLitDataset'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /content/gdrive/My Drive/feedback-prize-english-language-learning/deberta-v3-base were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias']\n",
            "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at /content/gdrive/My Drive/feedback-prize-english-language-learning/deberta-v3-base and are newly initialized: ['classifier.bias', 'pooler.dense.weight', 'classifier.weight', 'pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff88504b2ae8430d99fe12885723ecca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "16 steps took 11.8 seconds\n",
            "Epoch: 0 batch_num: 16 val_rmse: 0.6536 New best_val_rmse: 0.6536\n",
            "\n",
            "16 steps took 10.3 seconds\n",
            "Epoch: 0 batch_num: 32 val_rmse: 0.9906 Still best_val_rmse: 0.6536 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 48 val_rmse: 0.6377 New best_val_rmse: 0.6377\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 64 val_rmse: 0.6473 Still best_val_rmse: 0.6377 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 80 val_rmse: 0.6173 New best_val_rmse: 0.6173\n",
            "\n",
            "16 steps took 10.3 seconds\n",
            "Epoch: 0 batch_num: 96 val_rmse: 0.6399 Still best_val_rmse: 0.6173 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 112 val_rmse: 0.6395 Still best_val_rmse: 0.6173 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 128 val_rmse: 0.6391 Still best_val_rmse: 0.6173 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 144 val_rmse: 0.6411 Still best_val_rmse: 0.6173 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 160 val_rmse: 0.628 Still best_val_rmse: 0.6173 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 176 val_rmse: 0.6182 Still best_val_rmse: 0.6173 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 192 val_rmse: 0.629 Still best_val_rmse: 0.6173 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 208 val_rmse: 0.6805 Still best_val_rmse: 0.6173 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 224 val_rmse: 0.6485 Still best_val_rmse: 0.6173 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 240 val_rmse: 0.6899 Still best_val_rmse: 0.6173 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 256 val_rmse: 0.6491 Still best_val_rmse: 0.6173 (from epoch 0)\n",
            "\n",
            "16 steps took 9.99 seconds\n",
            "Epoch: 0 batch_num: 272 val_rmse: 0.7148 Still best_val_rmse: 0.6173 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 288 val_rmse: 0.6533 Still best_val_rmse: 0.6173 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 304 val_rmse: 0.6439 Still best_val_rmse: 0.6173 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 320 val_rmse: 0.6567 Still best_val_rmse: 0.6173 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 336 val_rmse: 0.6403 Still best_val_rmse: 0.6173 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 352 val_rmse: 0.6921 Still best_val_rmse: 0.6173 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 368 val_rmse: 0.6433 Still best_val_rmse: 0.6173 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 384 val_rmse: 0.6484 Still best_val_rmse: 0.6173 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 400 val_rmse: 0.64 Still best_val_rmse: 0.6173 (from epoch 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-09-23 05:36:14,991]\u001b[0m Trial 1 finished with value: 0.6173365712165833 and parameters: {'base_lr': 0.0004919224821358357, 'last_lr': 0.000976393727357976, 'schedule_func': <function get_linear_schedule_with_warmup at 0x7fb51fd03560>, 'batch_size': 4, 'optimizer': 'adamw'}. Best is trial 0 with value: 0.4334683418273926.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "##### Using fold 0\n",
            "##### Using base_lr 0.00032909656093660627 last_lr 0.00015543854935066984 epochs 2\n",
            "##### Using <function get_linear_schedule_with_warmup at 0x7fb51fd03560>\n",
            "Model path\n",
            "/content/gdrive/My Drive/feedback-prize-english-language-learning/0917-deberta-v3-/microsoft-deberta-v3-base_fold2_best2.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_indices\n",
            "3259\n",
            "<class 'numpy.ndarray'>\n",
            "train_dataset\n",
            "3259\n",
            "<class '__main__.CommonLitDataset'>\n",
            "val_dataset\n",
            "652\n",
            "<class '__main__.CommonLitDataset'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /content/gdrive/My Drive/feedback-prize-english-language-learning/deberta-v3-base were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias']\n",
            "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at /content/gdrive/My Drive/feedback-prize-english-language-learning/deberta-v3-base and are newly initialized: ['classifier.bias', 'pooler.dense.weight', 'classifier.weight', 'pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55772880edde46a3a9d2992e54494d9c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "16 steps took 11.7 seconds\n",
            "Epoch: 0 batch_num: 16 val_rmse: 0.7159 New best_val_rmse: 0.7159\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 32 val_rmse: 1.021 Still best_val_rmse: 0.7159 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 48 val_rmse: 0.609 New best_val_rmse: 0.609\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 64 val_rmse: 0.5194 New best_val_rmse: 0.5194\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 80 val_rmse: 0.632 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 96 val_rmse: 0.6222 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 112 val_rmse: 0.7939 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 128 val_rmse: 0.6171 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 144 val_rmse: 0.6467 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 160 val_rmse: 0.6271 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 176 val_rmse: 0.6981 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 192 val_rmse: 0.6172 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 208 val_rmse: 0.6664 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 224 val_rmse: 0.7589 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 240 val_rmse: 0.648 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 256 val_rmse: 0.6257 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 272 val_rmse: 0.6868 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 288 val_rmse: 0.6292 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 304 val_rmse: 0.6168 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 320 val_rmse: 0.6519 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 336 val_rmse: 0.6217 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 352 val_rmse: 0.6632 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 368 val_rmse: 0.6208 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 384 val_rmse: 0.6317 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 400 val_rmse: 0.6181 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 1 batch_num: 8 val_rmse: 0.8137 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 24 val_rmse: 0.6163 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 40 val_rmse: 0.6165 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 56 val_rmse: 0.6268 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 72 val_rmse: 0.7134 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 88 val_rmse: 0.6193 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 104 val_rmse: 0.6823 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 120 val_rmse: 0.6164 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 136 val_rmse: 0.6225 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 152 val_rmse: 0.6327 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 168 val_rmse: 0.6235 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 184 val_rmse: 0.6321 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 200 val_rmse: 0.6439 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 1 batch_num: 216 val_rmse: 0.6434 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 1 batch_num: 232 val_rmse: 0.6206 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 1 batch_num: 248 val_rmse: 0.6128 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 264 val_rmse: 0.616 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 280 val_rmse: 0.6325 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 296 val_rmse: 0.6218 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 312 val_rmse: 0.6501 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 328 val_rmse: 0.6298 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 344 val_rmse: 0.6268 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 360 val_rmse: 0.6187 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 376 val_rmse: 0.622 Still best_val_rmse: 0.5194 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 1 batch_num: 392 val_rmse: 0.6177 Still best_val_rmse: 0.5194 (from epoch 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-09-23 06:00:55,144]\u001b[0m Trial 2 finished with value: 0.5194218754768372 and parameters: {'base_lr': 0.00032909656093660627, 'last_lr': 0.00015543854935066984, 'schedule_func': <function get_linear_schedule_with_warmup at 0x7fb51fd03560>, 'batch_size': 4, 'optimizer': 'adamw'}. Best is trial 0 with value: 0.4334683418273926.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "##### Using fold 0\n",
            "##### Using base_lr 0.000473478659897781 last_lr 0.0004011051991730669 epochs 2\n",
            "##### Using <function get_cosine_schedule_with_warmup at 0x7fb51fd035f0>\n",
            "Model path\n",
            "/content/gdrive/My Drive/feedback-prize-english-language-learning/0917-deberta-v3-/microsoft-deberta-v3-base_fold2_best2.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_indices\n",
            "3259\n",
            "<class 'numpy.ndarray'>\n",
            "train_dataset\n",
            "3259\n",
            "<class '__main__.CommonLitDataset'>\n",
            "val_dataset\n",
            "652\n",
            "<class '__main__.CommonLitDataset'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /content/gdrive/My Drive/feedback-prize-english-language-learning/deberta-v3-base were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias']\n",
            "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at /content/gdrive/My Drive/feedback-prize-english-language-learning/deberta-v3-base and are newly initialized: ['classifier.bias', 'pooler.dense.weight', 'classifier.weight', 'pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "68ca7b2b2f144b85ac90501bc7aebaf5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "16 steps took 11.8 seconds\n",
            "Epoch: 0 batch_num: 16 val_rmse: 0.6364 New best_val_rmse: 0.6364\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 32 val_rmse: 0.9668 Still best_val_rmse: 0.6364 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 48 val_rmse: 0.7604 Still best_val_rmse: 0.6364 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 64 val_rmse: 0.6723 Still best_val_rmse: 0.6364 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 80 val_rmse: 0.6806 Still best_val_rmse: 0.6364 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 96 val_rmse: 0.6297 New best_val_rmse: 0.6297\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 112 val_rmse: 0.7536 Still best_val_rmse: 0.6297 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 128 val_rmse: 0.6183 New best_val_rmse: 0.6183\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 144 val_rmse: 0.5996 New best_val_rmse: 0.5996\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 160 val_rmse: 0.5512 New best_val_rmse: 0.5512\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 176 val_rmse: 0.6231 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 192 val_rmse: 0.6795 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 208 val_rmse: 0.6309 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 9.99 seconds\n",
            "Epoch: 0 batch_num: 224 val_rmse: 0.6203 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 9.99 seconds\n",
            "Epoch: 0 batch_num: 240 val_rmse: 0.7095 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 9.99 seconds\n",
            "Epoch: 0 batch_num: 256 val_rmse: 0.6594 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 9.99 seconds\n",
            "Epoch: 0 batch_num: 272 val_rmse: 0.679 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 288 val_rmse: 0.6324 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 9.99 seconds\n",
            "Epoch: 0 batch_num: 304 val_rmse: 0.6331 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 320 val_rmse: 0.6276 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 336 val_rmse: 0.6265 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 9.99 seconds\n",
            "Epoch: 0 batch_num: 352 val_rmse: 0.6698 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 9.99 seconds\n",
            "Epoch: 0 batch_num: 368 val_rmse: 0.6194 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 9.99 seconds\n",
            "Epoch: 0 batch_num: 384 val_rmse: 0.6455 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 400 val_rmse: 0.6278 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 1 batch_num: 8 val_rmse: 0.8261 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 9.99 seconds\n",
            "Epoch: 1 batch_num: 24 val_rmse: 0.629 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 40 val_rmse: 0.6219 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 9.99 seconds\n",
            "Epoch: 1 batch_num: 56 val_rmse: 0.6354 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 72 val_rmse: 0.7267 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 9.98 seconds\n",
            "Epoch: 1 batch_num: 88 val_rmse: 0.6218 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 104 val_rmse: 0.693 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 9.99 seconds\n",
            "Epoch: 1 batch_num: 120 val_rmse: 0.618 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 136 val_rmse: 0.6235 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 152 val_rmse: 0.6338 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 168 val_rmse: 0.626 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 9.99 seconds\n",
            "Epoch: 1 batch_num: 184 val_rmse: 0.6329 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 9.99 seconds\n",
            "Epoch: 1 batch_num: 200 val_rmse: 0.6463 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 216 val_rmse: 0.6514 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 9.99 seconds\n",
            "Epoch: 1 batch_num: 232 val_rmse: 0.6213 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 248 val_rmse: 0.6189 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 264 val_rmse: 0.6158 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 280 val_rmse: 0.6343 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 9.99 seconds\n",
            "Epoch: 1 batch_num: 296 val_rmse: 0.6176 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 9.99 seconds\n",
            "Epoch: 1 batch_num: 312 val_rmse: 0.6352 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 328 val_rmse: 0.6284 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 344 val_rmse: 0.63 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 9.99 seconds\n",
            "Epoch: 1 batch_num: 360 val_rmse: 0.6177 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 9.99 seconds\n",
            "Epoch: 1 batch_num: 376 val_rmse: 0.6172 Still best_val_rmse: 0.5512 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 392 val_rmse: 0.6198 Still best_val_rmse: 0.5512 (from epoch 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-09-23 06:25:36,737]\u001b[0m Trial 3 finished with value: 0.5512157082557678 and parameters: {'base_lr': 0.000473478659897781, 'last_lr': 0.0004011051991730669, 'schedule_func': <function get_cosine_schedule_with_warmup at 0x7fb51fd035f0>, 'batch_size': 4, 'optimizer': 'adamw'}. Best is trial 0 with value: 0.4334683418273926.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "##### Using fold 0\n",
            "##### Using base_lr 0.00029273404289147494 last_lr 0.00048113740008511144 epochs 2\n",
            "##### Using <function get_cosine_with_hard_restarts_schedule_with_warmup at 0x7fb51fd03680>\n",
            "Model path\n",
            "/content/gdrive/My Drive/feedback-prize-english-language-learning/0917-deberta-v3-/microsoft-deberta-v3-base_fold2_best2.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_indices\n",
            "3259\n",
            "<class 'numpy.ndarray'>\n",
            "train_dataset\n",
            "3259\n",
            "<class '__main__.CommonLitDataset'>\n",
            "val_dataset\n",
            "652\n",
            "<class '__main__.CommonLitDataset'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /content/gdrive/My Drive/feedback-prize-english-language-learning/deberta-v3-base were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias']\n",
            "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at /content/gdrive/My Drive/feedback-prize-english-language-learning/deberta-v3-base and are newly initialized: ['classifier.bias', 'pooler.dense.weight', 'classifier.weight', 'pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09c05d2b5f0c409da17eef91f70f1fbd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "16 steps took 11.8 seconds\n",
            "Epoch: 0 batch_num: 16 val_rmse: 1.099 New best_val_rmse: 1.099\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 32 val_rmse: 0.8516 New best_val_rmse: 0.8516\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 48 val_rmse: 0.7007 New best_val_rmse: 0.7007\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 64 val_rmse: 0.6499 New best_val_rmse: 0.6499\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 80 val_rmse: 0.6519 Still best_val_rmse: 0.6499 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 96 val_rmse: 0.6873 Still best_val_rmse: 0.6499 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 112 val_rmse: 0.7043 Still best_val_rmse: 0.6499 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 128 val_rmse: 0.792 Still best_val_rmse: 0.6499 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 144 val_rmse: 0.6428 New best_val_rmse: 0.6428\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 160 val_rmse: 0.516 New best_val_rmse: 0.516\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 176 val_rmse: 0.5417 Still best_val_rmse: 0.516 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 192 val_rmse: 0.6418 Still best_val_rmse: 0.516 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 208 val_rmse: 0.5902 Still best_val_rmse: 0.516 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 224 val_rmse: 0.6521 Still best_val_rmse: 0.516 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 240 val_rmse: 0.5258 Still best_val_rmse: 0.516 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 256 val_rmse: 0.5074 New best_val_rmse: 0.5074\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 272 val_rmse: 0.9271 Still best_val_rmse: 0.5074 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 288 val_rmse: 0.5861 Still best_val_rmse: 0.5074 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 304 val_rmse: 0.5506 Still best_val_rmse: 0.5074 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 320 val_rmse: 0.4965 New best_val_rmse: 0.4965\n",
            "\n",
            "8 steps took 5.09 seconds\n",
            "Epoch: 0 batch_num: 328 val_rmse: 0.5293 Still best_val_rmse: 0.4965 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 344 val_rmse: 0.5943 Still best_val_rmse: 0.4965 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 360 val_rmse: 0.5267 Still best_val_rmse: 0.4965 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 376 val_rmse: 0.5233 Still best_val_rmse: 0.4965 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 392 val_rmse: 0.5817 Still best_val_rmse: 0.4965 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 1 batch_num: 0 val_rmse: 0.512 Still best_val_rmse: 0.4965 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 1 batch_num: 16 val_rmse: 0.632 Still best_val_rmse: 0.4965 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 32 val_rmse: 0.6221 Still best_val_rmse: 0.4965 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 48 val_rmse: 0.6999 Still best_val_rmse: 0.4965 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 64 val_rmse: 0.6415 Still best_val_rmse: 0.4965 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 80 val_rmse: 0.6492 Still best_val_rmse: 0.4965 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 96 val_rmse: 0.6242 Still best_val_rmse: 0.4965 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 112 val_rmse: 0.6707 Still best_val_rmse: 0.4965 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 128 val_rmse: 0.6282 Still best_val_rmse: 0.4965 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 144 val_rmse: 0.6308 Still best_val_rmse: 0.4965 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 160 val_rmse: 0.6372 Still best_val_rmse: 0.4965 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 176 val_rmse: 0.6256 Still best_val_rmse: 0.4965 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 192 val_rmse: 0.6514 Still best_val_rmse: 0.4965 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 208 val_rmse: 0.6266 Still best_val_rmse: 0.4965 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 224 val_rmse: 0.6338 Still best_val_rmse: 0.4965 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 240 val_rmse: 0.6238 Still best_val_rmse: 0.4965 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 256 val_rmse: 0.6306 Still best_val_rmse: 0.4965 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 272 val_rmse: 0.6389 Still best_val_rmse: 0.4965 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 288 val_rmse: 0.7226 Still best_val_rmse: 0.4965 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 304 val_rmse: 0.6368 Still best_val_rmse: 0.4965 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 320 val_rmse: 0.6231 Still best_val_rmse: 0.4965 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 336 val_rmse: 0.6303 Still best_val_rmse: 0.4965 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 352 val_rmse: 0.6408 Still best_val_rmse: 0.4965 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 368 val_rmse: 0.6233 Still best_val_rmse: 0.4965 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 384 val_rmse: 0.6354 Still best_val_rmse: 0.4965 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 400 val_rmse: 0.6387 Still best_val_rmse: 0.4965 (from epoch 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-09-23 06:50:52,818]\u001b[0m Trial 4 finished with value: 0.49653974175453186 and parameters: {'base_lr': 0.00029273404289147494, 'last_lr': 0.00048113740008511144, 'schedule_func': <function get_cosine_with_hard_restarts_schedule_with_warmup at 0x7fb51fd03680>, 'batch_size': 4, 'optimizer': 'adam'}. Best is trial 0 with value: 0.4334683418273926.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "##### Using fold 0\n",
            "##### Using base_lr 0.00024755780184612224 last_lr 0.0031391501996965144 epochs 2\n",
            "##### Using <function get_cosine_schedule_with_warmup at 0x7fb51fd035f0>\n",
            "Model path\n",
            "/content/gdrive/My Drive/feedback-prize-english-language-learning/0917-deberta-v3-/microsoft-deberta-v3-base_fold2_best2.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_indices\n",
            "3259\n",
            "<class 'numpy.ndarray'>\n",
            "train_dataset\n",
            "3259\n",
            "<class '__main__.CommonLitDataset'>\n",
            "val_dataset\n",
            "652\n",
            "<class '__main__.CommonLitDataset'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /content/gdrive/My Drive/feedback-prize-english-language-learning/deberta-v3-base were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias']\n",
            "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at /content/gdrive/My Drive/feedback-prize-english-language-learning/deberta-v3-base and are newly initialized: ['classifier.bias', 'pooler.dense.weight', 'classifier.weight', 'pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "79a0f371b4cc442fa91b285bd6863379",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "16 steps took 11.8 seconds\n",
            "Epoch: 0 batch_num: 16 val_rmse: 0.6153 New best_val_rmse: 0.6153\n",
            "\n",
            "16 steps took 10.3 seconds\n",
            "Epoch: 0 batch_num: 32 val_rmse: 1.473 Still best_val_rmse: 0.6153 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 48 val_rmse: 0.656 Still best_val_rmse: 0.6153 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 64 val_rmse: 0.6314 Still best_val_rmse: 0.6153 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 80 val_rmse: 0.5719 New best_val_rmse: 0.5719\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 96 val_rmse: 0.6323 Still best_val_rmse: 0.5719 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 112 val_rmse: 0.5712 New best_val_rmse: 0.5712\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 128 val_rmse: 0.752 Still best_val_rmse: 0.5712 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 144 val_rmse: 0.5403 New best_val_rmse: 0.5403\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 160 val_rmse: 0.4911 New best_val_rmse: 0.4911\n",
            "\n",
            "8 steps took 5.1 seconds\n",
            "Epoch: 0 batch_num: 168 val_rmse: 0.5059 Still best_val_rmse: 0.4911 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 184 val_rmse: 0.5147 Still best_val_rmse: 0.4911 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 200 val_rmse: 0.5746 Still best_val_rmse: 0.4911 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 216 val_rmse: 0.5869 Still best_val_rmse: 0.4911 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 232 val_rmse: 0.5794 Still best_val_rmse: 0.4911 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 248 val_rmse: 0.7244 Still best_val_rmse: 0.4911 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 264 val_rmse: 0.684 Still best_val_rmse: 0.4911 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 280 val_rmse: 0.6471 Still best_val_rmse: 0.4911 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 296 val_rmse: 0.543 Still best_val_rmse: 0.4911 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 312 val_rmse: 0.4887 New best_val_rmse: 0.4887\n",
            "\n",
            "4 steps took 2.53 seconds\n",
            "Epoch: 0 batch_num: 316 val_rmse: 0.5039 Still best_val_rmse: 0.4887 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 332 val_rmse: 0.493 Still best_val_rmse: 0.4887 (from epoch 0)\n",
            "\n",
            "8 steps took 5.06 seconds\n",
            "Epoch: 0 batch_num: 340 val_rmse: 0.6616 Still best_val_rmse: 0.4887 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 356 val_rmse: 0.7865 Still best_val_rmse: 0.4887 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 372 val_rmse: 0.6238 Still best_val_rmse: 0.4887 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 388 val_rmse: 0.4734 New best_val_rmse: 0.4734\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 0 batch_num: 390 val_rmse: 0.4907 Still best_val_rmse: 0.4734 (from epoch 0)\n",
            "\n",
            "8 steps took 5.07 seconds\n",
            "Epoch: 0 batch_num: 398 val_rmse: 0.495 Still best_val_rmse: 0.4734 (from epoch 0)\n",
            "\n",
            "8 steps took 5.07 seconds\n",
            "Epoch: 0 batch_num: 406 val_rmse: 0.4754 Still best_val_rmse: 0.4734 (from epoch 0)\n",
            "\n",
            "2 steps took 1.38 seconds\n",
            "Epoch: 1 batch_num: 0 val_rmse: 0.6014 Still best_val_rmse: 0.4734 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 1 batch_num: 16 val_rmse: 0.5185 Still best_val_rmse: 0.4734 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 1 batch_num: 32 val_rmse: 0.4767 Still best_val_rmse: 0.4734 (from epoch 0)\n",
            "\n",
            "2 steps took 1.26 seconds\n",
            "Epoch: 1 batch_num: 34 val_rmse: 0.4721 New best_val_rmse: 0.4721\n",
            "\n",
            "2 steps took 1.28 seconds\n",
            "Epoch: 1 batch_num: 36 val_rmse: 0.4707 New best_val_rmse: 0.4707\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 38 val_rmse: 0.5011 Still best_val_rmse: 0.4707 (from epoch 1)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 1 batch_num: 54 val_rmse: 0.5648 Still best_val_rmse: 0.4707 (from epoch 1)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 1 batch_num: 70 val_rmse: 0.5348 Still best_val_rmse: 0.4707 (from epoch 1)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 1 batch_num: 86 val_rmse: 0.4926 Still best_val_rmse: 0.4707 (from epoch 1)\n",
            "\n",
            "8 steps took 5.06 seconds\n",
            "Epoch: 1 batch_num: 94 val_rmse: 0.4594 New best_val_rmse: 0.4594\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 95 val_rmse: 0.4614 Still best_val_rmse: 0.4594 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 96 val_rmse: 0.4642 Still best_val_rmse: 0.4594 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 97 val_rmse: 0.4647 Still best_val_rmse: 0.4594 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 98 val_rmse: 0.467 Still best_val_rmse: 0.4594 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 99 val_rmse: 0.479 Still best_val_rmse: 0.4594 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 101 val_rmse: 0.565 Still best_val_rmse: 0.4594 (from epoch 1)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 1 batch_num: 117 val_rmse: 0.4741 Still best_val_rmse: 0.4594 (from epoch 1)\n",
            "\n",
            "2 steps took 1.26 seconds\n",
            "Epoch: 1 batch_num: 119 val_rmse: 0.5175 Still best_val_rmse: 0.4594 (from epoch 1)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 1 batch_num: 135 val_rmse: 0.5361 Still best_val_rmse: 0.4594 (from epoch 1)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 1 batch_num: 151 val_rmse: 0.513 Still best_val_rmse: 0.4594 (from epoch 1)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 1 batch_num: 167 val_rmse: 0.4654 Still best_val_rmse: 0.4594 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 168 val_rmse: 0.4814 Still best_val_rmse: 0.4594 (from epoch 1)\n",
            "\n",
            "4 steps took 2.53 seconds\n",
            "Epoch: 1 batch_num: 172 val_rmse: 0.484 Still best_val_rmse: 0.4594 (from epoch 1)\n",
            "\n",
            "4 steps took 2.53 seconds\n",
            "Epoch: 1 batch_num: 176 val_rmse: 0.503 Still best_val_rmse: 0.4594 (from epoch 1)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 1 batch_num: 192 val_rmse: 0.5256 Still best_val_rmse: 0.4594 (from epoch 1)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 1 batch_num: 208 val_rmse: 0.4687 Still best_val_rmse: 0.4594 (from epoch 1)\n",
            "\n",
            "1 steps took 0.632 seconds\n",
            "Epoch: 1 batch_num: 209 val_rmse: 0.4704 Still best_val_rmse: 0.4594 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 211 val_rmse: 0.4706 Still best_val_rmse: 0.4594 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 213 val_rmse: 0.464 Still best_val_rmse: 0.4594 (from epoch 1)\n",
            "\n",
            "1 steps took 0.629 seconds\n",
            "Epoch: 1 batch_num: 214 val_rmse: 0.4668 Still best_val_rmse: 0.4594 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 215 val_rmse: 0.4727 Still best_val_rmse: 0.4594 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 217 val_rmse: 0.5005 Still best_val_rmse: 0.4594 (from epoch 1)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 1 batch_num: 233 val_rmse: 0.4713 Still best_val_rmse: 0.4594 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 235 val_rmse: 0.4692 Still best_val_rmse: 0.4594 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 236 val_rmse: 0.4703 Still best_val_rmse: 0.4594 (from epoch 1)\n",
            "\n",
            "2 steps took 1.26 seconds\n",
            "Epoch: 1 batch_num: 238 val_rmse: 0.4663 Still best_val_rmse: 0.4594 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 239 val_rmse: 0.4674 Still best_val_rmse: 0.4594 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 240 val_rmse: 0.4732 Still best_val_rmse: 0.4594 (from epoch 1)\n",
            "\n",
            "2 steps took 1.26 seconds\n",
            "Epoch: 1 batch_num: 242 val_rmse: 0.4832 Still best_val_rmse: 0.4594 (from epoch 1)\n",
            "\n",
            "4 steps took 2.53 seconds\n",
            "Epoch: 1 batch_num: 246 val_rmse: 0.5168 Still best_val_rmse: 0.4594 (from epoch 1)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 1 batch_num: 262 val_rmse: 0.4673 Still best_val_rmse: 0.4594 (from epoch 1)\n",
            "\n",
            "1 steps took 0.628 seconds\n",
            "Epoch: 1 batch_num: 263 val_rmse: 0.4616 Still best_val_rmse: 0.4594 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 264 val_rmse: 0.4949 Still best_val_rmse: 0.4594 (from epoch 1)\n",
            "\n",
            "8 steps took 5.08 seconds\n",
            "Epoch: 1 batch_num: 272 val_rmse: 0.5214 Still best_val_rmse: 0.4594 (from epoch 1)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 1 batch_num: 288 val_rmse: 0.4574 New best_val_rmse: 0.4574\n",
            "\n",
            "1 steps took 0.643 seconds\n",
            "Epoch: 1 batch_num: 289 val_rmse: 0.4565 New best_val_rmse: 0.4565\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 290 val_rmse: 0.4572 Still best_val_rmse: 0.4565 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 291 val_rmse: 0.4649 Still best_val_rmse: 0.4565 (from epoch 1)\n",
            "\n",
            "1 steps took 0.632 seconds\n",
            "Epoch: 1 batch_num: 292 val_rmse: 0.4727 Still best_val_rmse: 0.4565 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 294 val_rmse: 0.4714 Still best_val_rmse: 0.4565 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 296 val_rmse: 0.4554 New best_val_rmse: 0.4554\n",
            "\n",
            "1 steps took 0.645 seconds\n",
            "Epoch: 1 batch_num: 297 val_rmse: 0.4561 Still best_val_rmse: 0.4554 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 298 val_rmse: 0.4571 Still best_val_rmse: 0.4554 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 299 val_rmse: 0.4563 Still best_val_rmse: 0.4554 (from epoch 1)\n",
            "\n",
            "1 steps took 0.631 seconds\n",
            "Epoch: 1 batch_num: 300 val_rmse: 0.4554 New best_val_rmse: 0.4554\n",
            "\n",
            "1 steps took 0.648 seconds\n",
            "Epoch: 1 batch_num: 301 val_rmse: 0.4556 Still best_val_rmse: 0.4554 (from epoch 1)\n",
            "\n",
            "1 steps took 0.641 seconds\n",
            "Epoch: 1 batch_num: 302 val_rmse: 0.4557 Still best_val_rmse: 0.4554 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 303 val_rmse: 0.4589 Still best_val_rmse: 0.4554 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 304 val_rmse: 0.4634 Still best_val_rmse: 0.4554 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 305 val_rmse: 0.4719 Still best_val_rmse: 0.4554 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 307 val_rmse: 0.4921 Still best_val_rmse: 0.4554 (from epoch 1)\n",
            "\n",
            "8 steps took 5.08 seconds\n",
            "Epoch: 1 batch_num: 315 val_rmse: 0.5237 Still best_val_rmse: 0.4554 (from epoch 1)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 1 batch_num: 331 val_rmse: 0.4823 Still best_val_rmse: 0.4554 (from epoch 1)\n",
            "\n",
            "4 steps took 2.53 seconds\n",
            "Epoch: 1 batch_num: 335 val_rmse: 0.4642 Still best_val_rmse: 0.4554 (from epoch 1)\n",
            "\n",
            "1 steps took 0.632 seconds\n",
            "Epoch: 1 batch_num: 336 val_rmse: 0.462 Still best_val_rmse: 0.4554 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 337 val_rmse: 0.4649 Still best_val_rmse: 0.4554 (from epoch 1)\n",
            "\n",
            "1 steps took 0.632 seconds\n",
            "Epoch: 1 batch_num: 338 val_rmse: 0.4751 Still best_val_rmse: 0.4554 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 340 val_rmse: 0.4942 Still best_val_rmse: 0.4554 (from epoch 1)\n",
            "\n",
            "8 steps took 5.1 seconds\n",
            "Epoch: 1 batch_num: 348 val_rmse: 0.4824 Still best_val_rmse: 0.4554 (from epoch 1)\n",
            "\n",
            "4 steps took 2.54 seconds\n",
            "Epoch: 1 batch_num: 352 val_rmse: 0.4574 Still best_val_rmse: 0.4554 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 353 val_rmse: 0.4591 Still best_val_rmse: 0.4554 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 354 val_rmse: 0.4621 Still best_val_rmse: 0.4554 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 355 val_rmse: 0.4623 Still best_val_rmse: 0.4554 (from epoch 1)\n",
            "\n",
            "1 steps took 0.641 seconds\n",
            "Epoch: 1 batch_num: 356 val_rmse: 0.4592 Still best_val_rmse: 0.4554 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 357 val_rmse: 0.4578 Still best_val_rmse: 0.4554 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 358 val_rmse: 0.4618 Still best_val_rmse: 0.4554 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 359 val_rmse: 0.4604 Still best_val_rmse: 0.4554 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 360 val_rmse: 0.4592 Still best_val_rmse: 0.4554 (from epoch 1)\n",
            "\n",
            "1 steps took 0.64 seconds\n",
            "Epoch: 1 batch_num: 361 val_rmse: 0.4599 Still best_val_rmse: 0.4554 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 362 val_rmse: 0.4697 Still best_val_rmse: 0.4554 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 363 val_rmse: 0.487 Still best_val_rmse: 0.4554 (from epoch 1)\n",
            "\n",
            "4 steps took 2.54 seconds\n",
            "Epoch: 1 batch_num: 367 val_rmse: 0.4629 Still best_val_rmse: 0.4554 (from epoch 1)\n",
            "\n",
            "1 steps took 0.64 seconds\n",
            "Epoch: 1 batch_num: 368 val_rmse: 0.465 Still best_val_rmse: 0.4554 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 369 val_rmse: 0.4721 Still best_val_rmse: 0.4554 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 371 val_rmse: 0.4835 Still best_val_rmse: 0.4554 (from epoch 1)\n",
            "\n",
            "4 steps took 2.52 seconds\n",
            "Epoch: 1 batch_num: 375 val_rmse: 0.4642 Still best_val_rmse: 0.4554 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 376 val_rmse: 0.48 Still best_val_rmse: 0.4554 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 378 val_rmse: 0.5198 Still best_val_rmse: 0.4554 (from epoch 1)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 1 batch_num: 394 val_rmse: 0.4912 Still best_val_rmse: 0.4554 (from epoch 1)\n",
            "\n",
            "8 steps took 5.06 seconds\n",
            "Epoch: 1 batch_num: 402 val_rmse: 0.5423 Still best_val_rmse: 0.4554 (from epoch 1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-09-23 07:38:00,660]\u001b[0m Trial 5 finished with value: 0.45539113879203796 and parameters: {'base_lr': 0.00024755780184612224, 'last_lr': 0.0031391501996965144, 'schedule_func': <function get_cosine_schedule_with_warmup at 0x7fb51fd035f0>, 'batch_size': 2, 'optimizer': 'adamw'}. Best is trial 0 with value: 0.4334683418273926.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "##### Using fold 0\n",
            "##### Using base_lr 4.968468501314881e-05 last_lr 8.23811562140965e-05 epochs 2\n",
            "##### Using <function get_cosine_with_hard_restarts_schedule_with_warmup at 0x7fb51fd03680>\n",
            "Model path\n",
            "/content/gdrive/My Drive/feedback-prize-english-language-learning/0917-deberta-v3-/microsoft-deberta-v3-base_fold2_best2.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_indices\n",
            "3259\n",
            "<class 'numpy.ndarray'>\n",
            "train_dataset\n",
            "3259\n",
            "<class '__main__.CommonLitDataset'>\n",
            "val_dataset\n",
            "652\n",
            "<class '__main__.CommonLitDataset'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /content/gdrive/My Drive/feedback-prize-english-language-learning/deberta-v3-base were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias']\n",
            "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at /content/gdrive/My Drive/feedback-prize-english-language-learning/deberta-v3-base and are newly initialized: ['classifier.bias', 'pooler.dense.weight', 'classifier.weight', 'pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "049f4adc9edc4613bcff8006daebb070",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "16 steps took 11.8 seconds\n",
            "Epoch: 0 batch_num: 16 val_rmse: 0.6713 New best_val_rmse: 0.6713\n",
            "\n",
            "16 steps took 10.3 seconds\n",
            "Epoch: 0 batch_num: 32 val_rmse: 0.6161 New best_val_rmse: 0.6161\n",
            "\n",
            "16 steps took 10.3 seconds\n",
            "Epoch: 0 batch_num: 48 val_rmse: 0.558 New best_val_rmse: 0.558\n",
            "\n",
            "16 steps took 10.3 seconds\n",
            "Epoch: 0 batch_num: 64 val_rmse: 0.4626 New best_val_rmse: 0.4626\n",
            "\n",
            "1 steps took 0.659 seconds\n",
            "Epoch: 0 batch_num: 65 val_rmse: 0.5446 Still best_val_rmse: 0.4626 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 81 val_rmse: 0.7135 Still best_val_rmse: 0.4626 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 97 val_rmse: 0.5584 Still best_val_rmse: 0.4626 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 113 val_rmse: 0.5909 Still best_val_rmse: 0.4626 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 129 val_rmse: 0.6192 Still best_val_rmse: 0.4626 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 145 val_rmse: 0.4828 Still best_val_rmse: 0.4626 (from epoch 0)\n",
            "\n",
            "4 steps took 2.55 seconds\n",
            "Epoch: 0 batch_num: 149 val_rmse: 0.5158 Still best_val_rmse: 0.4626 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 165 val_rmse: 0.4558 New best_val_rmse: 0.4558\n",
            "\n",
            "1 steps took 0.679 seconds\n",
            "Epoch: 0 batch_num: 166 val_rmse: 0.4463 New best_val_rmse: 0.4463\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 0 batch_num: 167 val_rmse: 0.4473 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "1 steps took 0.646 seconds\n",
            "Epoch: 0 batch_num: 168 val_rmse: 0.4467 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "1 steps took 0.64 seconds\n",
            "Epoch: 0 batch_num: 169 val_rmse: 0.4524 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 0 batch_num: 170 val_rmse: 0.4466 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 0 batch_num: 171 val_rmse: 0.4746 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 0 batch_num: 173 val_rmse: 0.5402 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 189 val_rmse: 0.4674 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 0 batch_num: 190 val_rmse: 0.4778 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 0 batch_num: 192 val_rmse: 0.4639 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 0 batch_num: 193 val_rmse: 0.4954 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "8 steps took 5.1 seconds\n",
            "Epoch: 0 batch_num: 201 val_rmse: 0.4861 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "4 steps took 2.54 seconds\n",
            "Epoch: 0 batch_num: 205 val_rmse: 0.5206 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 221 val_rmse: 0.5786 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 237 val_rmse: 0.5314 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 253 val_rmse: 0.527 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 269 val_rmse: 0.4635 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 0 batch_num: 270 val_rmse: 0.5169 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 286 val_rmse: 0.4594 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 0 batch_num: 287 val_rmse: 0.4613 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "1 steps took 0.64 seconds\n",
            "Epoch: 0 batch_num: 288 val_rmse: 0.4751 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 0 batch_num: 290 val_rmse: 0.4726 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 0 batch_num: 292 val_rmse: 0.4805 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "4 steps took 2.54 seconds\n",
            "Epoch: 0 batch_num: 296 val_rmse: 0.5228 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 312 val_rmse: 0.45 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 0 batch_num: 313 val_rmse: 0.4558 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 0 batch_num: 314 val_rmse: 0.46 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 0 batch_num: 315 val_rmse: 0.4529 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 0 batch_num: 316 val_rmse: 0.4466 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 0 batch_num: 317 val_rmse: 0.4589 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 0 batch_num: 318 val_rmse: 0.5006 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 334 val_rmse: 0.4739 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "2 steps took 1.28 seconds\n",
            "Epoch: 0 batch_num: 336 val_rmse: 0.4775 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 0 batch_num: 338 val_rmse: 0.4702 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 0 batch_num: 340 val_rmse: 0.48 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "2 steps took 1.28 seconds\n",
            "Epoch: 0 batch_num: 342 val_rmse: 0.4737 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 0 batch_num: 344 val_rmse: 0.4703 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 0 batch_num: 346 val_rmse: 0.4889 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "4 steps took 2.54 seconds\n",
            "Epoch: 0 batch_num: 350 val_rmse: 0.471 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 0 batch_num: 352 val_rmse: 0.4638 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 0 batch_num: 353 val_rmse: 0.4781 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 0 batch_num: 355 val_rmse: 0.5117 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 371 val_rmse: 0.4517 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 0 batch_num: 372 val_rmse: 0.4576 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 0 batch_num: 373 val_rmse: 0.4684 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 0 batch_num: 374 val_rmse: 0.4801 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "4 steps took 2.54 seconds\n",
            "Epoch: 0 batch_num: 378 val_rmse: 0.4543 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 0 batch_num: 379 val_rmse: 0.4674 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 0 batch_num: 380 val_rmse: 0.4862 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "4 steps took 2.54 seconds\n",
            "Epoch: 0 batch_num: 384 val_rmse: 0.4647 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 0 batch_num: 385 val_rmse: 0.4486 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 0 batch_num: 386 val_rmse: 0.4491 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "1 steps took 0.642 seconds\n",
            "Epoch: 0 batch_num: 387 val_rmse: 0.4508 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 0 batch_num: 388 val_rmse: 0.4648 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 0 batch_num: 389 val_rmse: 0.4703 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "2 steps took 1.28 seconds\n",
            "Epoch: 0 batch_num: 391 val_rmse: 0.4705 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 0 batch_num: 393 val_rmse: 0.4624 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 0 batch_num: 394 val_rmse: 0.4646 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 0 batch_num: 395 val_rmse: 0.4639 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 0 batch_num: 396 val_rmse: 0.4594 Still best_val_rmse: 0.4463 (from epoch 0)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 0 batch_num: 397 val_rmse: 0.4443 New best_val_rmse: 0.4443\n",
            "\n",
            "1 steps took 0.658 seconds\n",
            "Epoch: 0 batch_num: 398 val_rmse: 0.4493 Still best_val_rmse: 0.4443 (from epoch 0)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 0 batch_num: 399 val_rmse: 0.4578 Still best_val_rmse: 0.4443 (from epoch 0)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 0 batch_num: 400 val_rmse: 0.4676 Still best_val_rmse: 0.4443 (from epoch 0)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 0 batch_num: 401 val_rmse: 0.4657 Still best_val_rmse: 0.4443 (from epoch 0)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 0 batch_num: 402 val_rmse: 0.445 Still best_val_rmse: 0.4443 (from epoch 0)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 0 batch_num: 403 val_rmse: 0.4451 Still best_val_rmse: 0.4443 (from epoch 0)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 0 batch_num: 404 val_rmse: 0.4499 Still best_val_rmse: 0.4443 (from epoch 0)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 0 batch_num: 405 val_rmse: 0.4616 Still best_val_rmse: 0.4443 (from epoch 0)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 0 batch_num: 406 val_rmse: 0.4745 Still best_val_rmse: 0.4443 (from epoch 0)\n",
            "\n",
            "2 steps took 1.36 seconds\n",
            "Epoch: 1 batch_num: 0 val_rmse: 0.455 Still best_val_rmse: 0.4443 (from epoch 0)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 1 val_rmse: 0.4433 New best_val_rmse: 0.4433\n",
            "\n",
            "1 steps took 0.651 seconds\n",
            "Epoch: 1 batch_num: 2 val_rmse: 0.445 Still best_val_rmse: 0.4433 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 3 val_rmse: 0.4586 Still best_val_rmse: 0.4433 (from epoch 1)\n",
            "\n",
            "1 steps took 0.632 seconds\n",
            "Epoch: 1 batch_num: 4 val_rmse: 0.4794 Still best_val_rmse: 0.4433 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 6 val_rmse: 0.4893 Still best_val_rmse: 0.4433 (from epoch 1)\n",
            "\n",
            "4 steps took 2.54 seconds\n",
            "Epoch: 1 batch_num: 10 val_rmse: 0.4589 Still best_val_rmse: 0.4433 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 11 val_rmse: 0.4931 Still best_val_rmse: 0.4433 (from epoch 1)\n",
            "\n",
            "8 steps took 5.09 seconds\n",
            "Epoch: 1 batch_num: 19 val_rmse: 0.4557 Still best_val_rmse: 0.4433 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 20 val_rmse: 0.4492 Still best_val_rmse: 0.4433 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 21 val_rmse: 0.4365 New best_val_rmse: 0.4365\n",
            "\n",
            "1 steps took 0.64 seconds\n",
            "Epoch: 1 batch_num: 22 val_rmse: 0.4368 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.648 seconds\n",
            "Epoch: 1 batch_num: 23 val_rmse: 0.4415 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.64 seconds\n",
            "Epoch: 1 batch_num: 24 val_rmse: 0.4451 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 25 val_rmse: 0.4451 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 26 val_rmse: 0.4464 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 27 val_rmse: 0.4458 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 28 val_rmse: 0.4577 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 29 val_rmse: 0.4679 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 30 val_rmse: 0.4536 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 31 val_rmse: 0.4479 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 32 val_rmse: 0.4474 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 33 val_rmse: 0.4485 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 34 val_rmse: 0.4519 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 35 val_rmse: 0.457 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 36 val_rmse: 0.4647 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 37 val_rmse: 0.465 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 38 val_rmse: 0.4646 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 39 val_rmse: 0.4579 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 40 val_rmse: 0.4516 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 41 val_rmse: 0.4506 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 42 val_rmse: 0.4579 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 43 val_rmse: 0.4843 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "4 steps took 2.55 seconds\n",
            "Epoch: 1 batch_num: 47 val_rmse: 0.4739 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 49 val_rmse: 0.4567 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.642 seconds\n",
            "Epoch: 1 batch_num: 50 val_rmse: 0.4671 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.631 seconds\n",
            "Epoch: 1 batch_num: 51 val_rmse: 0.4816 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "4 steps took 2.55 seconds\n",
            "Epoch: 1 batch_num: 55 val_rmse: 0.4918 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "8 steps took 5.08 seconds\n",
            "Epoch: 1 batch_num: 63 val_rmse: 0.4558 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 64 val_rmse: 0.4606 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 65 val_rmse: 0.4649 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.64 seconds\n",
            "Epoch: 1 batch_num: 66 val_rmse: 0.4646 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 67 val_rmse: 0.463 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.642 seconds\n",
            "Epoch: 1 batch_num: 68 val_rmse: 0.4661 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.641 seconds\n",
            "Epoch: 1 batch_num: 69 val_rmse: 0.4539 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 70 val_rmse: 0.4599 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 71 val_rmse: 0.4608 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 72 val_rmse: 0.4511 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 73 val_rmse: 0.4504 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 74 val_rmse: 0.4504 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 75 val_rmse: 0.4516 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.64 seconds\n",
            "Epoch: 1 batch_num: 76 val_rmse: 0.4525 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 77 val_rmse: 0.4525 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 78 val_rmse: 0.4518 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 79 val_rmse: 0.4518 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 80 val_rmse: 0.4527 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 81 val_rmse: 0.4549 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 82 val_rmse: 0.4522 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 83 val_rmse: 0.4495 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 84 val_rmse: 0.4483 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 85 val_rmse: 0.4482 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.642 seconds\n",
            "Epoch: 1 batch_num: 86 val_rmse: 0.4475 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.64 seconds\n",
            "Epoch: 1 batch_num: 87 val_rmse: 0.4466 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 88 val_rmse: 0.4462 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.64 seconds\n",
            "Epoch: 1 batch_num: 89 val_rmse: 0.4459 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.64 seconds\n",
            "Epoch: 1 batch_num: 90 val_rmse: 0.446 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 91 val_rmse: 0.4486 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 92 val_rmse: 0.4509 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 93 val_rmse: 0.4522 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 94 val_rmse: 0.4555 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 95 val_rmse: 0.4561 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 96 val_rmse: 0.4523 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 97 val_rmse: 0.4496 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 98 val_rmse: 0.4487 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 99 val_rmse: 0.4479 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 100 val_rmse: 0.448 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 101 val_rmse: 0.4528 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 102 val_rmse: 0.4573 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 103 val_rmse: 0.4626 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 104 val_rmse: 0.4657 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 105 val_rmse: 0.4715 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 107 val_rmse: 0.4467 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 108 val_rmse: 0.4507 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 109 val_rmse: 0.4541 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 110 val_rmse: 0.454 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.64 seconds\n",
            "Epoch: 1 batch_num: 111 val_rmse: 0.4502 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 112 val_rmse: 0.4491 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 113 val_rmse: 0.4477 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 114 val_rmse: 0.445 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 115 val_rmse: 0.4452 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 116 val_rmse: 0.4439 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 117 val_rmse: 0.4407 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.643 seconds\n",
            "Epoch: 1 batch_num: 118 val_rmse: 0.4401 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 119 val_rmse: 0.4395 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 120 val_rmse: 0.4422 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 121 val_rmse: 0.4434 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 122 val_rmse: 0.4454 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.643 seconds\n",
            "Epoch: 1 batch_num: 123 val_rmse: 0.4483 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 124 val_rmse: 0.4451 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 125 val_rmse: 0.4429 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 126 val_rmse: 0.4418 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 127 val_rmse: 0.4403 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 128 val_rmse: 0.4404 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 129 val_rmse: 0.4444 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 130 val_rmse: 0.4486 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 131 val_rmse: 0.4468 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 132 val_rmse: 0.4439 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 133 val_rmse: 0.4385 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 134 val_rmse: 0.4386 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 135 val_rmse: 0.4397 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 136 val_rmse: 0.4457 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 137 val_rmse: 0.4626 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.647 seconds\n",
            "Epoch: 1 batch_num: 138 val_rmse: 0.4764 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "2 steps took 1.28 seconds\n",
            "Epoch: 1 batch_num: 140 val_rmse: 0.4577 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 141 val_rmse: 0.4424 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 142 val_rmse: 0.4424 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 143 val_rmse: 0.456 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 144 val_rmse: 0.481 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "4 steps took 2.55 seconds\n",
            "Epoch: 1 batch_num: 148 val_rmse: 0.4391 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 149 val_rmse: 0.4466 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.632 seconds\n",
            "Epoch: 1 batch_num: 150 val_rmse: 0.467 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 151 val_rmse: 0.4787 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 153 val_rmse: 0.4957 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "8 steps took 5.11 seconds\n",
            "Epoch: 1 batch_num: 161 val_rmse: 0.4979 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "8 steps took 5.08 seconds\n",
            "Epoch: 1 batch_num: 169 val_rmse: 0.458 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 170 val_rmse: 0.4972 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "8 steps took 5.09 seconds\n",
            "Epoch: 1 batch_num: 178 val_rmse: 0.4561 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.631 seconds\n",
            "Epoch: 1 batch_num: 179 val_rmse: 0.4737 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 181 val_rmse: 0.4945 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "8 steps took 5.09 seconds\n",
            "Epoch: 1 batch_num: 189 val_rmse: 0.4801 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "4 steps took 2.55 seconds\n",
            "Epoch: 1 batch_num: 193 val_rmse: 0.4427 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.641 seconds\n",
            "Epoch: 1 batch_num: 194 val_rmse: 0.4423 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 195 val_rmse: 0.4438 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 196 val_rmse: 0.447 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 197 val_rmse: 0.4444 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 198 val_rmse: 0.4421 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 199 val_rmse: 0.4405 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 200 val_rmse: 0.4446 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 201 val_rmse: 0.4443 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 202 val_rmse: 0.4395 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 203 val_rmse: 0.4395 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 204 val_rmse: 0.4414 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 205 val_rmse: 0.4429 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 206 val_rmse: 0.4471 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 207 val_rmse: 0.4476 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 208 val_rmse: 0.4476 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 209 val_rmse: 0.4487 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.641 seconds\n",
            "Epoch: 1 batch_num: 210 val_rmse: 0.4498 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 211 val_rmse: 0.4521 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 212 val_rmse: 0.4547 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 213 val_rmse: 0.4572 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 214 val_rmse: 0.4584 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 215 val_rmse: 0.4595 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.64 seconds\n",
            "Epoch: 1 batch_num: 216 val_rmse: 0.4569 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 217 val_rmse: 0.4557 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 218 val_rmse: 0.4583 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 219 val_rmse: 0.4675 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 220 val_rmse: 0.4753 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "2 steps took 1.28 seconds\n",
            "Epoch: 1 batch_num: 222 val_rmse: 0.475 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 224 val_rmse: 0.4412 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 225 val_rmse: 0.4428 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 226 val_rmse: 0.4508 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 227 val_rmse: 0.4603 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 228 val_rmse: 0.4722 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 230 val_rmse: 0.4622 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 231 val_rmse: 0.4627 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.64 seconds\n",
            "Epoch: 1 batch_num: 232 val_rmse: 0.456 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 233 val_rmse: 0.4478 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.64 seconds\n",
            "Epoch: 1 batch_num: 234 val_rmse: 0.4412 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 235 val_rmse: 0.445 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 236 val_rmse: 0.4478 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.64 seconds\n",
            "Epoch: 1 batch_num: 237 val_rmse: 0.4517 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 238 val_rmse: 0.4586 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 239 val_rmse: 0.4582 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 240 val_rmse: 0.4596 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 241 val_rmse: 0.4521 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 242 val_rmse: 0.4485 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 243 val_rmse: 0.4436 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 244 val_rmse: 0.4422 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 245 val_rmse: 0.4412 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 246 val_rmse: 0.4434 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 247 val_rmse: 0.4497 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 248 val_rmse: 0.4548 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.641 seconds\n",
            "Epoch: 1 batch_num: 249 val_rmse: 0.464 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.645 seconds\n",
            "Epoch: 1 batch_num: 250 val_rmse: 0.4721 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 252 val_rmse: 0.4687 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 253 val_rmse: 0.4637 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.632 seconds\n",
            "Epoch: 1 batch_num: 254 val_rmse: 0.4523 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 255 val_rmse: 0.4445 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 256 val_rmse: 0.4413 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 257 val_rmse: 0.4414 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.64 seconds\n",
            "Epoch: 1 batch_num: 258 val_rmse: 0.4417 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.632 seconds\n",
            "Epoch: 1 batch_num: 259 val_rmse: 0.4433 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 260 val_rmse: 0.4469 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 261 val_rmse: 0.4497 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 262 val_rmse: 0.4454 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 263 val_rmse: 0.4418 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 264 val_rmse: 0.44 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 265 val_rmse: 0.4398 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 266 val_rmse: 0.4396 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 267 val_rmse: 0.4395 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 268 val_rmse: 0.4395 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 269 val_rmse: 0.4401 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 270 val_rmse: 0.4405 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 271 val_rmse: 0.4395 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 272 val_rmse: 0.4394 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 273 val_rmse: 0.4427 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 274 val_rmse: 0.4487 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 275 val_rmse: 0.4508 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 276 val_rmse: 0.459 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 277 val_rmse: 0.4709 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 279 val_rmse: 0.4831 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "4 steps took 2.54 seconds\n",
            "Epoch: 1 batch_num: 283 val_rmse: 0.4816 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "4 steps took 2.55 seconds\n",
            "Epoch: 1 batch_num: 287 val_rmse: 0.4374 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 288 val_rmse: 0.4662 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 289 val_rmse: 0.5044 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 1 batch_num: 305 val_rmse: 0.4427 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 306 val_rmse: 0.4418 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 307 val_rmse: 0.4415 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 308 val_rmse: 0.4415 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 309 val_rmse: 0.4421 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 310 val_rmse: 0.4428 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 311 val_rmse: 0.4418 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 312 val_rmse: 0.4423 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 313 val_rmse: 0.4409 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 314 val_rmse: 0.4393 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 315 val_rmse: 0.4392 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 316 val_rmse: 0.4383 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 317 val_rmse: 0.4395 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 318 val_rmse: 0.4425 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 319 val_rmse: 0.4486 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 320 val_rmse: 0.4562 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.64 seconds\n",
            "Epoch: 1 batch_num: 321 val_rmse: 0.4534 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 322 val_rmse: 0.4467 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 323 val_rmse: 0.4412 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 324 val_rmse: 0.4398 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 325 val_rmse: 0.4396 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 326 val_rmse: 0.4418 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 327 val_rmse: 0.4421 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 328 val_rmse: 0.4424 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.632 seconds\n",
            "Epoch: 1 batch_num: 329 val_rmse: 0.4437 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 330 val_rmse: 0.446 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 331 val_rmse: 0.4467 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.641 seconds\n",
            "Epoch: 1 batch_num: 332 val_rmse: 0.4421 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 333 val_rmse: 0.4395 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 334 val_rmse: 0.4491 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 335 val_rmse: 0.476 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 337 val_rmse: 0.5253 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 1 batch_num: 353 val_rmse: 0.4433 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 354 val_rmse: 0.4474 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 355 val_rmse: 0.4525 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 356 val_rmse: 0.4538 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 357 val_rmse: 0.4511 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 358 val_rmse: 0.4507 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 359 val_rmse: 0.4502 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 360 val_rmse: 0.4493 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 361 val_rmse: 0.4508 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 362 val_rmse: 0.4548 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 363 val_rmse: 0.4512 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 364 val_rmse: 0.4435 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 365 val_rmse: 0.4396 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 366 val_rmse: 0.4401 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 367 val_rmse: 0.4451 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 368 val_rmse: 0.4519 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 369 val_rmse: 0.4575 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 370 val_rmse: 0.4608 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 371 val_rmse: 0.468 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 372 val_rmse: 0.4671 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 373 val_rmse: 0.4733 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 375 val_rmse: 0.4549 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 376 val_rmse: 0.449 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 377 val_rmse: 0.4453 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 378 val_rmse: 0.4429 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 379 val_rmse: 0.4431 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 380 val_rmse: 0.4462 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 381 val_rmse: 0.4523 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.643 seconds\n",
            "Epoch: 1 batch_num: 382 val_rmse: 0.4591 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 383 val_rmse: 0.4624 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 384 val_rmse: 0.4572 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 385 val_rmse: 0.4482 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 386 val_rmse: 0.4426 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.644 seconds\n",
            "Epoch: 1 batch_num: 387 val_rmse: 0.4407 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 388 val_rmse: 0.4404 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 389 val_rmse: 0.4401 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 390 val_rmse: 0.4413 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 391 val_rmse: 0.4425 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 392 val_rmse: 0.4405 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 393 val_rmse: 0.4399 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 394 val_rmse: 0.4422 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 395 val_rmse: 0.4481 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 396 val_rmse: 0.4524 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 397 val_rmse: 0.4543 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.63 seconds\n",
            "Epoch: 1 batch_num: 398 val_rmse: 0.4523 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 399 val_rmse: 0.4467 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 400 val_rmse: 0.4411 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 401 val_rmse: 0.4402 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.643 seconds\n",
            "Epoch: 1 batch_num: 402 val_rmse: 0.4469 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 403 val_rmse: 0.4561 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 404 val_rmse: 0.4679 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 405 val_rmse: 0.4633 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 406 val_rmse: 0.4538 Still best_val_rmse: 0.4365 (from epoch 1)\n",
            "\n",
            "1 steps took 0.291 seconds\n",
            "Epoch: 1 batch_num: 407 val_rmse: 0.4401 Still best_val_rmse: 0.4365 (from epoch 1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-09-23 09:49:06,979]\u001b[0m Trial 6 finished with value: 0.4365008473396301 and parameters: {'base_lr': 4.968468501314881e-05, 'last_lr': 8.23811562140965e-05, 'schedule_func': <function get_cosine_with_hard_restarts_schedule_with_warmup at 0x7fb51fd03680>, 'batch_size': 8, 'optimizer': 'adam'}. Best is trial 0 with value: 0.4334683418273926.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "##### Using fold 0\n",
            "##### Using base_lr 0.0002791115409978205 last_lr 9.274988470321305e-05 epochs 2\n",
            "##### Using <function get_cosine_schedule_with_warmup at 0x7fb51fd035f0>\n",
            "Model path\n",
            "/content/gdrive/My Drive/feedback-prize-english-language-learning/0917-deberta-v3-/microsoft-deberta-v3-base_fold2_best2.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_indices\n",
            "3259\n",
            "<class 'numpy.ndarray'>\n",
            "train_dataset\n",
            "3259\n",
            "<class '__main__.CommonLitDataset'>\n",
            "val_dataset\n",
            "652\n",
            "<class '__main__.CommonLitDataset'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /content/gdrive/My Drive/feedback-prize-english-language-learning/deberta-v3-base were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias']\n",
            "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at /content/gdrive/My Drive/feedback-prize-english-language-learning/deberta-v3-base and are newly initialized: ['classifier.bias', 'pooler.dense.weight', 'classifier.weight', 'pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0434489585be42b9adab9b7d0e2b86f2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "16 steps took 11.8 seconds\n",
            "Epoch: 0 batch_num: 16 val_rmse: 1.129 New best_val_rmse: 1.129\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 32 val_rmse: 0.892 New best_val_rmse: 0.892\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 48 val_rmse: 0.7858 New best_val_rmse: 0.7858\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 64 val_rmse: 0.7957 Still best_val_rmse: 0.7858 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 80 val_rmse: 0.6364 New best_val_rmse: 0.6364\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 96 val_rmse: 0.6 New best_val_rmse: 0.6\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 112 val_rmse: 0.6331 Still best_val_rmse: 0.6 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 128 val_rmse: 0.6683 Still best_val_rmse: 0.6 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 144 val_rmse: 0.6173 Still best_val_rmse: 0.6 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 160 val_rmse: 0.6065 Still best_val_rmse: 0.6 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 176 val_rmse: 0.6927 Still best_val_rmse: 0.6 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 192 val_rmse: 0.6158 Still best_val_rmse: 0.6 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 208 val_rmse: 0.5291 New best_val_rmse: 0.5291\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 224 val_rmse: 0.6178 Still best_val_rmse: 0.5291 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 240 val_rmse: 0.7436 Still best_val_rmse: 0.5291 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 256 val_rmse: 0.6524 Still best_val_rmse: 0.5291 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 272 val_rmse: 0.6781 Still best_val_rmse: 0.5291 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 288 val_rmse: 0.6357 Still best_val_rmse: 0.5291 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 304 val_rmse: 0.6168 Still best_val_rmse: 0.5291 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 320 val_rmse: 0.6539 Still best_val_rmse: 0.5291 (from epoch 0)\n",
            "\n",
            "16 steps took 9.99 seconds\n",
            "Epoch: 0 batch_num: 336 val_rmse: 0.6209 Still best_val_rmse: 0.5291 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 352 val_rmse: 0.6639 Still best_val_rmse: 0.5291 (from epoch 0)\n",
            "\n",
            "16 steps took 9.99 seconds\n",
            "Epoch: 0 batch_num: 368 val_rmse: 0.6216 Still best_val_rmse: 0.5291 (from epoch 0)\n",
            "\n",
            "16 steps took 9.99 seconds\n",
            "Epoch: 0 batch_num: 384 val_rmse: 0.6302 Still best_val_rmse: 0.5291 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 0 batch_num: 400 val_rmse: 0.6177 Still best_val_rmse: 0.5291 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 1 batch_num: 8 val_rmse: 0.8149 Still best_val_rmse: 0.5291 (from epoch 0)\n",
            "\n",
            "16 steps took 9.99 seconds\n",
            "Epoch: 1 batch_num: 24 val_rmse: 0.6166 Still best_val_rmse: 0.5291 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 40 val_rmse: 0.6167 Still best_val_rmse: 0.5291 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 56 val_rmse: 0.6273 Still best_val_rmse: 0.5291 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 72 val_rmse: 0.7085 Still best_val_rmse: 0.5291 (from epoch 0)\n",
            "\n",
            "16 steps took 9.97 seconds\n",
            "Epoch: 1 batch_num: 88 val_rmse: 0.6175 Still best_val_rmse: 0.5291 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 104 val_rmse: 0.6812 Still best_val_rmse: 0.5291 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 120 val_rmse: 0.6235 Still best_val_rmse: 0.5291 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 136 val_rmse: 0.6186 Still best_val_rmse: 0.5291 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 152 val_rmse: 0.6339 Still best_val_rmse: 0.5291 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 168 val_rmse: 0.6184 Still best_val_rmse: 0.5291 (from epoch 0)\n",
            "\n",
            "16 steps took 9.99 seconds\n",
            "Epoch: 1 batch_num: 184 val_rmse: 0.6328 Still best_val_rmse: 0.5291 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 200 val_rmse: 0.6562 Still best_val_rmse: 0.5291 (from epoch 0)\n",
            "\n",
            "16 steps took 9.99 seconds\n",
            "Epoch: 1 batch_num: 216 val_rmse: 0.6498 Still best_val_rmse: 0.5291 (from epoch 0)\n",
            "\n",
            "16 steps took 9.99 seconds\n",
            "Epoch: 1 batch_num: 232 val_rmse: 0.6204 Still best_val_rmse: 0.5291 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 248 val_rmse: 0.6174 Still best_val_rmse: 0.5291 (from epoch 0)\n",
            "\n",
            "16 steps took 9.99 seconds\n",
            "Epoch: 1 batch_num: 264 val_rmse: 0.6161 Still best_val_rmse: 0.5291 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 280 val_rmse: 0.6371 Still best_val_rmse: 0.5291 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 296 val_rmse: 0.6169 Still best_val_rmse: 0.5291 (from epoch 0)\n",
            "\n",
            "16 steps took 9.99 seconds\n",
            "Epoch: 1 batch_num: 312 val_rmse: 0.6234 Still best_val_rmse: 0.5291 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 328 val_rmse: 0.621 Still best_val_rmse: 0.5291 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 344 val_rmse: 0.6243 Still best_val_rmse: 0.5291 (from epoch 0)\n",
            "\n",
            "16 steps took 9.99 seconds\n",
            "Epoch: 1 batch_num: 360 val_rmse: 0.6176 Still best_val_rmse: 0.5291 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 376 val_rmse: 0.6164 Still best_val_rmse: 0.5291 (from epoch 0)\n",
            "\n",
            "16 steps took 10.0 seconds\n",
            "Epoch: 1 batch_num: 392 val_rmse: 0.6225 Still best_val_rmse: 0.5291 (from epoch 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-09-23 10:13:56,885]\u001b[0m Trial 7 finished with value: 0.5290858149528503 and parameters: {'base_lr': 0.0002791115409978205, 'last_lr': 9.274988470321305e-05, 'schedule_func': <function get_cosine_schedule_with_warmup at 0x7fb51fd035f0>, 'batch_size': 4, 'optimizer': 'adam'}. Best is trial 0 with value: 0.4334683418273926.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "##### Using fold 0\n",
            "##### Using base_lr 0.00027437272047720643 last_lr 0.00014902850451245248 epochs 2\n",
            "##### Using <function get_cosine_schedule_with_warmup at 0x7fb51fd035f0>\n",
            "Model path\n",
            "/content/gdrive/My Drive/feedback-prize-english-language-learning/0917-deberta-v3-/microsoft-deberta-v3-base_fold2_best2.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_indices\n",
            "3259\n",
            "<class 'numpy.ndarray'>\n",
            "train_dataset\n",
            "3259\n",
            "<class '__main__.CommonLitDataset'>\n",
            "val_dataset\n",
            "652\n",
            "<class '__main__.CommonLitDataset'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /content/gdrive/My Drive/feedback-prize-english-language-learning/deberta-v3-base were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias']\n",
            "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at /content/gdrive/My Drive/feedback-prize-english-language-learning/deberta-v3-base and are newly initialized: ['classifier.bias', 'pooler.dense.weight', 'classifier.weight', 'pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "acf1a21b13ed4ad0b418cbcde0a4b968",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "16 steps took 11.8 seconds\n",
            "Epoch: 0 batch_num: 16 val_rmse: 1.16 New best_val_rmse: 1.16\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 32 val_rmse: 0.8397 New best_val_rmse: 0.8397\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 48 val_rmse: 0.8024 New best_val_rmse: 0.8024\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 64 val_rmse: 0.8013 New best_val_rmse: 0.8013\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 80 val_rmse: 0.6319 New best_val_rmse: 0.6319\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 96 val_rmse: 0.6365 Still best_val_rmse: 0.6319 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 112 val_rmse: 0.6874 Still best_val_rmse: 0.6319 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 128 val_rmse: 0.6234 New best_val_rmse: 0.6234\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 144 val_rmse: 0.6223 New best_val_rmse: 0.6223\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 160 val_rmse: 0.631 Still best_val_rmse: 0.6223 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 176 val_rmse: 0.6873 Still best_val_rmse: 0.6223 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 192 val_rmse: 0.5076 New best_val_rmse: 0.5076\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 208 val_rmse: 0.5439 Still best_val_rmse: 0.5076 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 224 val_rmse: 0.5361 Still best_val_rmse: 0.5076 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 240 val_rmse: 0.5844 Still best_val_rmse: 0.5076 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 256 val_rmse: 0.5394 Still best_val_rmse: 0.5076 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 272 val_rmse: 0.5061 New best_val_rmse: 0.5061\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 288 val_rmse: 0.5184 Still best_val_rmse: 0.5061 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 304 val_rmse: 0.496 New best_val_rmse: 0.496\n",
            "\n",
            "8 steps took 5.08 seconds\n",
            "Epoch: 0 batch_num: 312 val_rmse: 0.5202 Still best_val_rmse: 0.496 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 328 val_rmse: 0.5267 Still best_val_rmse: 0.496 (from epoch 0)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 0 batch_num: 344 val_rmse: 0.5283 Still best_val_rmse: 0.496 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 360 val_rmse: 0.4752 New best_val_rmse: 0.4752\n",
            "\n",
            "2 steps took 1.28 seconds\n",
            "Epoch: 0 batch_num: 362 val_rmse: 0.4726 New best_val_rmse: 0.4726\n",
            "\n",
            "2 steps took 1.26 seconds\n",
            "Epoch: 0 batch_num: 364 val_rmse: 0.4756 Still best_val_rmse: 0.4726 (from epoch 0)\n",
            "\n",
            "2 steps took 1.26 seconds\n",
            "Epoch: 0 batch_num: 366 val_rmse: 0.4926 Still best_val_rmse: 0.4726 (from epoch 0)\n",
            "\n",
            "8 steps took 5.07 seconds\n",
            "Epoch: 0 batch_num: 374 val_rmse: 0.6015 Still best_val_rmse: 0.4726 (from epoch 0)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 0 batch_num: 390 val_rmse: 0.4905 Still best_val_rmse: 0.4726 (from epoch 0)\n",
            "\n",
            "8 steps took 5.07 seconds\n",
            "Epoch: 0 batch_num: 398 val_rmse: 0.4976 Still best_val_rmse: 0.4726 (from epoch 0)\n",
            "\n",
            "8 steps took 5.07 seconds\n",
            "Epoch: 0 batch_num: 406 val_rmse: 0.4998 Still best_val_rmse: 0.4726 (from epoch 0)\n",
            "\n",
            "8 steps took 5.15 seconds\n",
            "Epoch: 1 batch_num: 6 val_rmse: 0.4861 Still best_val_rmse: 0.4726 (from epoch 0)\n",
            "\n",
            "4 steps took 2.53 seconds\n",
            "Epoch: 1 batch_num: 10 val_rmse: 0.4708 New best_val_rmse: 0.4708\n",
            "\n",
            "2 steps took 1.29 seconds\n",
            "Epoch: 1 batch_num: 12 val_rmse: 0.4692 New best_val_rmse: 0.4692\n",
            "\n",
            "1 steps took 0.637 seconds\n",
            "Epoch: 1 batch_num: 13 val_rmse: 0.4769 Still best_val_rmse: 0.4692 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 15 val_rmse: 0.5046 Still best_val_rmse: 0.4692 (from epoch 1)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 1 batch_num: 31 val_rmse: 0.6311 Still best_val_rmse: 0.4692 (from epoch 1)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 1 batch_num: 47 val_rmse: 0.4816 Still best_val_rmse: 0.4692 (from epoch 1)\n",
            "\n",
            "4 steps took 2.53 seconds\n",
            "Epoch: 1 batch_num: 51 val_rmse: 0.5005 Still best_val_rmse: 0.4692 (from epoch 1)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 1 batch_num: 67 val_rmse: 0.4617 New best_val_rmse: 0.4617\n",
            "\n",
            "1 steps took 0.651 seconds\n",
            "Epoch: 1 batch_num: 68 val_rmse: 0.4761 Still best_val_rmse: 0.4617 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 70 val_rmse: 0.4718 Still best_val_rmse: 0.4617 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 72 val_rmse: 0.4741 Still best_val_rmse: 0.4617 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 74 val_rmse: 0.51 Still best_val_rmse: 0.4617 (from epoch 1)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 1 batch_num: 90 val_rmse: 0.6614 Still best_val_rmse: 0.4617 (from epoch 1)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 1 batch_num: 106 val_rmse: 0.5109 Still best_val_rmse: 0.4617 (from epoch 1)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 1 batch_num: 122 val_rmse: 0.5189 Still best_val_rmse: 0.4617 (from epoch 1)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 1 batch_num: 138 val_rmse: 0.4799 Still best_val_rmse: 0.4617 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 140 val_rmse: 0.4995 Still best_val_rmse: 0.4617 (from epoch 1)\n",
            "\n",
            "8 steps took 5.06 seconds\n",
            "Epoch: 1 batch_num: 148 val_rmse: 0.4813 Still best_val_rmse: 0.4617 (from epoch 1)\n",
            "\n",
            "4 steps took 2.54 seconds\n",
            "Epoch: 1 batch_num: 152 val_rmse: 0.4927 Still best_val_rmse: 0.4617 (from epoch 1)\n",
            "\n",
            "8 steps took 5.06 seconds\n",
            "Epoch: 1 batch_num: 160 val_rmse: 0.4781 Still best_val_rmse: 0.4617 (from epoch 1)\n",
            "\n",
            "2 steps took 1.26 seconds\n",
            "Epoch: 1 batch_num: 162 val_rmse: 0.471 Still best_val_rmse: 0.4617 (from epoch 1)\n",
            "\n",
            "2 steps took 1.26 seconds\n",
            "Epoch: 1 batch_num: 164 val_rmse: 0.4728 Still best_val_rmse: 0.4617 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 166 val_rmse: 0.5013 Still best_val_rmse: 0.4617 (from epoch 1)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 1 batch_num: 182 val_rmse: 0.4814 Still best_val_rmse: 0.4617 (from epoch 1)\n",
            "\n",
            "4 steps took 2.53 seconds\n",
            "Epoch: 1 batch_num: 186 val_rmse: 0.4675 Still best_val_rmse: 0.4617 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 187 val_rmse: 0.4675 Still best_val_rmse: 0.4617 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 188 val_rmse: 0.4709 Still best_val_rmse: 0.4617 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 190 val_rmse: 0.46 New best_val_rmse: 0.46\n",
            "\n",
            "1 steps took 0.659 seconds\n",
            "Epoch: 1 batch_num: 191 val_rmse: 0.4588 New best_val_rmse: 0.4588\n",
            "\n",
            "1 steps took 0.641 seconds\n",
            "Epoch: 1 batch_num: 192 val_rmse: 0.4615 Still best_val_rmse: 0.4588 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 193 val_rmse: 0.4749 Still best_val_rmse: 0.4588 (from epoch 1)\n",
            "\n",
            "2 steps took 1.26 seconds\n",
            "Epoch: 1 batch_num: 195 val_rmse: 0.4799 Still best_val_rmse: 0.4588 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 197 val_rmse: 0.4672 Still best_val_rmse: 0.4588 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 198 val_rmse: 0.4717 Still best_val_rmse: 0.4588 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 200 val_rmse: 0.4716 Still best_val_rmse: 0.4588 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 202 val_rmse: 0.4688 Still best_val_rmse: 0.4588 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 203 val_rmse: 0.4703 Still best_val_rmse: 0.4588 (from epoch 1)\n",
            "\n",
            "2 steps took 1.26 seconds\n",
            "Epoch: 1 batch_num: 205 val_rmse: 0.4681 Still best_val_rmse: 0.4588 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 206 val_rmse: 0.4716 Still best_val_rmse: 0.4588 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 208 val_rmse: 0.4884 Still best_val_rmse: 0.4588 (from epoch 1)\n",
            "\n",
            "4 steps took 2.55 seconds\n",
            "Epoch: 1 batch_num: 212 val_rmse: 0.5249 Still best_val_rmse: 0.4588 (from epoch 1)\n",
            "\n",
            "16 steps took 10.2 seconds\n",
            "Epoch: 1 batch_num: 228 val_rmse: 0.4925 Still best_val_rmse: 0.4588 (from epoch 1)\n",
            "\n",
            "8 steps took 5.06 seconds\n",
            "Epoch: 1 batch_num: 236 val_rmse: 0.477 Still best_val_rmse: 0.4588 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 238 val_rmse: 0.4792 Still best_val_rmse: 0.4588 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 240 val_rmse: 0.4717 Still best_val_rmse: 0.4588 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 242 val_rmse: 0.4726 Still best_val_rmse: 0.4588 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 244 val_rmse: 0.4916 Still best_val_rmse: 0.4588 (from epoch 1)\n",
            "\n",
            "8 steps took 5.06 seconds\n",
            "Epoch: 1 batch_num: 252 val_rmse: 0.4572 New best_val_rmse: 0.4572\n",
            "\n",
            "1 steps took 0.657 seconds\n",
            "Epoch: 1 batch_num: 253 val_rmse: 0.4601 Still best_val_rmse: 0.4572 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 254 val_rmse: 0.4631 Still best_val_rmse: 0.4572 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 255 val_rmse: 0.4614 Still best_val_rmse: 0.4572 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 256 val_rmse: 0.4579 Still best_val_rmse: 0.4572 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 257 val_rmse: 0.457 New best_val_rmse: 0.457\n",
            "\n",
            "1 steps took 0.655 seconds\n",
            "Epoch: 1 batch_num: 258 val_rmse: 0.4552 New best_val_rmse: 0.4552\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 259 val_rmse: 0.4555 Still best_val_rmse: 0.4552 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 260 val_rmse: 0.4607 Still best_val_rmse: 0.4552 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 261 val_rmse: 0.4702 Still best_val_rmse: 0.4552 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 263 val_rmse: 0.4796 Still best_val_rmse: 0.4552 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 265 val_rmse: 0.4571 Still best_val_rmse: 0.4552 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 266 val_rmse: 0.4533 New best_val_rmse: 0.4533\n",
            "\n",
            "1 steps took 0.64 seconds\n",
            "Epoch: 1 batch_num: 267 val_rmse: 0.4534 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 268 val_rmse: 0.4536 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 269 val_rmse: 0.4538 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "1 steps took 0.631 seconds\n",
            "Epoch: 1 batch_num: 270 val_rmse: 0.4562 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "1 steps took 0.631 seconds\n",
            "Epoch: 1 batch_num: 271 val_rmse: 0.4606 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 272 val_rmse: 0.4678 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 273 val_rmse: 0.4677 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 274 val_rmse: 0.4632 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "1 steps took 0.64 seconds\n",
            "Epoch: 1 batch_num: 275 val_rmse: 0.4559 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 276 val_rmse: 0.4558 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "1 steps took 0.63 seconds\n",
            "Epoch: 1 batch_num: 277 val_rmse: 0.4558 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 278 val_rmse: 0.4564 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "1 steps took 0.631 seconds\n",
            "Epoch: 1 batch_num: 279 val_rmse: 0.4574 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "1 steps took 0.631 seconds\n",
            "Epoch: 1 batch_num: 280 val_rmse: 0.4549 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 281 val_rmse: 0.4541 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "1 steps took 0.639 seconds\n",
            "Epoch: 1 batch_num: 282 val_rmse: 0.4682 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 283 val_rmse: 0.475 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 285 val_rmse: 0.4792 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 287 val_rmse: 0.4604 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "1 steps took 0.632 seconds\n",
            "Epoch: 1 batch_num: 288 val_rmse: 0.4635 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "1 steps took 0.635 seconds\n",
            "Epoch: 1 batch_num: 289 val_rmse: 0.4648 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 290 val_rmse: 0.4714 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 292 val_rmse: 0.492 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "8 steps took 5.08 seconds\n",
            "Epoch: 1 batch_num: 300 val_rmse: 0.463 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "1 steps took 0.631 seconds\n",
            "Epoch: 1 batch_num: 301 val_rmse: 0.4611 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 302 val_rmse: 0.4901 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "8 steps took 5.07 seconds\n",
            "Epoch: 1 batch_num: 310 val_rmse: 0.5001 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 1 batch_num: 326 val_rmse: 0.5908 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 1 batch_num: 342 val_rmse: 0.4771 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "2 steps took 1.26 seconds\n",
            "Epoch: 1 batch_num: 344 val_rmse: 0.5163 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 1 batch_num: 360 val_rmse: 0.5235 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 1 batch_num: 376 val_rmse: 0.5008 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "16 steps took 10.1 seconds\n",
            "Epoch: 1 batch_num: 392 val_rmse: 0.4672 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "1 steps took 0.63 seconds\n",
            "Epoch: 1 batch_num: 393 val_rmse: 0.4616 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 394 val_rmse: 0.4575 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 395 val_rmse: 0.4571 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "1 steps took 0.636 seconds\n",
            "Epoch: 1 batch_num: 396 val_rmse: 0.4573 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "1 steps took 0.632 seconds\n",
            "Epoch: 1 batch_num: 397 val_rmse: 0.4575 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "1 steps took 0.638 seconds\n",
            "Epoch: 1 batch_num: 398 val_rmse: 0.4581 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 399 val_rmse: 0.4608 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 400 val_rmse: 0.4626 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 401 val_rmse: 0.4682 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "1 steps took 0.633 seconds\n",
            "Epoch: 1 batch_num: 402 val_rmse: 0.4735 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "2 steps took 1.27 seconds\n",
            "Epoch: 1 batch_num: 404 val_rmse: 0.458 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "1 steps took 0.629 seconds\n",
            "Epoch: 1 batch_num: 405 val_rmse: 0.458 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "1 steps took 0.634 seconds\n",
            "Epoch: 1 batch_num: 406 val_rmse: 0.4586 Still best_val_rmse: 0.4533 (from epoch 1)\n",
            "\n",
            "1 steps took 0.293 seconds\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "[I 2022-09-20 22:50:25,743] Trial 2 finished with value: 0.4340265095233917 and parameters: \n",
        "{'base_lr': 6.589032198953331e-05, 'last_lr': 0.00022464473383019027, \n",
        "'schedule_func': <function get_cosine_schedule_with_warmup at 0x7f92e04fc3b0>, \n",
        "'batch_size': 2, 'optimizer': 'adamw'}. Best is trial 2 with value: 0.4340265095233917.\n",
        "\n",
        "'''\n",
        "\n",
        "for i in range(0, 1):\n",
        "    fold = i\n",
        "    study = optuna.create_study(direction=\"minimize\")\n",
        "    study.optimize(objective, n_trials=10) #n_trials=20\n",
        "\n",
        "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "\n",
        "    print(\"Study statistics: \")\n",
        "    print(\"  Number of finished trials: \", len(study.trials))\n",
        "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "    print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "    print(\"Best trial:\")\n",
        "    trial = study.best_trial\n",
        "\n",
        "    print(\"  Value: \", trial.value)\n",
        "\n",
        "    print(\"  Params: \")\n",
        "    for key, value in trial.params.items():\n",
        "        print(\"    {}: {}\".format(key, value))\n",
        "\n",
        "\n",
        "    print(\" Best value: \", study.best_trial.value)\n",
        "    print(\" Best  params: \")\n",
        "    for key, value in study.best_trial.params.items():\n",
        "        print(f\"    {key}: {value}\")\n"
      ],
      "id": "48210ee3-d9ea-4bab-b852-627f6f75ce0c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efb49c7b-f2b8-4929-bd03-2b74c20361cf"
      },
      "outputs": [],
      "source": [
        "\n",
        "'''\n",
        "\n",
        "[I 2022-09-23 05:23:45,709] Trial 0 finished with value: 0.4334683418273926 and parameters: {\n",
        "  'base_lr': 3.577643544798571e-05, 'last_lr': 0.0015857753780737184, \n",
        "  'schedule_func': <function get_cosine_with_hard_restarts_schedule_with_warmup at 0x7fb51fd03680>, \n",
        "  'batch_size': 2, \n",
        "  'optimizer': 'adam'}. Best is trial 0 with value: 0.4334683418273926.\n",
        "\n",
        "\n",
        "\n",
        "%%time\n",
        "\n",
        "for i in range(4, 5):\n",
        "    fold = i\n",
        "    study = optuna.create_study(direction=\"minimize\")\n",
        "    study.optimize(objective, n_trials=20)\n",
        "    print(\" Best value: \", study.best_trial.value)\n",
        "    print(\" Best params: \")\n",
        "    for key, value in study.best_trial.params.items():\n",
        "        print(f\"    {key}: {value}\")\n",
        "'''\n"
      ],
      "id": "efb49c7b-f2b8-4929-bd03-2b74c20361cf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d360e24c-6ca3-4486-b2ba-27d94cb53913"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "for i in range(4, len(list(splits))):\n",
        "    fold = i\n",
        "    study = optuna.create_study(direction=\"minimize\")\n",
        "    study.optimize(objective, n_trials=20)\n",
        "    print(\" Best value: \", study.best_trial.value)\n",
        "    print(\" Best params: \")\n",
        "    for key, value in study.best_trial.params.items():\n",
        "        print(f\"    {key}: {value}\")\n",
        "'''"
      ],
      "id": "d360e24c-6ca3-4486-b2ba-27d94cb53913"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20a69a20-e7bd-4426-8394-9fe92ff4ceba"
      },
      "source": [
        "### Verify the model"
      ],
      "id": "20a69a20-e7bd-4426-8394-9fe92ff4ceba"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1d2f26d-f0bc-4d35-b970-a18b100c97f7"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tqdm.notebook import tqdm"
      ],
      "id": "b1d2f26d-f0bc-4d35-b970-a18b100c97f7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "820cfbb0-36c6-41e7-b98e-d5ecc379c827"
      },
      "outputs": [],
      "source": [
        "cfg.model_offset = 0\n",
        "cfg.model_limit = 6\n",
        "cfg.n_folds = 5\n",
        "cfg.svm_kernels = ['rbf']\n",
        "cfg.svm_c = 5"
      ],
      "id": "820cfbb0-36c6-41e7-b98e-d5ecc379c827"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34fe3330-3d2c-49c5-be98-69a13cf2a3e3"
      },
      "outputs": [],
      "source": [
        "num_bins = int(np.ceil(np.log2(len(train_df))))\n",
        "train_df['bins'] = pd.cut(train_df['syntax'], bins=num_bins, labels=False)\n",
        "bins = train_df['bins'].values"
      ],
      "id": "34fe3330-3d2c-49c5-be98-69a13cf2a3e3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9508c0ef-984f-4af5-a283-88498c1dcabd"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "inference_models = []\n",
        "for i in range(1, cfg.NUM_FOLDS + 1):\n",
        "    print(f'Model {i}')\n",
        "    inference_model = CommonLitModel()\n",
        "    inference_model = inference_model.cuda()\n",
        "    inference_model.load_state_dict(torch.load(str(MODELS_PATH/f\"{cfg.model_name.replace('/', '_')}_{i}/model_{i}.pth\")))\n",
        "    inference_model.eval();\n",
        "    inference_models.append(inference_model)"
      ],
      "id": "9508c0ef-984f-4af5-a283-88498c1dcabd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "386a6b85-3e21-44c5-bbe1-347c12d4c864"
      },
      "outputs": [],
      "source": [
        "from transformers import RobertaTokenizer\n",
        "\n",
        "tokenizers = []\n",
        "for i in range(1, cfg.NUM_FOLDS):\n",
        "    tokenizer = RobertaTokenizer.from_pretrained(MODELS_PATH + \"/\" + f\"{cfg.model_name.replace('/', '_')}_{i}\")\n",
        "    tokenizers.append(tokenizer)"
      ],
      "id": "386a6b85-3e21-44c5-bbe1-347c12d4c864"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6479666-2703-4691-831c-6a1a493924b0"
      },
      "outputs": [],
      "source": [
        "def get_cls_embeddings(dl, transformer_model):\n",
        "    cls_embeddings = []\n",
        "    with torch.no_grad():\n",
        "        for input_features in tqdm(dl, total=len(dl)):\n",
        "            output, context_vector = transformer_model(input_features['input_ids'].cuda(), input_features['attention_mask'].cuda())\n",
        "#             cls_embeddings.extend(output['last_hidden_state'][:,0,:].detach().cpu().numpy())\n",
        "            embedding_out = context_vector.detach().cpu().numpy()\n",
        "            cls_embeddings.extend(embedding_out)\n",
        "    return np.array(cls_embeddings)"
      ],
      "id": "e6479666-2703-4691-831c-6a1a493924b0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cb0cd48-b89a-4be9-b3f8-75f79133292e"
      },
      "outputs": [],
      "source": [
        "def rmse_score(X, y):\n",
        "    return np.sqrt(mean_squared_error(X, y))"
      ],
      "id": "9cb0cd48-b89a-4be9-b3f8-75f79133292e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c29dc0cb-b3d7-448c-8166-0716b76860c2"
      },
      "outputs": [],
      "source": [
        "def convert_to_list(t):\n",
        "    return t.flatten().long()\n",
        "\n",
        "class CommonLitDataset(nn.Module):\n",
        "    def __init__(self, text, test_id, tokenizer, max_len=128):\n",
        "        self.excerpt = text\n",
        "        self.test_id = test_id\n",
        "        self.max_len = max_len\n",
        "        self.tokenizer = tokenizer\n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        encode = self.tokenizer(self.excerpt[idx],\n",
        "                                return_tensors='pt',\n",
        "                                max_length=self.max_len,\n",
        "                                padding='max_length',\n",
        "                                truncation=True)\n",
        "        return {'input_ids': convert_to_list(encode['input_ids']),\n",
        "                'attention_mask': convert_to_list(encode['attention_mask']),\n",
        "                'id': self.test_id[idx]}\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.excerpt)"
      ],
      "id": "c29dc0cb-b3d7-448c-8166-0716b76860c2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c69fc14c-d0c9-486c-b15c-1aa2d81ad424"
      },
      "outputs": [],
      "source": [
        "def create_dl(df, tokenizer):\n",
        "    text = df['full_text'].values\n",
        "    ids = df['text_id'].values\n",
        "    ds = CommonLitDataset(text, ids, tokenizer, max_len=cfg.MAX_LEN)\n",
        "    return DataLoader(ds, \n",
        "                      batch_size = cfg.BATCH_SIZE,\n",
        "                      shuffle=False,\n",
        "                      num_workers = 1,\n",
        "                      pin_memory=True,\n",
        "                      drop_last=False\n",
        "                     )"
      ],
      "id": "c69fc14c-d0c9-486c-b15c-1aa2d81ad424"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7052da7-31ff-4863-a4bf-ff6bb5829873"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(DATA_PATH + '/train-orig.csv')\n",
        "test_df = pd.read_csv(DATA_PATH + '/test.csv')\n",
        "remove_unnecessary(train_df)"
      ],
      "id": "b7052da7-31ff-4863-a4bf-ff6bb5829873"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a59f88ec-0471-4d1a-8270-f610141382b2"
      },
      "outputs": [],
      "source": [
        "train_target_mean = train_df['syntax'].mean()\n",
        "train_target_std = train_df['syntax'].std()\n",
        "train_df['normalized_target'] = (train_df['syntax'] - train_target_mean) / train_target_std"
      ],
      "id": "a59f88ec-0471-4d1a-8270-f610141382b2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efdb532e-9f76-406b-ba60-c8991851faf8"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "train_target = train_df['normalized_target'].values\n",
        "\n",
        "def calc_mean(scores):\n",
        "    return np.mean(np.array(scores), axis=0)\n",
        "\n",
        "final_scores = []\n",
        "final_rmse = []\n",
        "kernel_rmse_score_mean = []\n",
        "final_kernel_predictions_means = []\n",
        "for j, (inference_model, tokenizer) in enumerate(zip(inference_models, tokenizers)):\n",
        "    print('Model', j)\n",
        "    test_dl = create_dl(test_df, tokenizer)\n",
        "    train_dl = create_dl(train_df, tokenizer)\n",
        "    transformer_model = inference_model\n",
        "    transformer_model.cuda()\n",
        "    X = get_cls_embeddings(train_dl, transformer_model)\n",
        "    \n",
        "    y = train_target\n",
        "    X_test = get_cls_embeddings(test_dl, transformer_model)\n",
        "    \n",
        "    kfold = StratifiedKFold(n_splits=cfg.NUM_FOLDS)\n",
        "    scores = []\n",
        "    rmse_scores = []\n",
        "    kernel_predictions_means = []\n",
        "    for kernel in cfg.svm_kernels:\n",
        "        print('Kernel', kernel)\n",
        "        kernel_scores = []\n",
        "        kernel_rmse_scores = []\n",
        "        kernel_predictions = []\n",
        "        for k, (train_idx, valid_idx) in enumerate(kfold.split(X, bins)):\n",
        "\n",
        "            print('Fold', k, train_idx.shape, valid_idx.shape)\n",
        "            model = SVR(C=cfg.svm_c, kernel=kernel, gamma='auto')\n",
        "\n",
        "            X_train, y_train = X[train_idx], y[train_idx]\n",
        "            X_valid, y_valid = X[valid_idx], y[valid_idx]\n",
        "            model.fit(X_train, y_train)\n",
        "            prediction = model.predict(X_valid)\n",
        "            kernel_predictions.append(prediction)\n",
        "            kernel_rmse_scores.append(rmse_score(prediction, y_valid))\n",
        "            print('rmse_score', kernel_rmse_scores[k])\n",
        "            kernel_scores.append(model.predict(X_test))\n",
        "        kernel_predictions_means.append(np.array([np.mean(kp) for kp in kernel_predictions]).mean())\n",
        "        scores.append(calc_mean(kernel_scores))\n",
        "        kernel_rmse_score = calc_mean(kernel_rmse_scores)\n",
        "        kernel_rmse_score_mean.append(kernel_rmse_score)\n",
        "        rmse_scores.append(kernel_rmse_score)\n",
        "    final_kernel_predictions_means.append(kernel_predictions_means)\n",
        "    final_scores.append(calc_mean(scores))\n",
        "    final_rmse.append(calc_mean(rmse_scores))\n",
        "print('FINAL RMSE score', np.mean(np.array(final_rmse)))"
      ],
      "id": "efdb532e-9f76-406b-ba60-c8991851faf8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7e1ac2d7-605a-4cc7-8bd0-8eec0ec6f40d"
      },
      "outputs": [],
      "source": [
        "final_kernel_predictions_means"
      ],
      "id": "7e1ac2d7-605a-4cc7-8bd0-8eec0ec6f40d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0b649aa-784d-4dbf-83e4-252ca3f2bfc9"
      },
      "outputs": [],
      "source": [
        "# (train_df['target'] - cfg.train_target_mean) / cfg.train_target_std\n",
        "final_scores_normalized = np.array(final_scores) * train_target_std + train_target_mean"
      ],
      "id": "b0b649aa-784d-4dbf-83e4-252ca3f2bfc9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8fd46e8-1542-4a71-82ca-d6d4838d7470"
      },
      "outputs": [],
      "source": [
        "kernel_rmse_score_mean_array = np.array(kernel_rmse_score_mean)\n",
        "kernel_rmse_score_mean_sum = np.sum(kernel_rmse_score_mean_array)\n",
        "prop_losses = kernel_rmse_score_mean_array / kernel_rmse_score_mean_sum\n",
        "prop_losses_sum = (1 - prop_losses).sum()\n",
        "weights = (1 - prop_losses) / prop_losses_sum\n",
        "weights"
      ],
      "id": "e8fd46e8-1542-4a71-82ca-d6d4838d7470"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "040b9381-2a90-4183-b305-59f6d233017a"
      },
      "outputs": [],
      "source": [
        "def calc_mean(scores, weights=weights):\n",
        "    return np.average(np.array(scores), weights=weights, axis=0)"
      ],
      "id": "040b9381-2a90-4183-b305-59f6d233017a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03c0f5a2-7e63-4799-ad55-1a733b24a08b"
      },
      "outputs": [],
      "source": [
        "target_mean = train_df['syntax'].mean()\n",
        "final_scores_flat = calc_mean(final_scores_normalized).flatten()\n",
        "final_scores_mean = final_scores_flat.mean()\n",
        "target_mean, np.array(final_scores_normalized).mean()\n",
        "# (-0.9579984513405823, -0.8029817438292849)"
      ],
      "id": "03c0f5a2-7e63-4799-ad55-1a733b24a08b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "345a4669-2c5d-49e6-8dec-f9abb9cd8153"
      },
      "outputs": [],
      "source": [
        "final_scores_flat"
      ],
      "id": "345a4669-2c5d-49e6-8dec-f9abb9cd8153"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4614a6c5-af82-4b2c-bf5a-f1180109426a"
      },
      "outputs": [],
      "source": [
        "mean_diff = target_mean - final_scores_mean\n",
        "mean_diff, mean_diff / len(final_scores)"
      ],
      "id": "4614a6c5-af82-4b2c-bf5a-f1180109426a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29fd92a7-a55f-422a-bfae-7f475bd5f871"
      },
      "outputs": [],
      "source": [
        "sample_df['syntax'] = final_scores_flat + mean_diff\n",
        "# sample_df['target'] = len(final_scores) / np.sum(1 / np.array(final_scores), axis=0) # harmonic mean\n",
        "sample_df"
      ],
      "id": "29fd92a7-a55f-422a-bfae-7f475bd5f871"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1c995ca-ff1f-4b43-a41c-28d6ec11fa97"
      },
      "source": [
        "### Prepare Packaging"
      ],
      "id": "e1c995ca-ff1f-4b43-a41c-28d6ec11fa97"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1b9c5d5b-b293-4d59-b2e7-53131745079b"
      },
      "outputs": [],
      "source": [
        "cfg.model_name"
      ],
      "id": "1b9c5d5b-b293-4d59-b2e7-53131745079b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4993d2b0-3c68-4241-b15d-c51e10ee788b"
      },
      "outputs": [],
      "source": [
        "BEST_MODEL_FOLDER = MODELS_PATH/cfg.model_name/'best'\n",
        "!rm -rf {BEST_MODEL_FOLDER}\n",
        "!mkdir -p {BEST_MODEL_FOLDER}"
      ],
      "id": "4993d2b0-3c68-4241-b15d-c51e10ee788b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3e3faa7c-7b90-4fe2-aebf-cf9733a3674f"
      },
      "outputs": [],
      "source": [
        "BEST_MODEL_FOLDER"
      ],
      "id": "3e3faa7c-7b90-4fe2-aebf-cf9733a3674f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f44851d5-e456-4abd-972c-0838dd792714"
      },
      "outputs": [],
      "source": [
        "cfg.NUM_FOLDS"
      ],
      "id": "f44851d5-e456-4abd-972c-0838dd792714"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8b30572a-121f-4432-a83d-f49c6fa5e815"
      },
      "outputs": [],
      "source": [
        "bestmodels = [MODELS_PATH/f'{cfg.model_name}_{i + 1}' for i in range(0, cfg.NUM_FOLDS)]"
      ],
      "id": "8b30572a-121f-4432-a83d-f49c6fa5e815"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3a0cf4b3-862c-4676-bc1d-875cd32ce7a8"
      },
      "outputs": [],
      "source": [
        "bestmodels"
      ],
      "id": "3a0cf4b3-862c-4676-bc1d-875cd32ce7a8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85f114e7-7e75-43d8-8c4c-6889f6393b76"
      },
      "outputs": [],
      "source": [
        "from shutil import copyfile\n",
        "\n",
        "def normalize_name(path_name):\n",
        "    return path_name.replace('', '')\n",
        "\n",
        "for i, best_model in enumerate(bestmodels):\n",
        "    print(f'Processing {i}th model')\n",
        "    i = i + 1\n",
        "    best_model_file = f'{best_model}/model_{i}.pth'\n",
        "    if Path(best_model_file).exists():\n",
        "        copyfile(best_model_file, f'{BEST_MODEL_FOLDER}/{i}_pytorch_model.bin')\n",
        "        tokenizer_path = Path(BEST_MODEL_FOLDER/f'tokenizer-{i}')\n",
        "        tokenizer_path.mkdir(parents=True, exist_ok=True)\n",
        "        assert tokenizer_path.exists()\n",
        "\n",
        "        tokenizer_json = Path(normalize_name(f'{MODELS_PATH/cfg.model_name}_{i}/tokenizer_config.json'))\n",
        "        assert tokenizer_json.exists(), f'{tokenizer_json} does not exist'\n",
        "        copyfile(tokenizer_json, tokenizer_path/'tokenizer.json')\n",
        "\n",
        "        vocab_txt = Path(normalize_name(f'{MODELS_PATH/cfg.model_name}_{i}/vocab.json'))\n",
        "        assert vocab_txt.exists(), f'{vocab_txt} does not exist'\n",
        "        copyfile(vocab_txt, tokenizer_path/'vocab.json')\n",
        "\n",
        "        merges = Path(normalize_name(f'{MODELS_PATH/cfg.model_name}_{i}/merges.txt'))\n",
        "        assert merges.exists()\n",
        "        copyfile(merges, tokenizer_path/'merges.txt')\n",
        "    else:\n",
        "        print(f'{best_model_file} is missing')"
      ],
      "id": "85f114e7-7e75-43d8-8c4c-6889f6393b76"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bc422f71-d671-4eca-82f4-0dd059b1200e"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "shutil.make_archive(MODELS_PATH/cfg.model_name/'best_models', 'zip', BEST_MODEL_FOLDER)"
      ],
      "id": "bc422f71-d671-4eca-82f4-0dd059b1200e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fc9d2659-6041-47d9-ba4c-a8ecade644a7"
      },
      "outputs": [],
      "source": [
        "!ls {MODELS_PATH/cfg.model_name}"
      ],
      "id": "fc9d2659-6041-47d9-ba4c-a8ecade644a7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccbf7473-d8fd-4ff4-8b51-67028bc5d2fa"
      },
      "outputs": [],
      "source": [
        "!mv {MODELS_PATH}/{cfg.model_name}.yaml {MODELS_PATH/cfg.model_name}"
      ],
      "id": "ccbf7473-d8fd-4ff4-8b51-67028bc5d2fa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80bdcbd8-bed2-4ac9-91a0-93b35b0d2637"
      },
      "outputs": [],
      "source": [
        "transformer_model.transformer_model.save_pretrained(save_directory=f'{MODELS_PATH/cfg.model_name}/lm')"
      ],
      "id": "80bdcbd8-bed2-4ac9-91a0-93b35b0d2637"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ab5088d-df35-4b54-8de6-9c8a3bdc5054"
      },
      "outputs": [],
      "source": [
        "!du -h {MODELS_PATH/cfg.model_name}/*"
      ],
      "id": "6ab5088d-df35-4b54-8de6-9c8a3bdc5054"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "099a2e2d-e325-4b5f-ab68-71b1cc9d3af6"
      },
      "outputs": [],
      "source": [
        "shutil.make_archive(MODELS_PATH/cfg.model_name/'lm', 'zip', f'{MODELS_PATH/cfg.model_name}/lm')"
      ],
      "id": "099a2e2d-e325-4b5f-ab68-71b1cc9d3af6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4616c042-2877-470a-b227-948606188b58"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets init -p {MODELS_PATH/cfg.model_name}"
      ],
      "id": "4616c042-2877-470a-b227-948606188b58"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0e6984b-07d9-49e6-89b2-6066503bda93"
      },
      "outputs": [],
      "source": [
        "dataset_json_path = Path(MODELS_PATH/cfg.model_name/'dataset-metadata.json')\n",
        "assert dataset_json_path.exists()"
      ],
      "id": "c0e6984b-07d9-49e6-89b2-6066503bda93"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aafa049c-faa9-45da-af4f-554a2000f047"
      },
      "outputs": [],
      "source": [
        "!cat {str(dataset_json_path)}"
      ],
      "id": "aafa049c-faa9-45da-af4f-554a2000f047"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faf108e8-c48c-4134-809b-6c775ef5b1b5"
      },
      "outputs": [],
      "source": [
        "with open(dataset_json_path, 'r') as f:\n",
        "    dataset_json = f.read()\n",
        "    dataset_json = dataset_json.replace('INSERT_TITLE_HERE', f'commonlit-{cfg.model_name}-light').replace('INSERT_SLUG_HERE', f'commonlit-{cfg.model_name}-light')\n",
        "    print(dataset_json)\n",
        "with(open(dataset_json_path, 'w')) as f:\n",
        "    f.write(dataset_json)"
      ],
      "id": "faf108e8-c48c-4134-809b-6c775ef5b1b5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9877c0cb-0d80-43d6-a064-f929ad92b43e"
      },
      "outputs": [],
      "source": [
        "!rm -rf {MODELS_PATH/cfg.model_name}/best\n",
        "!rm -rf {MODELS_PATH/cfg.model_name}/lm"
      ],
      "id": "9877c0cb-0d80-43d6-a064-f929ad92b43e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "851185dc-f532-4920-bfc0-39f36f0224bb"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets create -p {MODELS_PATH/cfg.model_name}"
      ],
      "id": "851185dc-f532-4920-bfc0-39f36f0224bb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5d19f40a-df46-4f1d-b247-c627e7cf091c"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets version -p {MODELS_PATH/cfg.model_name} -m \"Version with merges.txt\" -d"
      ],
      "id": "5d19f40a-df46-4f1d-b247-c627e7cf091c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8ffe0ba-8412-4616-a0a4-78c0b4552f4b"
      },
      "outputs": [],
      "source": [
        "state_dict = torch.load(str(MODELS_PATH/f'distilroberta-0/checkpoint-105/pytorch_model.bin'))"
      ],
      "id": "f8ffe0ba-8412-4616-a0a4-78c0b4552f4b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "107e77de-3b71-408f-8d6c-25bae3e60f5e"
      },
      "outputs": [],
      "source": [
        "loaded_model = CommonLitModel()"
      ],
      "id": "107e77de-3b71-408f-8d6c-25bae3e60f5e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3de19b9-2d6b-41c1-a765-5c39551fe176"
      },
      "outputs": [],
      "source": [
        "loaded_model.load_state_dict(state_dict)"
      ],
      "id": "e3de19b9-2d6b-41c1-a765-5c39551fe176"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "859231b7-d595-463e-8ab7-1ac150193306"
      },
      "outputs": [],
      "source": [],
      "id": "859231b7-d595-463e-8ab7-1ac150193306"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00362774a3a4483db0058e3191a6fdaa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03609fd9407b4cad819897205be25795": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0434489585be42b9adab9b7d0e2b86f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4530e3a2fcc64f9d85f8a823772c6c03",
              "IPY_MODEL_9d00213a02354271b33fe6416f990f3c",
              "IPY_MODEL_7fa41932901a4ba9ab438db021c13ab6"
            ],
            "layout": "IPY_MODEL_2fea71869441416d91ec8e1ada11a682"
          }
        },
        "049f4adc9edc4613bcff8006daebb070": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c3756d81f5ce4bf9b7b65255fbb16ccb",
              "IPY_MODEL_62760582ede2419ea52aad9f0581ce32",
              "IPY_MODEL_9e3c0e794b6b4a05a2b820e9a0fcb7ab"
            ],
            "layout": "IPY_MODEL_d9ae0f8c8031415a9b41b484df58045d"
          }
        },
        "09c05d2b5f0c409da17eef91f70f1fbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd811ff4fb3c4cd593ab75229ba2f269",
              "IPY_MODEL_ab0fc8272b7343ab8dfd6e3e5419977c",
              "IPY_MODEL_e679cdd86c584f1b9281bf9f7f84a4c3"
            ],
            "layout": "IPY_MODEL_23dae928bb1341f2aa5031366d688672"
          }
        },
        "0afeb7cb684f4bf0a715bc3f24df4c12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0cd54542f16b4b789593db716088db30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6f99cafc22a84eefa4779cf58f7c4645",
              "IPY_MODEL_1fa142239bde4480b2dd4e1e1f124f0f",
              "IPY_MODEL_db4587a905df42fa8dca0a269ea25f9f"
            ],
            "layout": "IPY_MODEL_9e52ecf6f0f04f69a2105e7c267d9583"
          }
        },
        "0f8c22cbc7f844d79e9a69f3a03865e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10b2836914a4405d9bfa766baff8733d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "129ea341968249f3a35f724becf88170": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1541432391394fbfaceed522a55765ee",
            "placeholder": "​",
            "style": "IPY_MODEL_fda6ebbb48504b4d8d73e01e886d70b5",
            "value": " 2/2 [24:34&lt;00:00, 736.17s/it]"
          }
        },
        "12a85a5381104dd3b02dd939602c7466": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14738aafc055462ab3f8420fb383870f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1541432391394fbfaceed522a55765ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "185db4e3c9084cae8e41ce5f2eb0f998": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aacc28cb283e4d3289a748a01229bd2b",
            "placeholder": "​",
            "style": "IPY_MODEL_1fff40feb71b45db83ac74a8bce54791",
            "value": "Epoch: 1: 100%"
          }
        },
        "194c1be7078f42f385db452af1f4ad46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a269e972116429891a4b24c45b7150c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fa142239bde4480b2dd4e1e1f124f0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ab7129032b64ef8bfc832f12a0ffea8",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3bf8f0f7c315454195e35e3448ebd7bd",
            "value": 2
          }
        },
        "1fff40feb71b45db83ac74a8bce54791": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23cf86c20fe948d1adadb10869da011b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23dae928bb1341f2aa5031366d688672": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24947296fee143ecbbe05a4f88f96016": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e47ec956d864448afbacc2ab375f51b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fea71869441416d91ec8e1ada11a682": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37953eebe35c468d8b73157f8d9eb74e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc3ad48f882b4b3baa6e6ad675427d0d",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6bd007881764222a2db1376740caaa1",
            "value": 1
          }
        },
        "38a90602ba284c23b7270815ff1d9086": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bf8f0f7c315454195e35e3448ebd7bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c88df238991414e8204a1916a0bc0e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3dd04e53ab6746dca3475b6309ede9b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca8d7c27dd8042bbb3e425a929cf4a3c",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf0eea23318448cea384c260e92b1e46",
            "value": 2
          }
        },
        "406f354626ca4ad89ebbb86af233583f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4530e3a2fcc64f9d85f8a823772c6c03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38a90602ba284c23b7270815ff1d9086",
            "placeholder": "​",
            "style": "IPY_MODEL_14738aafc055462ab3f8420fb383870f",
            "value": "Epoch: 1: 100%"
          }
        },
        "4ab7129032b64ef8bfc832f12a0ffea8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "513ca98be4eb4231a1adea0ee9c6e32a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5351f0094377416abff31dea69238172",
            "placeholder": "​",
            "style": "IPY_MODEL_0f8c22cbc7f844d79e9a69f3a03865e2",
            "value": "Epoch: 1:  50%"
          }
        },
        "5351f0094377416abff31dea69238172": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "556dd0c57a4d4a029249b5a83315f443": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3c8adbee3854af8a18ab1cf97961771",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dddbc1880ea54efeb49fbd50a2158e96",
            "value": 2
          }
        },
        "55772880edde46a3a9d2992e54494d9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_185db4e3c9084cae8e41ce5f2eb0f998",
              "IPY_MODEL_556dd0c57a4d4a029249b5a83315f443",
              "IPY_MODEL_b1cdec34663e4bd08ad1c6eb18371a8d"
            ],
            "layout": "IPY_MODEL_bbbf4981209f4f7e8a008a150998e6b7"
          }
        },
        "5a4e67dc9ed54b978b602964e0fcc37b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b34b340693064ecca93d7ead7cee8ceb",
            "placeholder": "​",
            "style": "IPY_MODEL_d3dd42c03e3a42cb97a4cb004b428488",
            "value": " 1/2 [12:22&lt;12:21, 741.53s/it]"
          }
        },
        "5dffd65ae28d42e3ac52a7e1cac29d80": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60e4cc85bebd4a6ca2c3cc8dc38fa821": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61c31ae9ad51412b8951146fd0f65903": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62760582ede2419ea52aad9f0581ce32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f41cffe82a1844b883b107f114a259c5",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_10b2836914a4405d9bfa766baff8733d",
            "value": 2
          }
        },
        "6666ed7f91884d0e85653271f9acb21d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67a3efc5d6ee481fa8f25b136189aaf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23cf86c20fe948d1adadb10869da011b",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da54eab21c334c2dbff5643b5931e12b",
            "value": 2
          }
        },
        "68ca7b2b2f144b85ac90501bc7aebaf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9abef67aacd84158aaebacf4d4b89df9",
              "IPY_MODEL_3dd04e53ab6746dca3475b6309ede9b8",
              "IPY_MODEL_129ea341968249f3a35f724becf88170"
            ],
            "layout": "IPY_MODEL_60e4cc85bebd4a6ca2c3cc8dc38fa821"
          }
        },
        "6f99cafc22a84eefa4779cf58f7c4645": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce3599bd3a3745cc954d3f63c18f86b9",
            "placeholder": "​",
            "style": "IPY_MODEL_9526d7e3421f4cb199f1de7f074f204e",
            "value": "Epoch: 1: 100%"
          }
        },
        "729e27f0c98d432f80bb17c19293d1e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9074be9404a4b24bdf35c9dad6ebe69",
            "placeholder": "​",
            "style": "IPY_MODEL_194c1be7078f42f385db452af1f4ad46",
            "value": " 2/2 [47:00&lt;00:00, 1512.61s/it]"
          }
        },
        "781504b638fd4acb842a2b5dfe8aa78e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79a0f371b4cc442fa91b285bd6863379": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7ddf538ebfeb42fbad51fb556aa6b62f",
              "IPY_MODEL_67a3efc5d6ee481fa8f25b136189aaf7",
              "IPY_MODEL_729e27f0c98d432f80bb17c19293d1e0"
            ],
            "layout": "IPY_MODEL_eedd5ce0d4b647ce828ae3bf464e834d"
          }
        },
        "7ca07fc91670451d9bc4e78ee8751b77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ddf538ebfeb42fbad51fb556aa6b62f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_949b0c7987a24859ad0413c4c48c6fc1",
            "placeholder": "​",
            "style": "IPY_MODEL_ecb3cdecfa194e88b32aefb9067b2391",
            "value": "Epoch: 1: 100%"
          }
        },
        "7e5a3a5c30c24f829d020d80e94b037c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7fa41932901a4ba9ab438db021c13ab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffe99fe880254b9cb3d530a313ca2b0e",
            "placeholder": "​",
            "style": "IPY_MODEL_0afeb7cb684f4bf0a715bc3f24df4c12",
            "value": " 2/2 [24:42&lt;00:00, 739.51s/it]"
          }
        },
        "8411e93e873f47e396990618831abba9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93bd77ff2869409593704a5fb7813019": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "949b0c7987a24859ad0413c4c48c6fc1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9526d7e3421f4cb199f1de7f074f204e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9abef67aacd84158aaebacf4d4b89df9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec4968332c2b46049aeefacfa7a23bb0",
            "placeholder": "​",
            "style": "IPY_MODEL_781504b638fd4acb842a2b5dfe8aa78e",
            "value": "Epoch: 1: 100%"
          }
        },
        "9d00213a02354271b33fe6416f990f3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dff8e3f4e3ec40b89c1ec35390af2bb7",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_93bd77ff2869409593704a5fb7813019",
            "value": 2
          }
        },
        "9e16f5966b66472788de79a3173523a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e3c0e794b6b4a05a2b820e9a0fcb7ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_406f354626ca4ad89ebbb86af233583f",
            "placeholder": "​",
            "style": "IPY_MODEL_f6f9cf838fbb4f469fe67f9cd0775f61",
            "value": " 2/2 [2:10:59&lt;00:00, 4298.04s/it]"
          }
        },
        "9e52ecf6f0f04f69a2105e7c267d9583": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a01232dfb9d8429298563a31fb2cfdb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a269e972116429891a4b24c45b7150c",
            "placeholder": "​",
            "style": "IPY_MODEL_12a85a5381104dd3b02dd939602c7466",
            "value": " 1/2 [14:23&lt;14:23, 863.85s/it]"
          }
        },
        "a23a2041e4b34db4bcc5c8aaea4e3bf6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3c8adbee3854af8a18ab1cf97961771": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a97301ffca414a78b00271fdeb4d075d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aacc28cb283e4d3289a748a01229bd2b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab0fc8272b7343ab8dfd6e3e5419977c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6666ed7f91884d0e85653271f9acb21d",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a97301ffca414a78b00271fdeb4d075d",
            "value": 2
          }
        },
        "acf1a21b13ed4ad0b418cbcde0a4b968": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_513ca98be4eb4231a1adea0ee9c6e32a",
              "IPY_MODEL_e451df8b02ac4e47a708672b61d77b1a",
              "IPY_MODEL_a01232dfb9d8429298563a31fb2cfdb6"
            ],
            "layout": "IPY_MODEL_5dffd65ae28d42e3ac52a7e1cac29d80"
          }
        },
        "b1cdec34663e4bd08ad1c6eb18371a8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e86a130bec0a470d8e5af821882a844d",
            "placeholder": "​",
            "style": "IPY_MODEL_9e16f5966b66472788de79a3173523a3",
            "value": " 2/2 [24:32&lt;00:00, 735.56s/it]"
          }
        },
        "b34b340693064ecca93d7ead7cee8ceb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbbf4981209f4f7e8a008a150998e6b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd811ff4fb3c4cd593ab75229ba2f269": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e47ec956d864448afbacc2ab375f51b",
            "placeholder": "​",
            "style": "IPY_MODEL_3c88df238991414e8204a1916a0bc0e1",
            "value": "Epoch: 1: 100%"
          }
        },
        "bf0eea23318448cea384c260e92b1e46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c3756d81f5ce4bf9b7b65255fbb16ccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8411e93e873f47e396990618831abba9",
            "placeholder": "​",
            "style": "IPY_MODEL_7ca07fc91670451d9bc4e78ee8751b77",
            "value": "Epoch: 1: 100%"
          }
        },
        "c9074be9404a4b24bdf35c9dad6ebe69": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca8d7c27dd8042bbb3e425a929cf4a3c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc3ad48f882b4b3baa6e6ad675427d0d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce3599bd3a3745cc954d3f63c18f86b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d22aba869ff14c5ba39412874b935752": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3dd42c03e3a42cb97a4cb004b428488": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6bd007881764222a2db1376740caaa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9ae0f8c8031415a9b41b484df58045d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da54eab21c334c2dbff5643b5931e12b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db4587a905df42fa8dca0a269ea25f9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a23a2041e4b34db4bcc5c8aaea4e3bf6",
            "placeholder": "​",
            "style": "IPY_MODEL_ef7d650c9e3c4afdbbcc11f71053d765",
            "value": " 2/2 [1:58:04&lt;00:00, 3864.39s/it]"
          }
        },
        "dddbc1880ea54efeb49fbd50a2158e96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dff8e3f4e3ec40b89c1ec35390af2bb7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e451df8b02ac4e47a708672b61d77b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61c31ae9ad51412b8951146fd0f65903",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24947296fee143ecbbe05a4f88f96016",
            "value": 1
          }
        },
        "e679cdd86c584f1b9281bf9f7f84a4c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00362774a3a4483db0058e3191a6fdaa",
            "placeholder": "​",
            "style": "IPY_MODEL_7e5a3a5c30c24f829d020d80e94b037c",
            "value": " 2/2 [25:09&lt;00:00, 753.89s/it]"
          }
        },
        "e77fbcc105de449e914293ebdad64bb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff38cc3b284d4127b4ca316075d70a61",
            "placeholder": "​",
            "style": "IPY_MODEL_03609fd9407b4cad819897205be25795",
            "value": "Epoch: 1:  50%"
          }
        },
        "e86a130bec0a470d8e5af821882a844d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec4968332c2b46049aeefacfa7a23bb0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecb3cdecfa194e88b32aefb9067b2391": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eedd5ce0d4b647ce828ae3bf464e834d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef7d650c9e3c4afdbbcc11f71053d765": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f41cffe82a1844b883b107f114a259c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6f9cf838fbb4f469fe67f9cd0775f61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fda6ebbb48504b4d8d73e01e886d70b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff38cc3b284d4127b4ca316075d70a61": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff88504b2ae8430d99fe12885723ecca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e77fbcc105de449e914293ebdad64bb3",
              "IPY_MODEL_37953eebe35c468d8b73157f8d9eb74e",
              "IPY_MODEL_5a4e67dc9ed54b978b602964e0fcc37b"
            ],
            "layout": "IPY_MODEL_d22aba869ff14c5ba39412874b935752"
          }
        },
        "ffe99fe880254b9cb3d530a313ca2b0e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3206746a345465c9e6cd6cebe17e36a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2245537afaa4475f8c666d87e0d40fe3",
              "IPY_MODEL_ba65a8f16cc744949c301fa6fbe97a6f",
              "IPY_MODEL_d2d464de09dc4d849496e75a367ce676"
            ],
            "layout": "IPY_MODEL_4d6846d243ce44b296f6fb9ada4b5118"
          }
        },
        "2245537afaa4475f8c666d87e0d40fe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6804fd0bf95e455cbe353620c25cb283",
            "placeholder": "​",
            "style": "IPY_MODEL_a307c09a5cfb458b9c4b0c98ee018c9e",
            "value": ""
          }
        },
        "ba65a8f16cc744949c301fa6fbe97a6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ef4e0eaa48e4b829f17268185ac98f0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1badb5737ac942ada61d4f612da7166c",
            "value": 0
          }
        },
        "d2d464de09dc4d849496e75a367ce676": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08766aa343eb44889cb28348c6c558f8",
            "placeholder": "​",
            "style": "IPY_MODEL_3e05981666154fd18381cd70fe2cb3f5",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "4d6846d243ce44b296f6fb9ada4b5118": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6804fd0bf95e455cbe353620c25cb283": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a307c09a5cfb458b9c4b0c98ee018c9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ef4e0eaa48e4b829f17268185ac98f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "1badb5737ac942ada61d4f612da7166c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "08766aa343eb44889cb28348c6c558f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e05981666154fd18381cd70fe2cb3f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}